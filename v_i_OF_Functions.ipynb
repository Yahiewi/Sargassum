{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913665e7-f6a8-44e5-89c4-01ba935ffe28",
   "metadata": {},
   "source": [
    "# Optical Flow Functions\n",
    "In this notebook, we're going to define the functions we will need for the display, calculations, GIF creation and other utilities that are useful (these functions were previously defined in v_Motion_Estimation but we moved them here to avoid circular dependencies)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b116660-52d0-4f9d-bf95-a0c3b2d604e4",
   "metadata": {},
   "source": [
    "## Importing necessary libraries and notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b4cd8-d658-461b-bf13-82b82a32616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import io\n",
    "import os\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import Image, display, HTML\n",
    "from PIL import Image as PILImage\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import matplotlib as mpl\n",
    "# Increase the embed limit for animations\n",
    "mpl.rcParams['animation.embed_limit'] = 50  # Increase the limit to 50 MB\n",
    "\n",
    "# Import the other notebooks without running their cells\n",
    "from ii_Data_Manipulation import visualize_4\n",
    "from iii_GOES_average import time_list, visualize_aggregate, calculate_median\n",
    "from iv_Image_Processing import collect_times, crop_image, save_aggregate, binarize_image, bilateral_image, process_dates, process_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80acda4-b52f-40d1-956c-d22b50d35621",
   "metadata": {},
   "source": [
    "## Optical Flow Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7cc84-e4c8-4afd-af70-a60bdad40906",
   "metadata": {},
   "source": [
    "### Farneback_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069cfeb-2f6b-4520-ada6-83deda59d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def farneback_flow(prev_img, next_img):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    - flow : np.ndarray\n",
    "        The computed flow image that will have the same size as `prev_img` and\n",
    "        type CV_32FC2. Each element of the flow matrix will be a vector that\n",
    "        indicates the displacement (in pixels) of the corresponding pixel from\n",
    "        the first image to the second image.\n",
    "\n",
    "    Method Parameters:\n",
    "    - flow : np.ndarray\n",
    "        Optional input flow estimate. It must be a single precision floating point\n",
    "        image with the same size as `prev_img`. If provided, the function uses it as\n",
    "        an initial approximation of the flow. If None, the function estimates the flow\n",
    "        from scratch.\n",
    "    - pyr_scale : float\n",
    "        The image scale (<1) to build pyramids for each image; pyr_scale=0.5\n",
    "        means a classical pyramid, where each next layer is twice smaller than\n",
    "        the previous one.\n",
    "    - levels : int\n",
    "        The number of pyramid layers including the initial image. Levels=1\n",
    "        means that no extra layers are created and only the original images are used.\n",
    "    - winsize : int\n",
    "        The size of the window used to smooth derivatives used as a basis\n",
    "        for the polynomial expansion. The larger the size, the smoother the\n",
    "        input image and the more robust the algorithm is to noise, but the more\n",
    "        blurred motion details become.\n",
    "    - iterations : int\n",
    "        The number of iterations the algorithm will perform at each pyramid level.\n",
    "        More iterations can improve the accuracy of the flow estimation.\n",
    "    - poly_n : int\n",
    "        The size of the pixel neighborhood used to find polynomial expansion\n",
    "        in each pixel. Typical values are 5 or 7.\n",
    "    - poly_sigma : float\n",
    "        The standard deviation of the Gaussian that is used to smooth derivatives\n",
    "        used as a basis for the polynomial expansion. This parameter can\n",
    "        typically be ~1.1 for poly_n=5 and ~1.5 for poly_n=7.\n",
    "    - flags : int\n",
    "        Operation flags that can specify extra options such as using the initial\n",
    "        flow estimates or applying a more sophisticated form of smoothing:\n",
    "        - cv2.OPTFLOW_USE_INITIAL_FLOW: Uses the input flow as an initial flow estimate.\n",
    "        - cv2.OPTFLOW_FARNEBACK_GAUSSIAN: Uses a Gaussian window for smoothing\n",
    "          derivatives instead of a box filter.\n",
    "    \"\"\"\n",
    "    # Make images grayscale\n",
    "    prev_img = cv2.cvtColor(prev_img, cv2.COLOR_BGR2GRAY)\n",
    "    next_img = cv2.cvtColor(next_img, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(\n",
    "        prev_img, next_img, flow = None, pyr_scale=0.5, levels=3, winsize=15, \n",
    "        iterations=3, poly_n=5, poly_sigma=1.2, flags=0\n",
    "    )\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1952f1c2-404a-4c75-a8e4-4da0fa200467",
   "metadata": {},
   "source": [
    "### Lucas-Kanade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d7bd88-237d-4e3a-bc57-c7b9c852367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LK_flow(prev_img, next_img, max_corners=100, quality_level=0.3, min_distance=7, block_size=7, win_size=(15, 15), max_level=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)):\n",
    "    \"\"\"\n",
    "    Computes optical flow using the Lucas-Kanade method.\n",
    "\n",
    "    :param prev_img: The previous image frame.\n",
    "    :param next_img: The next image frame.\n",
    "    :param max_corners: Maximum number of corners to detect.\n",
    "    :param quality_level: Quality level for corner detection.\n",
    "    :param min_distance: Minimum possible Euclidean distance between the returned corners.\n",
    "    :param block_size: Size of an average block for computing a derivative covariance matrix over each pixel neighborhood.\n",
    "    :param win_size: Size of the search window at each pyramid level.\n",
    "    :param max_level: 0-based maximal pyramid level number.\n",
    "    :param criteria: Criteria for termination of the iterative search algorithm.\n",
    "    :return: p0, p1, st, err\n",
    "        p0: Initial points in the previous image.\n",
    "        p1: Corresponding points in the next image.\n",
    "        st: Status array indicating whether the flow for the corresponding feature has been found.\n",
    "        err: Error for each point.\n",
    "    \"\"\"\n",
    "    # Ensure images are grayscale\n",
    "    if len(prev_img.shape) == 3:\n",
    "        prev_img = cv2.cvtColor(prev_img, cv2.COLOR_BGR2GRAY)\n",
    "    if len(next_img.shape) == 3:\n",
    "        next_img = cv2.cvtColor(next_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect good features to track in the previous image\n",
    "    p0 = cv2.goodFeaturesToTrack(prev_img, maxCorners=max_corners, qualityLevel=quality_level, minDistance=min_distance, blockSize=block_size)\n",
    "    \n",
    "    # Calculate optical flow between the two images\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(prev_img, next_img, p0, None, winSize=win_size, maxLevel=max_level, criteria=criteria)\n",
    "    \n",
    "    return p0, p1, st, err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a13ec3b-1e4f-42a7-8699-b7ec204d8225",
   "metadata": {},
   "source": [
    "### ~Lucas-Kanade Flow~\n",
    "This is a version that returns the flow like the Farneback method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4777d-7500-44be-9317-7e9601e2f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LK_flow_2(prev_img, next_img):\n",
    "    prev_gray = cv2.cvtColor(prev_img, cv2.COLOR_BGR2GRAY)\n",
    "    next_gray = cv2.cvtColor(next_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params = dict(winSize=(15, 15),\n",
    "                     maxLevel=2,\n",
    "                     criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    # Detecting good features to track\n",
    "    prev_points = cv2.goodFeaturesToTrack(prev_gray, maxCorners=1000, qualityLevel=0.01, minDistance=7, blockSize=7)\n",
    "    \n",
    "    # Calculate optical flow using Lucas-Kanade method\n",
    "    next_points, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, next_gray, prev_points, None, **lk_params)\n",
    "    \n",
    "    # Select good points\n",
    "    good_prev = prev_points[st == 1]\n",
    "    good_next = next_points[st == 1]\n",
    "\n",
    "    # Create flow array\n",
    "    flow = np.zeros((prev_img.shape[0], prev_img.shape[1], 2), dtype=np.float32)\n",
    "    for pt1, pt2 in zip(good_prev, good_next):\n",
    "        x1, y1 = pt1.ravel()\n",
    "        x2, y2 = pt2.ravel()\n",
    "        flow[int(y1), int(x1)] = (x2 - x1, y2 - y1)\n",
    "\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a395a4-63b6-4c69-ad9d-784d3b95005c",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e573a1-cb73-436c-9b99-299eb4757848",
   "metadata": {},
   "source": [
    "### compute_flow_components\n",
    "Computes the magnitude and angle of the optical flow from the given flow vector components and then visualizes them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b131870-9992-419a-8a5c-94052ecdb825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_flow_components(flow):\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1], angleInDegrees=False)\n",
    "    return mag, ang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ffe47d-8ab5-4440-b6eb-b53211080fe8",
   "metadata": {},
   "source": [
    "### visualize_flow_components\n",
    "Visualizes the magnitude and angle of optical flow using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca142a00-f3c8-4099-aaa8-620c9e0ffe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_flow_components(mag, ang):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Magnitude plot\n",
    "    ax[0].imshow(mag, cmap='hot')\n",
    "    ax[0].set_title('Optical Flow Magnitude')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    # Angle plot\n",
    "    # Normalize the angles between 0 and 1 for visualization\n",
    "    ang_normalized = ang / (2 * np.pi)\n",
    "    ax[1].imshow(ang_normalized, cmap='hsv')  # HSV colormap to represent angle\n",
    "    ax[1].set_title('Optical Flow Angle')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c61e10-b5e0-4638-8282-bf616ad37a7c",
   "metadata": {},
   "source": [
    "### plot_flow_vectors\n",
    "We can also visualize the motion field through vectors. This uses quiver from matplotlib.\n",
    "\n",
    "Quiver produces nice looking arrows, but for our purposes, overlay_flow_vectors is probably better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b303aa-160b-4029-958d-06c570629c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flow_vectors(flow, base_img, step=16, scale=1, display=True, color='r'):\n",
    "    \"\"\"\n",
    "    Creates a plot of optical flow vectors over the base image and optionally displays it.\n",
    "\n",
    "    :param flow: Computed flow vectors with shape (H, W, 2).\n",
    "    :param base_img: Base image on which to plot the vectors.\n",
    "    :param step: Grid step size for sampling vectors. Smaller values increase density.\n",
    "    :param scale: Scaling factor for the magnitude of vectors to enhance visibility.\n",
    "    :param display: Boolean indicating whether to display the plot.\n",
    "    :return: An image array of the plot.\n",
    "    \"\"\"\n",
    "    H, W = flow.shape[:2]\n",
    "    y, x = np.mgrid[0:H:step, 0:W:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "\n",
    "    # Create a plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(base_img, cmap='gray')  # Ensure the image is displayed correctly\n",
    "    ax.quiver(x, y, fx, fy, color=color, angles='xy', scale_units='xy', scale=1/scale, width=0.0025)\n",
    "    ax.set_xlim([0, W])\n",
    "    ax.set_ylim([H, 0])\n",
    "    ax.axis('off')  # Turn off the axis\n",
    "\n",
    "    # Optionally display the plot\n",
    "    if display:\n",
    "        plt.show()\n",
    "\n",
    "    # Convert the Matplotlib figure to a PIL Image and then to a NumPy array\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)  # Close the figure to free memory\n",
    "    buf.seek(0)\n",
    "    img = PILImage.open(buf)\n",
    "    img_arr = np.array(img)\n",
    "\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90eb85a-fcb7-4b87-92ce-6612034cbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220723.png\")\n",
    "#     next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220724.png\")\n",
    "#     flow = farneback_flow(prev_img, next_img)\n",
    "#     plot_of_vectors(flow, prev_img, step=16, scale=1.25)\n",
    "#     display(Image(filename=\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220724.png\", width =750))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40f62d9-ddcb-431d-9dff-713b1fbac24e",
   "metadata": {},
   "source": [
    "### overlay_flow_vectors\n",
    "Overlays optical flow vectors on an image and returns the resulting image with vectors. Uses arrowedLine from OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6323c465-1fa1-4949-80a0-a867264b4e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_flow_vectors(flow, base_img, step=16, scale=1, color=(255, 0, 0)):\n",
    "    # Ensure base_img is in RGB to display colored vectors\n",
    "    if len(base_img.shape) == 2:\n",
    "        base_img = cv2.cvtColor(base_img, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    H, W = flow.shape[:2]\n",
    "    y, x = np.mgrid[0:H:step, 0:W:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "\n",
    "    # Create a figure for drawing\n",
    "    result_img = np.copy(base_img)\n",
    "    for i in range(len(x)):\n",
    "        start_point = (x[i], y[i])\n",
    "        end_point = (int(x[i] + fx[i] * scale), int(y[i] + fy[i] * scale))\n",
    "        cv2.arrowedLine(result_img, start_point, end_point, color, 1, tipLength=0.3)\n",
    "\n",
    "    return result_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702a681a-1850-41a0-bba4-b8470c5c3ff7",
   "metadata": {},
   "source": [
    "### overlay_flow_vectors_with_quiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e4b84-ddb4-4670-92d9-f2d002077290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_flow_vectors_with_quiver(flow, base_img, step=16, scale=1, color='r'):\n",
    "    \"\"\"\n",
    "    Overlays flow vectors using matplotlib's quiver directly on the image,\n",
    "    ensuring that the quiver plot matches the image size and aspect ratio.\n",
    "    \"\"\"\n",
    "    if len(base_img.shape) == 2:\n",
    "        base_img = cv2.cvtColor(base_img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    H, W = base_img.shape[:2]  # Use image dimensions for scaling and grid generation\n",
    "    y, x = np.mgrid[0:H:step, 0:W:step].reshape(2, -1)\n",
    "    fx, fy = flow[y, x].T\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(W / 100, H / 100), dpi=100)  # Set figure size based on image dimensions\n",
    "    ax.imshow(base_img, extent=[0, W, H, 0], aspect='auto')  # Force aspect ratio to match the image\n",
    "    ax.quiver(x, y, fx, fy, color=color, angles='xy', scale_units='xy', scale=1/scale, width=0.002)\n",
    "    ax.set_xlim([0, W])\n",
    "    ax.set_ylim([H, 0])\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Convert figure to an image\n",
    "    canvas = FigureCanvas(fig)\n",
    "    canvas.draw()\n",
    "    img_rgba = np.frombuffer(canvas.tostring_argb(), dtype=np.uint8)\n",
    "    img = img_rgba.reshape(canvas.get_width_height()[::-1] + (4,))[..., :3]  # Convert ARGB to RGB\n",
    "\n",
    "    plt.close(fig)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a31fd-6964-4312-b703-0a41c3a195d4",
   "metadata": {},
   "source": [
    "### create_flow_gif\n",
    "We can try to visualize the result using a GIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e7029e-869b-41da-a7f3-54df81933248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flow_gif(images, gif_path, fps=1, loop=10, quiver=False):\n",
    "    \"\"\"\n",
    "    Creates a GIF from a sequence of images, calculating optical flow and overlaying vectors.\n",
    "    \"\"\"\n",
    "    images_for_gif = []\n",
    "    \n",
    "    for i in range(len(images) - 1):\n",
    "        prev_img = images[i]\n",
    "        next_img = images[i+1]\n",
    "        flow = farneback_flow(prev_img, next_img)  # Assumes existence of this function\n",
    "        \n",
    "        if quiver:\n",
    "            overlay_img = overlay_flow_vectors_with_quiver(flow, prev_img)\n",
    "        else:\n",
    "            overlay_img = overlay_flow_vectors(flow, prev_img)  # Assumes existence of this function\n",
    "        \n",
    "        images_for_gif.append(prev_img)  # Add original image\n",
    "        images_for_gif.append(overlay_img)  # Add image with vectors\n",
    "\n",
    "    # Add the last image to the gif\n",
    "    images_for_gif.append(images[-1])\n",
    "\n",
    "    # Write GIF\n",
    "    imageio.mimsave(gif_path, images_for_gif, fps=fps, loop=loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f82c6-c59a-489b-a126-0fe60a5da580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     # Saving the GIF\n",
    "#     prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220723.png\")\n",
    "#     next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220724.png\")\n",
    "#     images = [prev_img, next_img]\n",
    "#     create_flow_gif(images, '/home/yahia/Documents/Jupyter/Sargassum/Images/GIFs/optical_flow.gif', fps=0.2, loop=10, quiver=True)\n",
    "    \n",
    "#     # Displaying the GIF\n",
    "#     gif_path = '/home/yahia/Documents/Jupyter/Sargassum/Images/GIFs/optical_flow.gif' \n",
    "#     display(Image(filename=gif_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28e9f8f-0268-4b7a-8813-286350c0219a",
   "metadata": {},
   "source": [
    "### plot_LK_vectors\n",
    "This function plots the flow vectors using the results of the LK algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b2b17e-0709-493d-9e27-c3256115f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_LK_vectors(p0, p1, st, base_img, display=True, color='r'):\n",
    "    \"\"\"\n",
    "    Creates a plot of optical flow vectors over the base image and optionally displays it.\n",
    "\n",
    "    :param p0: Initial points in the previous image.\n",
    "    :param p1: Corresponding points in the next image.\n",
    "    :param st: Status array indicating whether the flow for the corresponding feature has been found.\n",
    "    :param base_img: Base image on which to plot the vectors.\n",
    "    :param display: Boolean indicating whether to display the plot.\n",
    "    :param color: Color of the flow vectors.\n",
    "    :return: An image array of the plot.\n",
    "    \"\"\"\n",
    "    # Select good points\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "\n",
    "    # Create a plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(base_img, cmap='gray')  # Ensure the image is displayed correctly\n",
    "\n",
    "    # Draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        ax.plot([c, a], [d, b], color=color, linewidth=1.5)\n",
    "        ax.scatter(a, b, color=color, s=5)\n",
    "\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Optionally display the plot\n",
    "    if display:\n",
    "        plt.show()\n",
    "\n",
    "    # Convert the Matplotlib figure to a PIL Image and then to a NumPy array\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)  # Close the figure to free memory\n",
    "    buf.seek(0)\n",
    "    img = PILImage.open(buf)\n",
    "    img_arr = np.array(img)\n",
    "\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bd4970-d53c-49ab-8872-dd65a8635150",
   "metadata": {},
   "source": [
    "### display_image_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6543c-3437-4dc4-a409-f6984c8bf944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_cv(image_array):\n",
    "    # OpenCV might load images in BGR format, ensure to convert to RGB if necessary\n",
    "    if image_array.shape[2] == 3:  # Color image\n",
    "        image_array = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow('Optical Flow Vectors', image_array)\n",
    "    while True:\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e03f72a-9592-40e1-88d0-c4c6b85ea36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     # Binary image\n",
    "#     prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220723.png\")\n",
    "#     next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220724.png\")\n",
    "#     p0, p1, st, err = LK_flow(prev_img, next_img)\n",
    "#     img_with_vectors = LK_vector_field(p0, p1, st, prev_img)\n",
    "#     display_image_cv(img_with_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a5a00b-3060-4fa5-83d2-ad259ce11da8",
   "metadata": {},
   "source": [
    "### display_image_mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abda59a1-32d0-4643-92f0-636638a80428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_mpl(image_array, scale=1):\n",
    "    \"\"\"\n",
    "    Displays an image using matplotlib. Converts from BGR to RGB if needed and handles both grayscale and color images.\n",
    "    Allows specification of the display size.\n",
    "\n",
    "    Parameters:\n",
    "    - image_array (numpy array): The image data array. It can be in grayscale or BGR color format.\n",
    "    - width (float): Width of the figure in inches.\n",
    "    - height (float): Height of the figure in inches.\n",
    "    \"\"\"\n",
    "    # Check if image is in color (BGR format), and convert to RGB for display\n",
    "    if len(image_array.shape) == 3 and image_array.shape[2] == 3:\n",
    "        image_array = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Create a figure with specified size\n",
    "    plt.figure(figsize=(8*scale, 6*scale))\n",
    "    \n",
    "    # Determine if the image is grayscale and display it\n",
    "    if len(image_array.shape) == 2 or image_array.shape[2] == 1:\n",
    "        plt.imshow(image_array, cmap='gray')  # Display grayscale image\n",
    "    else:\n",
    "        plt.imshow(image_array)  # Display color image\n",
    "    \n",
    "    # Hide axes and show the figure\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b5af60-9dcc-4b76-9b51-1efb459e1a57",
   "metadata": {},
   "source": [
    "### superpose_images\n",
    "This is a function that takes two images (preferably binarized for clarity) and superposes them on top of each other with different colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f7ce2-085a-49b2-86da-9a3b58b83500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def superpose_images(image1, image2, color1=(255, 0, 0), color2=(0, 255, 0)):\n",
    "    \"\"\"\n",
    "    Superposes the black regions of two binarized images onto a white background with different colors.\n",
    "    Black areas from image1 and image2 are shown in distinct colors, and the background remains white.\n",
    "\n",
    "    Parameters:\n",
    "    - image1 (numpy.ndarray): The first binarized image, white background with black algae.\n",
    "    - image2 (numpy.ndarray): The second binarized image, white background with black algae.\n",
    "    - color1 (tuple): RGB color for the algae in the first image.\n",
    "    - color2 (tuple): RGB color for the algae in the second image.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: An image with the black regions of the two input images superposed in the specified colors.\n",
    "    \"\"\"\n",
    "    # Ensure images are grayscale\n",
    "    if len(image1.shape) == 3:\n",
    "        image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    if len(image2.shape) == 3:\n",
    "        image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold images to ensure they are binary\n",
    "    _, image1 = cv2.threshold(image1, 127, 255, cv2.THRESH_BINARY)\n",
    "    _, image2 = cv2.threshold(image2, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Create a white RGB image with the same dimensions as the input images\n",
    "    height, width = image1.shape\n",
    "    colored_image = np.full((height, width, 3), fill_value=(255, 255, 255), dtype=np.uint8)  # White background\n",
    "\n",
    "    # Apply the specified colors to the black regions of each binary image\n",
    "    colored_image[(image1 == 0)] = color1  # Apply color1 where image1 is black\n",
    "    colored_image[(image2 == 0)] = color2  # Apply color2 where image2 is black\n",
    "\n",
    "    return colored_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb1313-62fb-4d5b-98c8-7bb06c75c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220723.png\")\n",
    "#     next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220724.png\")\n",
    "#     superposed = superpose_images(prev_img, next_img)\n",
    "#     display_image_cv(superposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192dc00c-8906-4d02-b459-72a9a64ab90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     motion_field = overlay_optical_flow_vectors(flow, superposed, step=16, scale=1, color=(0,0,255))\n",
    "#     display_image_cv(motion_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb16311a-65ac-452a-be9d-2daab86b2466",
   "metadata": {},
   "source": [
    "### warp_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f3e08a-6add-4f84-bdbe-6f664824ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image(img, flow):\n",
    "    \"\"\"\n",
    "    Warps an image using the given optical flow map.\n",
    "\n",
    "    Parameters:\n",
    "    - img (numpy.ndarray): The original image to be warped.\n",
    "    - flow (numpy.ndarray): The optical flow vectors that indicate pixel displacements.\n",
    "\n",
    "    Returns:\n",
    "    - warped_img (numpy.ndarray): The resulting image after applying the flow warp.\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    # Create grid of coordinates\n",
    "    flow_map = np.column_stack((np.indices((h, w))[1].ravel() + flow[..., 0].ravel(),  # x coordinates\n",
    "                                np.indices((h, w))[0].ravel() + flow[..., 1].ravel())) # y coordinates\n",
    "    # Map coordinates from flow\n",
    "    flow_map = flow_map.reshape(h, w, 2).astype(np.float32)\n",
    "    # Apply remapping\n",
    "    warped_img = cv2.remap(img, flow_map, None, cv2.INTER_LANCZOS4)\n",
    "\n",
    "    return warped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19072f-52e1-4413-922c-93c0aa07a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220724.png\")\n",
    "    flow = farneback_flow(prev_img, next_img)\n",
    "    #plot_of_vectors(flow, prev_img, step=16, scale=1.25)\n",
    "    warped = warp_image(prev_img, flow)\n",
    "    display_image_mpl(warped)\n",
    "    # display(Image(filename=\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220723.png\", width =750))\n",
    "    # display(Image(filename=\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220724.png\", width =750))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96594b2b-774c-49b9-bbac-75bfdc2d46a5",
   "metadata": {},
   "source": [
    "### warp_image_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd68f00-41b8-416f-b9f8-8dde510f3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image_2(img, flow, alpha):\n",
    "    h, w = flow.shape[:2]\n",
    "    flow = flow * alpha\n",
    "    \n",
    "    # Create a grid of coordinates and apply the flow\n",
    "    coords = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    coords = np.array(coords).astype(np.float32)\n",
    "    coords = np.stack(coords, axis=-1)\n",
    "    coords += flow\n",
    "    \n",
    "    # Warp the image using the flow\n",
    "    map_x = coords[..., 0].astype(np.float32)\n",
    "    map_y = coords[..., 1].astype(np.float32)\n",
    "    warped_img = cv2.remap(img, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "    return warped_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa38641-53e9-44b7-8e0a-89f52fac5c91",
   "metadata": {},
   "source": [
    "### interpolate_images\n",
    "We're now going to try and visualize the movement of the algae from one frame to the next by interpolating between the frames. We're first going to try a linear interpolation method that simply divides the flow into **num_interpolations** fields. This function then applies a fraction of the flow to the first image and (the opposite of that flow) to the second image then blends them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051e2501-4401-4f99-b6d7-d8e1b27f0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_images(prev_img, next_img, flow, num_interpolations=30):\n",
    "    interpolated_images = []\n",
    "    for i in range(num_interpolations + 1):\n",
    "        alpha = i / num_interpolations\n",
    "        warped_prev = warp_image_2(prev_img, flow, alpha)\n",
    "        warped_next = warp_image_2(next_img, -flow, 1 - alpha)\n",
    "        blended_img = cv2.addWeighted(warped_prev, 1 - alpha, warped_next, alpha, 0)\n",
    "        interpolated_images.append(blended_img)\n",
    "    return interpolated_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1117f6-be30-47e7-ba81-dbc58aca3179",
   "metadata": {},
   "source": [
    "### visualize_movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdc1425-3843-4bfe-9946-7e34f1117fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_movement(interpolated_images, fps=15):\n",
    "    interval = 1000 / fps  # Interval in milliseconds\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    im = ax.imshow(interpolated_images[0])\n",
    "    \n",
    "    def update_frame(num):\n",
    "        im.set_array(interpolated_images[num])\n",
    "        return im,\n",
    "    \n",
    "    ani = animation.FuncAnimation(fig, update_frame, frames=len(interpolated_images), blit=True, interval=interval)\n",
    "    \n",
    "    # Display the animation in the notebook\n",
    "    display(HTML(ani.to_jshtml()))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2e509-514a-4bcf-ae65-6f7537f8d563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     # Binarized\n",
    "#     prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220723.png\")\n",
    "#     next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220724.png\")\n",
    "#     flow = farneback_flow(prev_img, next_img)\n",
    "#     interpolated_images = interpolate_images(prev_img, next_img, flow, num_interpolations=60)\n",
    "#     visualize_movement(interpolated_images, fps=15)\n",
    "#     #display(Image(filename='interpolated_images.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ca5c2-776a-4ac8-9a38-5c24feb0800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Viridis\n",
    "    prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220724.png\")\n",
    "    flow = farneback_flow(prev_img, next_img)\n",
    "    interpolated_images = interpolate_images(prev_img, next_img, flow, num_interpolations=60)\n",
    "    visualize_movement(interpolated_images, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955929da-553e-4b38-b3bf-14f2f81cbcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lucas-Kanade\n",
    "if __name__ == '__main__':\n",
    "    # Viridis\n",
    "    prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220724.png\")\n",
    "    flow = LK_flow_2(prev_img, next_img)\n",
    "    interpolated_images = interpolate_images(prev_img, next_img, flow, num_interpolations=60)\n",
    "    visualize_movement(interpolated_images, fps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9147dff-d62a-45f9-8254-f94cd222c0d6",
   "metadata": {},
   "source": [
    "## Error Quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa29638-792a-45c1-bbfb-08b64baf70df",
   "metadata": {},
   "source": [
    "### calculate_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb21a19-28ac-4d61-962c-2e23874b056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(image1, image2):\n",
    "    \"\"\"\n",
    "    Calculates the Mean Squared Error between two images, which measures the average of the squares of the errors.\n",
    "    \n",
    "    Parameters:\n",
    "    - image1 (numpy.ndarray): The first image (e.g., warped image).\n",
    "    - image2 (numpy.ndarray): The second image (e.g., actual next frame).\n",
    "\n",
    "    Returns:\n",
    "    - float: The mean squared error between the two images.\n",
    "    \"\"\"\n",
    "    # Ensure the images are the same shape\n",
    "    assert image1.shape == image2.shape, \"Images must have the same dimensions.\"\n",
    "\n",
    "    # Compute the squared differences\n",
    "    diff = np.square(image1.astype(\"float\") - image2.astype(\"float\"))\n",
    "    \n",
    "    # Return the mean of the differences\n",
    "    mse = np.mean(diff)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2c00a5-2082-47fa-8d88-de81475f5a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220724.png\")\n",
    "    flow = farneback_flow(prev_img, next_img)\n",
    "    #plot_of_vectors(flow, prev_img, step=16, scale=1.25)\n",
    "    warped = warp_image(prev_img, flow)\n",
    "    display_image_mpl(warped)\n",
    "    print(\"MSE = \" + str(calculate_mse(warped, next_img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cea89f5-30da-4b12-bda5-bdd24e73a1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
