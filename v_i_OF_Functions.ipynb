{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913665e7-f6a8-44e5-89c4-01ba935ffe28",
   "metadata": {},
   "source": [
    "# Optical Flow Functions\n",
    "In this notebook, we're going to define the functions we will need for the display, calculations, GIF creation and other utilities that are useful (these functions were previously defined in v_Motion_Estimation but we moved them here to avoid circular dependencies)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b116660-52d0-4f9d-bf95-a0c3b2d604e4",
   "metadata": {},
   "source": [
    "## Importing necessary libraries and notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b4cd8-d658-461b-bf13-82b82a32616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import io\n",
    "import os\n",
    "import cv2\n",
    "import imageio\n",
    "import plotly.graph_objects as go\n",
    "import mpld3\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import Image, display, HTML\n",
    "from PIL import Image as PILImage\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from plotly.subplots import make_subplots\n",
    "from geopy.distance import geodesic\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "import matplotlib as mpl\n",
    "# Increase the embed limit for animations\n",
    "mpl.rcParams['animation.embed_limit'] = 50  # Increase the limit to 50 MB\n",
    "\n",
    "# Import the other notebooks without running their cells\n",
    "from ii_Data_Manipulation import visualize_4\n",
    "from iii_GOES_average import time_list, visualize_aggregate, calculate_median\n",
    "from iv_Image_Processing import collect_times, crop_image, save_aggregate, binarize_image, bilateral_image, process_dates, process_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80acda4-b52f-40d1-956c-d22b50d35621",
   "metadata": {},
   "source": [
    "## Optical Flow Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7cc84-e4c8-4afd-af70-a60bdad40906",
   "metadata": {},
   "source": [
    "### Farneback_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069cfeb-2f6b-4520-ada6-83deda59d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def farneback_flow(prev_img, next_img):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    - flow : np.ndarray\n",
    "        The computed flow image that will have the same size as `prev_img` and\n",
    "        type CV_32FC2. Each element of the flow matrix will be a vector that\n",
    "        indicates the displacement (in pixels) of the corresponding pixel from\n",
    "        the first image to the second image.\n",
    "\n",
    "    Method Parameters:\n",
    "    - flow : np.ndarray\n",
    "        Optional input flow estimate. It must be a single precision floating point\n",
    "        image with the same size as `prev_img`. If provided, the function uses it as\n",
    "        an initial approximation of the flow. If None, the function estimates the flow\n",
    "        from scratch.\n",
    "    - pyr_scale : float\n",
    "        The image scale (<1) to build pyramids for each image; pyr_scale=0.5\n",
    "        means a classical pyramid, where each next layer is twice smaller than\n",
    "        the previous one.\n",
    "    - levels : int\n",
    "        The number of pyramid layers including the initial image. Levels=1\n",
    "        means that no extra layers are created and only the original images are used.\n",
    "    - winsize : int\n",
    "        The size of the window used to smooth derivatives used as a basis\n",
    "        for the polynomial expansion. The larger the size, the smoother the\n",
    "        input image and the more robust the algorithm is to noise, but the more\n",
    "        blurred motion details become.\n",
    "    - iterations : int\n",
    "        The number of iterations the algorithm will perform at each pyramid level.\n",
    "        More iterations can improve the accuracy of the flow estimation.\n",
    "    - poly_n : int\n",
    "        The size of the pixel neighborhood used to find polynomial expansion\n",
    "        in each pixel. Typical values are 5 or 7.\n",
    "    - poly_sigma : float\n",
    "        The standard deviation of the Gaussian that is used to smooth derivatives\n",
    "        used as a basis for the polynomial expansion. This parameter can\n",
    "        typically be ~1.1 for poly_n=5 and ~1.5 for poly_n=7.\n",
    "    - flags : int\n",
    "        Operation flags that can specify extra options such as using the initial\n",
    "        flow estimates or applying a more sophisticated form of smoothing:\n",
    "        - cv2.OPTFLOW_USE_INITIAL_FLOW: Uses the input flow as an initial flow estimate.\n",
    "        - cv2.OPTFLOW_FARNEBACK_GAUSSIAN: Uses a Gaussian window for smoothing\n",
    "          derivatives instead of a box filter.\n",
    "    \"\"\"\n",
    "    # Make images grayscale\n",
    "    prev_img = cv2.cvtColor(prev_img, cv2.COLOR_BGR2GRAY)\n",
    "    next_img = cv2.cvtColor(next_img, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(\n",
    "        prev_img, next_img, flow = None, pyr_scale=0.5, levels=3, winsize=15, \n",
    "        iterations=3, poly_n=5, poly_sigma=1.2, flags=0\n",
    "    )\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1952f1c2-404a-4c75-a8e4-4da0fa200467",
   "metadata": {},
   "source": [
    "### Lucas-Kanade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d7bd88-237d-4e3a-bc57-c7b9c852367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LK_flow(prev_img, next_img, max_corners=100, quality_level=0.3, min_distance=7, block_size=7, win_size=(15, 15), max_level=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)):\n",
    "    \"\"\"\n",
    "    Computes optical flow using the Lucas-Kanade method.\n",
    "\n",
    "    :param prev_img: The previous image frame.\n",
    "    :param next_img: The next image frame.\n",
    "    :param max_corners: Maximum number of corners to detect.\n",
    "    :param quality_level: Quality level for corner detection.\n",
    "    :param min_distance: Minimum possible Euclidean distance between the returned corners.\n",
    "    :param block_size: Size of an average block for computing a derivative covariance matrix over each pixel neighborhood.\n",
    "    :param win_size: Size of the search window at each pyramid level.\n",
    "    :param max_level: 0-based maximal pyramid level number.\n",
    "    :param criteria: Criteria for termination of the iterative search algorithm.\n",
    "    :return: p0, p1, st, err\n",
    "        p0: Initial points in the previous image.\n",
    "        p1: Corresponding points in the next image.\n",
    "        st: Status array indicating whether the flow for the corresponding feature has been found.\n",
    "        err: Error for each point.\n",
    "    \"\"\"\n",
    "    # Ensure images are grayscale\n",
    "    if len(prev_img.shape) == 3:\n",
    "        prev_img = cv2.cvtColor(prev_img, cv2.COLOR_BGR2GRAY)\n",
    "    if len(next_img.shape) == 3:\n",
    "        next_img = cv2.cvtColor(next_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect good features to track in the previous image\n",
    "    p0 = cv2.goodFeaturesToTrack(prev_img, maxCorners=max_corners, qualityLevel=quality_level, minDistance=min_distance, blockSize=block_size)\n",
    "    \n",
    "    # Calculate optical flow between the two images\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(prev_img, next_img, p0, None, winSize=win_size, maxLevel=max_level, criteria=criteria)\n",
    "    \n",
    "    return p0, p1, st, err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a13ec3b-1e4f-42a7-8699-b7ec204d8225",
   "metadata": {},
   "source": [
    "### ~Lucas-Kanade Flow~\n",
    "This is a version that returns the flow like the Farneback method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4777d-7500-44be-9317-7e9601e2f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LK_flow_2(prev_img, next_img):\n",
    "    prev_gray = cv2.cvtColor(prev_img, cv2.COLOR_BGR2GRAY)\n",
    "    next_gray = cv2.cvtColor(next_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params = dict(winSize=(15, 15),\n",
    "                     maxLevel=2,\n",
    "                     criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    # Detecting good features to track\n",
    "    prev_points = cv2.goodFeaturesToTrack(prev_gray, maxCorners=1000, qualityLevel=0.01, minDistance=7, blockSize=7)\n",
    "    \n",
    "    # Calculate optical flow using Lucas-Kanade method\n",
    "    next_points, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, next_gray, prev_points, None, **lk_params)\n",
    "    \n",
    "    # Select good points\n",
    "    good_prev = prev_points[st == 1]\n",
    "    good_next = next_points[st == 1]\n",
    "\n",
    "    # Create flow array\n",
    "    flow = np.zeros((prev_img.shape[0], prev_img.shape[1], 2), dtype=np.float32)\n",
    "    for pt1, pt2 in zip(good_prev, good_next):\n",
    "        x1, y1 = pt1.ravel()\n",
    "        x2, y2 = pt2.ravel()\n",
    "        flow[int(y1), int(x1)] = (x2 - x1, y2 - y1)\n",
    "\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29daf89d-03fe-4611-b5ea-b0422f42a0df",
   "metadata": {},
   "source": [
    "### DeepFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da715d-e5f9-498f-b786-85a2f27d6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepflow(prev_img, next_img):\n",
    "    prev_gray = cv2.cvtColor(prev_img, cv2.COLOR_BGR2GRAY)\n",
    "    next_gray = cv2.cvtColor(next_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Initialize DeepFlow\n",
    "    deep_flow = cv2.optflow.createOptFlow_DeepFlow()\n",
    "    \n",
    "    # Compute flow\n",
    "    flow = deep_flow.calc(prev_gray, next_gray, None)\n",
    "    \n",
    "    return flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a395a4-63b6-4c69-ad9d-784d3b95005c",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e573a1-cb73-436c-9b99-299eb4757848",
   "metadata": {},
   "source": [
    "### compute_flow_components\n",
    "Computes the magnitude and angle of the optical flow from the given flow vector components and then visualizes them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b131870-9992-419a-8a5c-94052ecdb825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_flow_components(flow):\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1], angleInDegrees=False)\n",
    "    return mag, ang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ffe47d-8ab5-4440-b6eb-b53211080fe8",
   "metadata": {},
   "source": [
    "### visualize_flow_components\n",
    "Visualizes the magnitude and angle of optical flow using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca142a00-f3c8-4099-aaa8-620c9e0ffe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_flow_components(mag, ang):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Magnitude plot\n",
    "    ax[0].imshow(mag, cmap='hot')\n",
    "    ax[0].set_title('Optical Flow Magnitude')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    # Angle plot\n",
    "    # Normalize the angles between 0 and 1 for visualization\n",
    "    ang_normalized = ang / (2 * np.pi)\n",
    "    ax[1].imshow(ang_normalized, cmap='hsv')  # HSV colormap to represent angle\n",
    "    ax[1].set_title('Optical Flow Angle')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c61e10-b5e0-4638-8282-bf616ad37a7c",
   "metadata": {},
   "source": [
    "### plot_flow_vectors\n",
    "We can also visualize the motion field through vectors. This uses quiver from matplotlib.\n",
    "\n",
    "Quiver produces nice looking arrows, but for our purposes, overlay_flow_vectors is probably better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b303aa-160b-4029-958d-06c570629c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flow_vectors(flow, base_img, step=16, scale=1, display=True, color='r'):\n",
    "    \"\"\"\n",
    "    Creates a plot of optical flow vectors over the base image and optionally displays it.\n",
    "\n",
    "    :param flow: Computed flow vectors with shape (H, W, 2).\n",
    "    :param base_img: Base image on which to plot the vectors.\n",
    "    :param step: Grid step size for sampling vectors. Smaller values increase density.\n",
    "    :param scale: Scaling factor for the magnitude of vectors to enhance visibility.\n",
    "    :param display: Boolean indicating whether to display the plot.\n",
    "    :return: An image array of the plot.\n",
    "    \"\"\"\n",
    "    H, W = flow.shape[:2]\n",
    "    y, x = np.mgrid[0:H:step, 0:W:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "\n",
    "    # Create a plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(base_img, cmap='gray')  # Ensure the image is displayed correctly\n",
    "    ax.quiver(x, y, fx, fy, color=color, angles='xy', scale_units='xy', scale=1/scale, width=0.0025)\n",
    "    ax.set_xlim([0, W])\n",
    "    ax.set_ylim([H, 0])\n",
    "    ax.axis('off')  # Turn off the axis\n",
    "\n",
    "    # Optionally display the plot\n",
    "    if display:\n",
    "        plt.show()\n",
    "\n",
    "    # Convert the Matplotlib figure to a PIL Image and then to a NumPy array\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)  # Close the figure to free memory\n",
    "    buf.seek(0)\n",
    "    img = PILImage.open(buf)\n",
    "    img_arr = np.array(img)\n",
    "\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90eb85a-fcb7-4b87-92ce-6612034cbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220723.png\")\n",
    "#     next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220724.png\")\n",
    "#     flow = farneback_flow(prev_img, next_img)\n",
    "#     plot_flow_vectors(flow, prev_img, step=16, scale=1.25)\n",
    "#     # display(Image(filename=\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220724.png\", width =750))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab0899d-4c13-4fe6-9629-ee0a185188aa",
   "metadata": {},
   "source": [
    "### plotly_flow_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa27b1e-c77d-4ac5-b6c0-a5319ae42d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotly_flow_vectors(flow, base_img, step=16, scale=1, arrow_sampling=5):\n",
    "    \"\"\"\n",
    "    Enhanced to show arrowheads selectively for performance.\n",
    "\n",
    "    :param arrow_sampling: Only plot an arrowhead for every nth vector.\n",
    "    \"\"\"\n",
    "    H, W = flow.shape[:2]\n",
    "    y, x = np.mgrid[0:H:step, 0:W:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T * scale\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Image(z=base_img))\n",
    "\n",
    "    # Add fewer arrowheads based on sampling rate\n",
    "    for i, (xi, yi, fxi, fyi) in enumerate(zip(x, y, fx, fy)):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[xi, xi + fxi],\n",
    "                y=[yi, yi + fyi],\n",
    "                mode='lines',\n",
    "                line=dict(color='red', width=2),\n",
    "                showlegend=False\n",
    "            )\n",
    "        )\n",
    "        if i % arrow_sampling == 0:  # Only add arrowheads for every nth vector\n",
    "            fig.add_annotation(\n",
    "                x=xi + fxi,\n",
    "                y=yi + fyi,\n",
    "                ax=xi,\n",
    "                ay=yi,\n",
    "                xref='x',\n",
    "                yref='y',\n",
    "                axref='x',\n",
    "                ayref='y',\n",
    "                showarrow=True,\n",
    "                arrowhead=3,\n",
    "                arrowsize=1,\n",
    "                arrowwidth=2,\n",
    "                arrowcolor='red'\n",
    "            )\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[0, W]),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[H, 0], scaleanchor=\"x\", scaleratio=1),\n",
    "        width=800,\n",
    "        height=800,\n",
    "        margin=dict(l=0, r=0, t=0, b=0)\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045e363-8e35-4a5b-bef3-a0fb9b300010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     # default\n",
    "#     prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220723.png\")\n",
    "#     next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220724.png\")\n",
    "#     flow = farneback_flow(prev_img, next_img)\n",
    "#     plot_flow_vectors(flow, prev_img, step=16, scale=1.25)\n",
    "#     # plotly\n",
    "#     prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220723.png\")\n",
    "#     next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220724.png\")\n",
    "#     flow = farneback_flow(prev_img, next_img)\n",
    "#     plotly_flow_vectors(flow, prev_img, step=16, scale=1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544c924b-4c9a-470e-b3fb-3c0902b7b938",
   "metadata": {},
   "source": [
    "### plot_flow_vectors_opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd58e85-6317-4582-96b7-f4a29a9a740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flow_vectors_opencv(flow, base_img, step=8, scale=1, color=(0, 0, 255), max_height=800):\n",
    "    \"\"\"\n",
    "    Draws optical flow vectors over the base image using OpenCV and displays the result.\n",
    "    Closes the display window when 'q' is pressed.\n",
    "\n",
    "    :param flow: Computed flow vectors with shape (H, W, 2).\n",
    "    :param base_img: Base image on which to plot the vectors.\n",
    "    :param step: Grid step size for sampling vectors. Smaller values increase density.\n",
    "    :param scale: Scaling factor for the magnitude of vectors to enhance visibility.\n",
    "    :param color: Color of the vectors in BGR format (default is red).\n",
    "    \"\"\"\n",
    "    # Check if image is grayscale and convert to color\n",
    "    if len(base_img.shape) == 2 or base_img.shape[2] == 1:\n",
    "        base_img_color = cv2.cvtColor(base_img, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        base_img_color = base_img.copy()\n",
    "\n",
    "    H, W = flow.shape[:2]\n",
    "    y, x = np.mgrid[0:H:step, 0:W:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T * scale\n",
    "\n",
    "    # Draw arrows or lines representing the flow vectors\n",
    "    for xi, yi, fxi, fyi in zip(x, y, fx, fy):\n",
    "        end_point = (int(xi + fxi), int(yi + fyi))\n",
    "        cv2.arrowedLine(base_img_color, (xi, yi), end_point, color, thickness=1, tipLength=0.2)  \n",
    "    \n",
    "    # # Resize the image for display if it's too large\n",
    "    # if H > max_height:\n",
    "    #     scale_factor = max_height / H\n",
    "    #     new_width = int(W * scale_factor)\n",
    "    #     resized_img = cv2.resize(base_img_color, (new_width, max_height))\n",
    "    # else:\n",
    "    #     resized_img = base_img_color\n",
    "    \n",
    "    # Display the image with flow vectors\n",
    "    cv2.imshow('Optical Flow Vectors', base_img_color)\n",
    "    while True:\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a755a-46ac-46e3-ae20-2b11364ccb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # default\n",
    "    prev_img = cv2.imread(\"/media/yahia/ballena/ABI/Atlantic/Averages_Binarized_Bilateral/Processed_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/media/yahia/ballena/ABI/Atlantic/Averages_Binarized_Bilateral/Processed_algae_distribution_20220724.png\")\n",
    "    flow = deepflow(prev_img, next_img)\n",
    "    plot_flow_vectors_opencv(flow, prev_img, step=16, scale=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9425c956-f677-411d-a0a8-6736ab4be00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # default\n",
    "    prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220724.png\")\n",
    "    flow = deepflow(prev_img, next_img)\n",
    "    plot_flow_vectors_opencv(flow, prev_img, step=16, scale=1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40f62d9-ddcb-431d-9dff-713b1fbac24e",
   "metadata": {},
   "source": [
    "### overlay_flow_vectors\n",
    "Overlays optical flow vectors on an image and returns the resulting image with vectors. Uses arrowedLine from OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6323c465-1fa1-4949-80a0-a867264b4e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_flow_vectors(flow, base_img, step=16, scale=1, color=(255, 0, 0)):\n",
    "    # Ensure base_img is in RGB to display colored vectors\n",
    "    if len(base_img.shape) == 2:\n",
    "        base_img = cv2.cvtColor(base_img, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    H, W = flow.shape[:2]\n",
    "    y, x = np.mgrid[0:H:step, 0:W:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "\n",
    "    # Create a figure for drawing\n",
    "    result_img = np.copy(base_img)\n",
    "    for i in range(len(x)):\n",
    "        start_point = (x[i], y[i])\n",
    "        end_point = (int(x[i] + fx[i] * scale), int(y[i] + fy[i] * scale))\n",
    "        cv2.arrowedLine(result_img, start_point, end_point, color, 1, tipLength=0.3)\n",
    "\n",
    "    return result_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702a681a-1850-41a0-bba4-b8470c5c3ff7",
   "metadata": {},
   "source": [
    "### overlay_flow_vectors_with_quiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e4b84-ddb4-4670-92d9-f2d002077290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_flow_vectors_with_quiver(flow, base_img, step=16, scale=1, color='r'):\n",
    "    \"\"\"\n",
    "    Overlays flow vectors using matplotlib's quiver directly on the image,\n",
    "    ensuring that the quiver plot matches the image size and aspect ratio.\n",
    "    \"\"\"\n",
    "    if len(base_img.shape) == 2:\n",
    "        base_img = cv2.cvtColor(base_img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    H, W = base_img.shape[:2]  # Use image dimensions for scaling and grid generation\n",
    "    y, x = np.mgrid[0:H:step, 0:W:step].reshape(2, -1)\n",
    "    fx, fy = flow[y, x].T\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(W / 100, H / 100), dpi=100)  # Set figure size based on image dimensions\n",
    "    ax.imshow(base_img, extent=[0, W, H, 0], aspect='auto')  # Force aspect ratio to match the image\n",
    "    ax.quiver(x, y, fx, fy, color=color, angles='xy', scale_units='xy', scale=1/scale, width=0.002)\n",
    "    ax.set_xlim([0, W])\n",
    "    ax.set_ylim([H, 0])\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Convert figure to an image\n",
    "    canvas = FigureCanvas(fig)\n",
    "    canvas.draw()\n",
    "    img_rgba = np.frombuffer(canvas.tostring_argb(), dtype=np.uint8)\n",
    "    img = img_rgba.reshape(canvas.get_width_height()[::-1] + (4,))[..., :3]  # Convert ARGB to RGB\n",
    "\n",
    "    plt.close(fig)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a31fd-6964-4312-b703-0a41c3a195d4",
   "metadata": {},
   "source": [
    "### create_flow_gif\n",
    "We can try to visualize the result using a GIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e7029e-869b-41da-a7f3-54df81933248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flow_gif(images, gif_path, fps=1, loop=10, quiver=False):\n",
    "    \"\"\"\n",
    "    Creates a GIF from a sequence of images, calculating optical flow and overlaying vectors.\n",
    "    \"\"\"\n",
    "    images_for_gif = []\n",
    "    \n",
    "    for i in range(len(images) - 1):\n",
    "        prev_img = images[i]\n",
    "        next_img = images[i+1]\n",
    "        flow = farneback_flow(prev_img, next_img)  # Assumes existence of this function\n",
    "        \n",
    "        if quiver:\n",
    "            overlay_img = overlay_flow_vectors_with_quiver(flow, prev_img)\n",
    "        else:\n",
    "            overlay_img = overlay_flow_vectors(flow, prev_img)  # Assumes existence of this function\n",
    "        \n",
    "        images_for_gif.append(prev_img)  # Add original image\n",
    "        images_for_gif.append(overlay_img)  # Add image with vectors\n",
    "\n",
    "    # Add the last image to the gif\n",
    "    images_for_gif.append(images[-1])\n",
    "\n",
    "    # Write GIF\n",
    "    imageio.mimsave(gif_path, images_for_gif, fps=fps, loop=loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f82c6-c59a-489b-a126-0fe60a5da580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     # Saving the GIF\n",
    "#     prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220723.png\")\n",
    "#     next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220724.png\")\n",
    "#     images = [prev_img, next_img]\n",
    "#     create_flow_gif(images, '/home/yahia/Documents/Jupyter/Sargassum/Images/GIFs/optical_flow.gif', fps=0.2, loop=10, quiver=True)\n",
    "    \n",
    "#     # Displaying the GIF\n",
    "#     gif_path = '/home/yahia/Documents/Jupyter/Sargassum/Images/GIFs/optical_flow.gif' \n",
    "#     display(Image(filename=gif_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28e9f8f-0268-4b7a-8813-286350c0219a",
   "metadata": {},
   "source": [
    "### plot_LK_vectors\n",
    "This function plots the flow vectors using the results of the LK algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b2b17e-0709-493d-9e27-c3256115f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_LK_vectors(p0, p1, st, base_img, display=True, color='r'):\n",
    "    \"\"\"\n",
    "    Creates a plot of optical flow vectors over the base image and optionally displays it.\n",
    "\n",
    "    :param p0: Initial points in the previous image.\n",
    "    :param p1: Corresponding points in the next image.\n",
    "    :param st: Status array indicating whether the flow for the corresponding feature has been found.\n",
    "    :param base_img: Base image on which to plot the vectors.\n",
    "    :param display: Boolean indicating whether to display the plot.\n",
    "    :param color: Color of the flow vectors.\n",
    "    :return: An image array of the plot.\n",
    "    \"\"\"\n",
    "    # Select good points\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "\n",
    "    # Create a plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(base_img, cmap='gray')  # Ensure the image is displayed correctly\n",
    "\n",
    "    # Draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        ax.plot([c, a], [d, b], color=color, linewidth=1.5)\n",
    "        ax.scatter(a, b, color=color, s=5)\n",
    "\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Optionally display the plot\n",
    "    if display:\n",
    "        plt.show()\n",
    "\n",
    "    # Convert the Matplotlib figure to a PIL Image and then to a NumPy array\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)  # Close the figure to free memory\n",
    "    buf.seek(0)\n",
    "    img = PILImage.open(buf)\n",
    "    img_arr = np.array(img)\n",
    "\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bd4970-d53c-49ab-8872-dd65a8635150",
   "metadata": {},
   "source": [
    "### display_image_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6543c-3437-4dc4-a409-f6984c8bf944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_cv(image_array):\n",
    "    # OpenCV might load images in BGR format, ensure to convert to RGB if necessary\n",
    "    if image_array.shape[2] == 3:  # Color image\n",
    "        image_array = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow('Optical Flow Vectors', image_array)\n",
    "    while True:\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e03f72a-9592-40e1-88d0-c4c6b85ea36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     # Binary image\n",
    "#     prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220723.png\")\n",
    "#     next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220724.png\")\n",
    "#     p0, p1, st, err = LK_flow(prev_img, next_img)\n",
    "#     img_with_vectors = LK_vector_field(p0, p1, st, prev_img)\n",
    "#     display_image_cv(img_with_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a5a00b-3060-4fa5-83d2-ad259ce11da8",
   "metadata": {},
   "source": [
    "### display_image_mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abda59a1-32d0-4643-92f0-636638a80428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_mpl(image_array, scale=1):\n",
    "    \"\"\"\n",
    "    Displays an image using matplotlib. Converts from BGR to RGB if needed and handles both grayscale and color images.\n",
    "    Allows specification of the display size.\n",
    "\n",
    "    Parameters:\n",
    "    - image_array (numpy array): The image data array. It can be in grayscale or BGR color format.\n",
    "    - width (float): Width of the figure in inches.\n",
    "    - height (float): Height of the figure in inches.\n",
    "    \"\"\"\n",
    "    # Check if image is in color (BGR format), and convert to RGB for display\n",
    "    if len(image_array.shape) == 3 and image_array.shape[2] == 3:\n",
    "        image_array = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Create a figure with specified size\n",
    "    plt.figure(figsize=(8*scale, 6*scale))\n",
    "    \n",
    "    # Determine if the image is grayscale and display it\n",
    "    if len(image_array.shape) == 2 or image_array.shape[2] == 1:\n",
    "        plt.imshow(image_array, cmap='gray')  # Display grayscale image\n",
    "    else:\n",
    "        plt.imshow(image_array)  # Display color image\n",
    "    \n",
    "    # Hide axes and show the figure\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b5af60-9dcc-4b76-9b51-1efb459e1a57",
   "metadata": {},
   "source": [
    "### superpose_images\n",
    "This is a function that takes two images (preferably binarized for clarity) and superposes them on top of each other with different colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f7ce2-085a-49b2-86da-9a3b58b83500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def superpose_images(image1, image2, color1=(255, 0, 0), color2=(0, 255, 0)):\n",
    "    \"\"\"\n",
    "    Superposes the black regions of two binarized images onto a white background with different colors.\n",
    "    Black areas from image1 and image2 are shown in distinct colors, and the background remains white.\n",
    "\n",
    "    Parameters:\n",
    "    - image1 (numpy.ndarray): The first binarized image, white background with black algae.\n",
    "    - image2 (numpy.ndarray): The second binarized image, white background with black algae.\n",
    "    - color1 (tuple): RGB color for the algae in the first image.\n",
    "    - color2 (tuple): RGB color for the algae in the second image.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: An image with the black regions of the two input images superposed in the specified colors.\n",
    "    \"\"\"\n",
    "    # Ensure images are grayscale\n",
    "    if len(image1.shape) == 3:\n",
    "        image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    if len(image2.shape) == 3:\n",
    "        image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold images to ensure they are binary\n",
    "    _, image1 = cv2.threshold(image1, 127, 255, cv2.THRESH_BINARY)\n",
    "    _, image2 = cv2.threshold(image2, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Create a white RGB image with the same dimensions as the input images\n",
    "    height, width = image1.shape\n",
    "    colored_image = np.full((height, width, 3), fill_value=(255, 255, 255), dtype=np.uint8)  # White background\n",
    "\n",
    "    # Apply the specified colors to the black regions of each binary image\n",
    "    colored_image[(image1 == 0)] = color1  # Apply color1 where image1 is black\n",
    "    colored_image[(image2 == 0)] = color2  # Apply color2 where image2 is black\n",
    "\n",
    "    return colored_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb1313-62fb-4d5b-98c8-7bb06c75c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220724.png\")\n",
    "    superposed = superpose_images(prev_img, next_img)\n",
    "    display_image_cv(superposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192dc00c-8906-4d02-b459-72a9a64ab90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    motion_field = overlay_flow_vectors(flow, superposed, step=16, scale=1, color=(0,0,255))\n",
    "    display_image_cv(motion_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb16311a-65ac-452a-be9d-2daab86b2466",
   "metadata": {},
   "source": [
    "### warp_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f3e08a-6add-4f84-bdbe-6f664824ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image(img, flow):\n",
    "    \"\"\"\n",
    "    Warps an image using the given optical flow map.\n",
    "\n",
    "    Parameters:\n",
    "    - img (numpy.ndarray): The original image to be warped.\n",
    "    - flow (numpy.ndarray): The optical flow vectors that indicate pixel displacements.\n",
    "\n",
    "    Returns:\n",
    "    - warped_img (numpy.ndarray): The resulting image after applying the flow warp.\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    # Create grid of coordinates\n",
    "    flow_map = np.column_stack((np.indices((h, w))[1].ravel() + flow[..., 0].ravel(),  # x coordinates\n",
    "                                np.indices((h, w))[0].ravel() + flow[..., 1].ravel())) # y coordinates\n",
    "    # Map coordinates from flow\n",
    "    flow_map = flow_map.reshape(h, w, 2).astype(np.float32)\n",
    "    # Apply remapping\n",
    "    warped_img = cv2.remap(img, flow_map, None, cv2.INTER_LANCZOS4)\n",
    "\n",
    "    return warped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19072f-52e1-4413-922c-93c0aa07a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220724.png\")\n",
    "    flow = farneback_flow(prev_img, next_img)\n",
    "    #plot_of_vectors(flow, prev_img, step=16, scale=1.25)\n",
    "    warped = warp_image(prev_img, flow)\n",
    "    display_image_mpl(warped)\n",
    "    # display(Image(filename=\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220723.png\", width =750))\n",
    "    # display(Image(filename=\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220724.png\", width =750))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96594b2b-774c-49b9-bbac-75bfdc2d46a5",
   "metadata": {},
   "source": [
    "### warp_image_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd68f00-41b8-416f-b9f8-8dde510f3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image_2(img, flow, alpha):\n",
    "    h, w = flow.shape[:2]\n",
    "    flow = flow * alpha\n",
    "    \n",
    "    # Create a grid of coordinates and apply the flow\n",
    "    coords = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    coords = np.array(coords).astype(np.float32)\n",
    "    coords = np.stack(coords, axis=-1)\n",
    "    coords += flow\n",
    "    \n",
    "    # Warp the image using the flow\n",
    "    map_x = coords[..., 0].astype(np.float32)\n",
    "    map_y = coords[..., 1].astype(np.float32)\n",
    "    warped_img = cv2.remap(img, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "    return warped_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa38641-53e9-44b7-8e0a-89f52fac5c91",
   "metadata": {},
   "source": [
    "### interpolate_images\n",
    "We're now going to try and visualize the movement of the algae from one frame to the next by interpolating between the frames. We're first going to try a linear interpolation method that simply divides the flow into **num_interpolations** fields. This function then applies a fraction of the flow to the first image and (the opposite of that flow) to the second image then blends them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051e2501-4401-4f99-b6d7-d8e1b27f0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_images(prev_img, next_img, flow, num_interpolations=30):\n",
    "    interpolated_images = []\n",
    "    for i in range(num_interpolations + 1):\n",
    "        alpha = i / num_interpolations\n",
    "        warped_prev = warp_image_2(prev_img, flow, alpha)\n",
    "        warped_next = warp_image_2(next_img, -flow, 1 - alpha)\n",
    "        blended_img = cv2.addWeighted(warped_prev, 1 - alpha, warped_next, alpha, 0)\n",
    "        interpolated_images.append(blended_img)\n",
    "    return interpolated_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1117f6-be30-47e7-ba81-dbc58aca3179",
   "metadata": {},
   "source": [
    "### visualize_movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdc1425-3843-4bfe-9946-7e34f1117fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_movement(interpolated_images, fps=15):\n",
    "    interval = 1000 / fps  # Interval in milliseconds\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    im = ax.imshow(interpolated_images[0])\n",
    "    \n",
    "    def update_frame(num):\n",
    "        im.set_array(interpolated_images[num])\n",
    "        return im,\n",
    "    \n",
    "    ani = animation.FuncAnimation(fig, update_frame, frames=len(interpolated_images), blit=True, interval=interval)\n",
    "    \n",
    "    # Display the animation in the notebook\n",
    "    display(HTML(ani.to_jshtml()))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2e509-514a-4bcf-ae65-6f7537f8d563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     # Binarized\n",
    "#     prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220723.png\")\n",
    "#     next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220724.png\")\n",
    "#     flow = farneback_flow(prev_img, next_img)\n",
    "#     interpolated_images = interpolate_images(prev_img, next_img, flow, num_interpolations=60)\n",
    "#     visualize_movement(interpolated_images, fps=15)\n",
    "#     #display(Image(filename='interpolated_images.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ca5c2-776a-4ac8-9a38-5c24feb0800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Viridis\n",
    "    prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220724.png\")\n",
    "    flow = farneback_flow(prev_img, next_img)\n",
    "    interpolated_images = interpolate_images(prev_img, next_img, flow, num_interpolations=60)\n",
    "    visualize_movement(interpolated_images, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955929da-553e-4b38-b3bf-14f2f81cbcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lucas-Kanade\n",
    "if __name__ == '__main__':\n",
    "    # Viridis\n",
    "    prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220724.png\")\n",
    "    flow = LK_flow_2(prev_img, next_img)\n",
    "    interpolated_images = interpolate_images(prev_img, next_img, flow, num_interpolations=60)\n",
    "    visualize_movement(interpolated_images, fps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9147dff-d62a-45f9-8254-f94cd222c0d6",
   "metadata": {},
   "source": [
    "## Error Quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa29638-792a-45c1-bbfb-08b64baf70df",
   "metadata": {},
   "source": [
    "### calculate_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb21a19-28ac-4d61-962c-2e23874b056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(image1, image2):\n",
    "    \"\"\"\n",
    "    Calculates the Mean Squared Error between two images, which measures the average of the squares of the errors.\n",
    "    \n",
    "    Parameters:\n",
    "    - image1 (numpy.ndarray): The first image (e.g., warped image).\n",
    "    - image2 (numpy.ndarray): The second image (e.g., actual next frame).\n",
    "\n",
    "    Returns:\n",
    "    - float: The mean squared error between the two images.\n",
    "    \"\"\"\n",
    "    # Ensure the images are the same shape\n",
    "    assert image1.shape == image2.shape, \"Images must have the same dimensions.\"\n",
    "\n",
    "    # Compute the squared differences\n",
    "    diff = np.square(image1.astype(\"float\") - image2.astype(\"float\"))\n",
    "    \n",
    "    # Return the mean of the differences\n",
    "    mse = np.mean(diff)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2c00a5-2082-47fa-8d88-de81475f5a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    prev_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis/Processed_algae_distribution_20220724.png\")\n",
    "    flow = farneback_flow(prev_img, next_img)\n",
    "    #plot_of_vectors(flow, prev_img, step=16, scale=1.25)\n",
    "    warped = warp_image(prev_img, flow)\n",
    "    display_image_mpl(warped)\n",
    "    print(\"MSE = \" + str(calculate_mse(warped, next_img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cea89f5-30da-4b12-bda5-bdd24e73a1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68a7f924-28bf-456f-9dbc-2fd81525486e",
   "metadata": {},
   "source": [
    "## Masking\n",
    "In this part, we're going to try and mask the parts which don't interest us (where there is no movement of algae). We'll start with the binarized image. The idea is to combine the two masks for the white pixels in the first and second image using the **bitwise OR operator**.\n",
    "\n",
    "We thought of combining both the previous and next image in the mask because it seems like the flow vectors can trace out the shape of the algae in the next image, but when we tried, we found that masking using only the first image makes more sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0c52df-f182-4932-94a3-6d98b9761e2b",
   "metadata": {},
   "source": [
    "### mask_flow_vectors\n",
    "Similar to plot_flow_vectors with the addition of the Mask optional parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb386f-d207-4014-8c50-89e9bc64ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_flow_vectors(flow, prev_img, combined_img, step=16, scale=1.25):\n",
    "    h, w = prev_img.shape[:2]\n",
    "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2,-1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "    \n",
    "    mask = combined_img[y, x] > 0  # Only consider white areas\n",
    "    x = x[mask]\n",
    "    y = y[mask]\n",
    "    fx = fx[mask]\n",
    "    fy = fy[mask]\n",
    "\n",
    "    # Create a plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(prev_img, cmap='gray')  # Ensure the image is displayed correctly\n",
    "    ax.quiver(x, y, fx, fy, color='r', angles='xy', scale_units='xy', scale=1/scale, width=0.0025)\n",
    "    ax.set_xlim([0, w])\n",
    "    ax.set_ylim([h, 0])\n",
    "    ax.axis('off')  # Turn off the axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7721cd47-72c4-4df9-9c4d-09621870541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom\n",
    "if __name__ == '__main__':\n",
    "    # Binarized\n",
    "    prev_img = cv2.imread(\"/media/yahia/ballena/ABI/Spiral/ABI_Averages_Spiral_Binarized_Bilateral/Processed_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/media/yahia/ballena/ABI/Spiral/ABI_Averages_Spiral_Binarized_Bilateral/Processed_algae_distribution_20220724.png\")\n",
    "    combined_img = cv2.bitwise_or(prev_img, prev_img)  # Combine masks to include both positions, use prev_img, next_img to combine\n",
    "    combined_img = cv2.cvtColor(combined_img, cv2.COLOR_BGR2GRAY)\n",
    "    flow = deepflow(prev_img, next_img)\n",
    "    mask_flow_vectors(flow, prev_img, combined_img, step=16, scale=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7df2c-5360-4ee4-b351-e3052f29049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23/07 - 24/07\n",
    "if __name__ == '__main__':\n",
    "    # Binarized\n",
    "    prev_img = cv2.imread(\"/media/yahia/ballena/ABI/ABI_Averages_Antilles_Binarized_Bilateral/Processed_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/media/yahia/ballena/ABI/ABI_Averages_Antilles_Binarized_Bilateral/Processed_algae_distribution_20220724.png\")\n",
    "    combined_img = cv2.bitwise_or(prev_img, prev_img)  # Combine masks to include both positions, use prev_img, next_img to combine\n",
    "    combined_img = cv2.cvtColor(combined_img, cv2.COLOR_BGR2GRAY)\n",
    "    flow = deepflow(prev_img, next_img)\n",
    "    plot_flow_vectors(flow, prev_img, step=16, scale=1.25)\n",
    "    mask_flow_vectors(flow, prev_img, combined_img, step=16, scale=1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddce364-88a0-4526-8380-669b1bd73dbb",
   "metadata": {},
   "source": [
    "We can see that the results aren't great when we try to apply this to an image with a bigger range (zoomed out).\n",
    "\n",
    "We could try to change the scale of the arrows, or write another algorithm with a less aggressive mask that doesn't mask vectors in the close vicinity of the white pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b74ee9-f45d-45b6-9e51-2a06448d20d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Quantitative Analysis\n",
    "Here we're going to try to visualize the magnitude of the displacement vectors in meters to be able to judge whether the flow our algorithm is physically consistent or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ff6a58-440a-4154-bd56-f0d2e9f880ad",
   "metadata": {},
   "source": [
    "### calculate_velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeac4d6-8cc4-45bb-a7f0-9f970ba2624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_velocity(flow, resolution_km=1, time_seconds=24*3600):\n",
    "    # Calculate the magnitude of the flow vectors\n",
    "    magnitude = np.sqrt(flow[..., 0]**2 + flow[..., 1]**2)\n",
    "    \n",
    "    # Convert from pixels to meters (1 km = 1000 meters)\n",
    "    magnitude_meters = magnitude * resolution_km * 1000\n",
    "    \n",
    "    # Calculate velocity in meters per second\n",
    "    velocity_m_per_s = magnitude_meters / time_seconds\n",
    "    return velocity_m_per_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8298ea6-1998-4811-8d01-d1c089fc3f97",
   "metadata": {},
   "source": [
    "### visualize_velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d941e7f-24c5-4ae1-8215-b458c268575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_velocity(velocity, prev_img):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(prev_img, cmap='gray', alpha=0.5)\n",
    "    plt.imshow(velocity, cmap='jet', alpha=0.5)\n",
    "    plt.colorbar(label='Velocity (m/s)')\n",
    "    plt.title('Flow Velocity Heatmap')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cd7b34-6d8b-4f1a-8e7b-3461590b4655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom\n",
    "if __name__ == '__main__':\n",
    "    prev_img = cv2.imread(\"/media/yahia/ballena/ABI/Spiral/ABI_Averages_Spiral_Binarized_Bilateral/Processed_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/media/yahia/ballena/ABI/Spiral/ABI_Averages_Spiral_Binarized_Bilateral/Processed_algae_distribution_20220724.png\") \n",
    "    flow = deepflow(prev_img, next_img)\n",
    "    plot_flow_vectors(flow, prev_img, step=16, scale=1.25)\n",
    "    \n",
    "    # Calculate the velocity of the flow vectors\n",
    "    velocity_m_per_s = calculate_velocity(flow, resolution_km=1)\n",
    "    print(\"Flow Velocity (m/s):\", velocity_m_per_s)\n",
    "    visualize_velocity(velocity_m_per_s, prev_img)\n",
    "\n",
    "    # Masked Version\n",
    "    prev_img = cv2.imread(\"/media/yahia/ballena/ABI/Spiral/ABI_Averages_Spiral_Binarized_Bilateral/Processed_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/media/yahia/ballena/ABI/Spiral/ABI_Averages_Spiral_Binarized_Bilateral/Processed_algae_distribution_20220724.png\")\n",
    "    prev_img = cv2.cvtColor(prev_img, cv2.COLOR_BGR2GRAY)\n",
    "    flow = deepflow(prev_img, next_img)\n",
    "    mask_flow_vectors(flow, prev_img, prev_img, step=16, scale=1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4c59e6-132e-4955-83d4-07e898ace9c6",
   "metadata": {},
   "source": [
    "## Image Segmentation\n",
    "Here we'll try to calculate the average of the vectors on each algae aggregate so as to be able to visualize and quantify the movement of the whole aggregate instead of individual pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3376f338-3e62-4973-b64e-0911ab44d808",
   "metadata": {},
   "source": [
    "### segment_aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366dbfb6-bfa0-4475-9728-15303a53d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_aggregations(mask):\n",
    "    # Ensure mask is binary and of type uint8\n",
    "    mask = (mask * 255).astype(np.uint8)\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c7d5cf-0ea4-4bd1-9730-d934dbd036a2",
   "metadata": {},
   "source": [
    "### calculate_average_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc41a40-7480-4793-9b02-c65a706c5dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_vectors(flow, contours):\n",
    "    avg_vectors = []\n",
    "    for contour in contours:\n",
    "        mask = np.zeros(flow.shape[:2], dtype=np.uint8)\n",
    "        cv2.drawContours(mask, [contour], -1, 1, thickness=cv2.FILLED)\n",
    "        masked_flow = flow[mask == 1]\n",
    "        if masked_flow.size != 0:  # Ensure there are vectors to average\n",
    "            avg_vector = masked_flow.mean(axis=0)\n",
    "            avg_vectors.append(avg_vector)\n",
    "        else:\n",
    "            avg_vectors.append(None)  # No valid vectors in this contour\n",
    "    return avg_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85006b1-c5e6-4c56-9661-960bdf6f1787",
   "metadata": {},
   "source": [
    "### haversine\n",
    "This function was tested and returns correct results (distance in km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab630cf-16ae-4a16-89d9-55f1572668fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great-circle distance between two points \n",
    "    on the Earth specified by their longitude and latitude.\n",
    "    \"\"\"\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371  # Radius of Earth in kilometers\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4c1b10-40af-47b6-92f5-0aba04184082",
   "metadata": {},
   "source": [
    "### calculate_area_haversine\n",
    "Since the distances are not uniform in the image we can't directly use **cv2.contourArea** to calculate the area as this function calculates it in terms of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9025df-f1f7-4236-b1b5-50baffb03b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_area_haversine(contour, lons, lats):\n",
    "    \"\"\"\n",
    "    Calculate the area of the contour using the Haversine formula.\n",
    "    \"\"\"\n",
    "    contour = contour.reshape(-1, 2)\n",
    "    points = [(lats[y, x], lons[y, x]) for x, y in contour]\n",
    "    centroid = np.mean(points, axis=0)\n",
    "\n",
    "    area_km2 = 0.0\n",
    "    for i in range(len(points)):\n",
    "        p1 = points[i]\n",
    "        p2 = points[(i + 1) % len(points)]\n",
    "        a = haversine(p1[0], p1[1], centroid[0], centroid[1])\n",
    "        b = haversine(p2[0], p2[1], centroid[0], centroid[1])\n",
    "        c = haversine(p1[0], p1[1], p2[0], p2[1])\n",
    "        s = (a + b + c) / 2\n",
    "        area_km2 += sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "\n",
    "    return area_km2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ebedf2-94c4-4274-8a43-6241089070ed",
   "metadata": {},
   "source": [
    "### generate_lat_lon_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe27e6-d805-4700-b39e-38ce82914ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lat_lon_arrays(lat_range, lon_range, image_shape):\n",
    "    \"\"\"\n",
    "    Generate latitude and longitude arrays for the given image shape and coordinate ranges.\n",
    "    \"\"\"\n",
    "    latitudes = np.linspace(lat_range[0], lat_range[1], image_shape[0])\n",
    "    longitudes = np.linspace(lon_range[0], lon_range[1], image_shape[1])\n",
    "    lats, lons = np.meshgrid(latitudes, longitudes, indexing='ij')\n",
    "    return lats, lons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ddd903-8194-4ffc-895c-ad3cdc7df8e6",
   "metadata": {},
   "source": [
    "### calculate_velocity_and_angles\n",
    "A generalization of the calculate_velocity function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5bd916-3d8b-43c3-a75d-3088caf0e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_velocity_and_angle(vector, lon1, lat1, lon2, lat2, time_seconds=24*3600):\n",
    "    \"\"\"\n",
    "    Calculate the velocity magnitude and angle between two points defined by longitude and latitude.\n",
    "    \"\"\"\n",
    "    distance_km = haversine(lon1, lat1, lon2, lat2)\n",
    "    magnitude_meters = distance_km * 1000\n",
    "    velocity_m_per_s = magnitude_meters / time_seconds\n",
    "    \n",
    "    # Calculate the angle of the vector (in degrees)\n",
    "    angle_degrees = np.degrees(np.arctan2(vector[1], vector[0]))\n",
    "    \n",
    "    return velocity_m_per_s, angle_degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a8610f-d5cf-48a6-8635-2d8d2394a6f5",
   "metadata": {},
   "source": [
    "### calculate_angular_velocity\n",
    "Since we're not considering individual pixels in this section, we need the angular velocity along with the regular velocity to be able to describe the movement of the contour.\n",
    "\n",
    "**Right now, this function returns absurd results**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97df5c3-f217-4293-94de-1aacec9c4a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angular_velocity(flow, contour, centroid, resolution_km=1, time_seconds=24*3600, units='degrees'):\n",
    "    mask = np.zeros(flow.shape[:2], dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [contour], -1, 1, thickness=cv2.FILLED)\n",
    "    y, x = np.where(mask == 1)\n",
    "    \n",
    "    angular_velocity = 0\n",
    "    for (i, j) in zip(x, y):\n",
    "        vector = flow[j, i]\n",
    "        r_vector = np.array([i - centroid[0], j - centroid[1]])\n",
    "        cross_product = np.cross(r_vector, vector)\n",
    "        angular_velocity += cross_product\n",
    "\n",
    "    # Normalize by the number of points and convert to radians per second\n",
    "    if len(x) > 0:\n",
    "        angular_velocity /= len(x)\n",
    "        angular_velocity_meters = angular_velocity * resolution_km * 1000\n",
    "        angular_velocity_radians_per_s = angular_velocity_meters / time_seconds\n",
    "    else:\n",
    "        angular_velocity_radians_per_s = 0\n",
    "    \n",
    "    if units == 'degrees':\n",
    "        angular_velocity_units_per_s = np.degrees(angular_velocity_radians_per_s)\n",
    "    else:\n",
    "        angular_velocity_units_per_s = angular_velocity_radians_per_s\n",
    "    \n",
    "    return angular_velocity_units_per_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ca37a-ba76-487d-a281-cdf73acfc80a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### plot_aggregations_with_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cf5b85-3a6c-4c17-b201-a19011e7367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_aggregations_with_vectors(img, contours, avg_vectors):\n",
    "    colors = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for proper color display\n",
    "    \n",
    "    for idx, (contour, vector) in enumerate(zip(contours, avg_vectors)):\n",
    "        M = cv2.moments(contour)\n",
    "        color = colors[idx % len(colors)]\n",
    "        if M['m00'] != 0 and vector is not None:\n",
    "            cx = int(M['m10'] / M['m00'])\n",
    "            cy = int(M['m01'] / M['m00'])\n",
    "            ax.quiver(cx, cy, vector[0], vector[1], color=color, scale=1.5, angles='xy', scale_units='xy')\n",
    "            ax.text(cx, cy, str(idx), color=color, fontsize=12, verticalalignment='bottom')  # Label the vector\n",
    "            # Draw the contour\n",
    "            contour = contour.reshape(-1, 2)\n",
    "            ax.plot(contour[:, 0], contour[:, 1], color=color, linewidth=2)\n",
    "            # Label the contour\n",
    "            centroid_x, centroid_y = np.mean(contour, axis=0).astype(int)\n",
    "            ax.text(centroid_x, centroid_y, str(idx), color=color, fontsize=12, verticalalignment='top')  # Label the contour\n",
    "        else:\n",
    "            print(f\"Contour {idx} with no area or no valid vectors found.\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12595097-893f-4949-bda9-77180ea987b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load images\n",
    "    prev_img = cv2.imread(\"/media/yahia/ballena/ABI/Spiral/ABI_Averages_Spiral_Binarized_Bilateral/Processed_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/media/yahia/ballena/ABI/Spiral/ABI_Averages_Spiral_Binarized_Bilateral/Processed_algae_distribution_20220724.png\")\n",
    "    \n",
    "    # Calculate flow\n",
    "    flow = deepflow(prev_img, next_img)\n",
    "    \n",
    "    # Create a mask for the algae aggregation (example mask creation)\n",
    "    mask = (prev_img[:,:,0] > 200) & (prev_img[:,:,1] > 200) & (prev_img[:,:,2] > 200)\n",
    "    \n",
    "    # Segment the algae aggregations\n",
    "    contours = segment_aggregations(mask)\n",
    "\n",
    "    # Calculate average vectors for each aggregation\n",
    "    avg_vectors = calculate_average_vectors(flow, contours)\n",
    "    \n",
    "    # Plot the aggregations with their average vectors\n",
    "    plot_aggregations_with_vectors(prev_img, contours, avg_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d25e3b7-ff4e-40f0-9300-20750d008798",
   "metadata": {},
   "source": [
    "## Interactive Plot\n",
    "The idea here is to be able to hover with the mouse over a contour and see the corresponding velocity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7efd89b-b0a6-43b7-aa8a-811b023d46ab",
   "metadata": {},
   "source": [
    "### plot_interactive_contours_with_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b872ab04-9c77-4bfc-968e-70514b060c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interactive_contours_with_vectors(img, contours, avg_vectors, flow, lons, lats, grid_step=10):\n",
    "    colors = ['red', 'blue', 'green', 'cyan', 'magenta', 'yellow']\n",
    "    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "    fig.add_trace(go.Image(z=rgb_img), row=1, col=1)\n",
    "\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    # Reverse the latitude array to ensure correct orientation\n",
    "    lats = np.flipud(lats)\n",
    "\n",
    "    # Create a scatter plot for the image with hover information at a lower resolution\n",
    "    hover_data = []\n",
    "    for y in range(0, height, grid_step):\n",
    "        for x in range(0, width, grid_step):\n",
    "            hover_data.append((x, y, lats[y, x], lons[y, x]))\n",
    "\n",
    "    hover_x, hover_y, hover_lat, hover_lon = zip(*hover_data)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=hover_x,\n",
    "        y=hover_y,\n",
    "        mode='markers',\n",
    "        marker=dict(size=1, opacity=0),\n",
    "        hoverinfo='text',\n",
    "        text=[f\"Lat: {lat:.6f}, Lon: {lon:.6f}\" for lat, lon in zip(hover_lat, hover_lon)],\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "    for idx, (contour, vector) in enumerate(zip(contours, avg_vectors)):\n",
    "        if vector is not None:\n",
    "            M = cv2.moments(contour)\n",
    "            cx = int(M['m10'] / M['m00'])\n",
    "            cy = int(M['m01'] / M['m00'])\n",
    "            lon1, lat1 = lons[cy, cx], lats[cy, cx]\n",
    "            lon2, lat2 = lons[cy + int(vector[1]), cx + int(vector[0])], lats[cy + int(vector[1]), cx + int(vector[0])]\n",
    "            velocity_m_per_s, angle_degrees = calculate_velocity_and_angle(vector, lon1, lat1, lon2, lat2)\n",
    "            contour = contour.reshape(-1, 2)\n",
    "            x_coords = contour[:, 0]\n",
    "            y_coords = contour[:, 1]\n",
    "            color = colors[idx % len(colors)]\n",
    "            \n",
    "            # Calculate the area using Haversine formula\n",
    "            area_km2 = calculate_area_haversine(contour, lons, lats)\n",
    "            \n",
    "            hovertext = (f\"Contour {idx}<br>\"\n",
    "                         f\"Velocity: {velocity_m_per_s:.2f} m/s<br>\"\n",
    "                         f\"Angle: {angle_degrees:.2f} degrees<br>\"\n",
    "                         f\"Lat: {lat1:.6f}, Lon: {lon1:.6f}<br>\"\n",
    "                         f\"Surface area: {area_km2:.6f} km²\")\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x_coords, y=y_coords, mode='lines+markers',\n",
    "                line=dict(color=color), marker=dict(size=2), name=f'Contour {idx}',\n",
    "                hovertext=hovertext, showlegend=False\n",
    "            ))\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[cx, cx + vector[0]], y=[cy, cy + vector[1]], \n",
    "                mode='lines+markers', line=dict(color=color), \n",
    "                marker=dict(size=2), name=f'Vector {idx}', \n",
    "                hovertext=hovertext, showlegend=False\n",
    "            ))\n",
    "            fig.add_annotation(\n",
    "                x=cx + vector[0], y=cy + vector[1], ax=cx, ay=cy,\n",
    "                xref=\"x\", yref=\"y\", axref=\"x\", ayref=\"y\",\n",
    "                showarrow=True, arrowhead=3, arrowsize=2, arrowwidth=1, arrowcolor=color\n",
    "            )\n",
    "\n",
    "    fig.update_layout(title='Algae Aggregations with Average Vectors', showlegend=False, \n",
    "                      xaxis=dict(visible=False), yaxis=dict(visible=False), \n",
    "                      width=1000, height=800)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91c606e-9edc-4e63-80ce-f3acd759c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load images\n",
    "    prev_img = cv2.imread(\"/media/yahia/ballena/ABI/Spiral/ABI_Averages_Spiral_Binarized_Bilateral/Processed_algae_distribution_20220723.png\")\n",
    "    next_img = cv2.imread(\"/media/yahia/ballena/ABI/Spiral/ABI_Averages_Spiral_Binarized_Bilateral/Processed_algae_distribution_20220724.png\")\n",
    "    \n",
    "    # Calculate flow\n",
    "    flow = deepflow(prev_img, next_img)\n",
    "    \n",
    "    # Create a mask for the algae aggregation (example mask creation)\n",
    "    mask = (prev_img[:,:,0] > 200) & (prev_img[:,:,1] > 200) & (prev_img[:,:,2] > 200)\n",
    "    \n",
    "    # Segment the algae aggregations\n",
    "    contours = segment_aggregations(mask)\n",
    "    \n",
    "    # Calculate average vectors for each aggregation\n",
    "    avg_vectors = calculate_average_vectors(flow, contours)\n",
    "    \n",
    "    # Define latitude and longitude ranges\n",
    "    lat_range = (14, 15)\n",
    "    lon_range = (-66, -65)\n",
    "    \n",
    "    # Get the shape of the image\n",
    "    image_shape = prev_img.shape[:2]\n",
    "    \n",
    "    # Generate latitude and longitude arrays\n",
    "    lats, lons = generate_lat_lon_arrays(lat_range, lon_range, image_shape)\n",
    "    \n",
    "    # Plot the aggregations with their average vectors\n",
    "    plot_interactive_contours_with_vectors(prev_img, contours, avg_vectors, flow, lons, lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f9b8a9-d314-425b-9d09-ee39b7b17ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
