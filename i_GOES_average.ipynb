{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f3c209-055e-48f3-802c-8ba78b7c6964",
   "metadata": {},
   "source": [
    "# Averaging ABI-GOES images for a given day:\n",
    "We could try to average the images for a given day to try and reproduce the images we see on the CLS datastore.\n",
    "GOES doesn't cover the same region from image to image, so we can't directly calculate the average, we'll have to calculate an average only when there is data (non-nan values). We're going to work on the same day of 24/07/2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf370928-7e70-4791-9ae7-318d43960628",
   "metadata": {},
   "source": [
    "## Importing necessary libraries and notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b6bbac2-4bd8-4be9-9dd0-8479aa69806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "import os\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import ticker\n",
    "from IPython.display import Image\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01eab59-c963-47dc-8349-275ea27b52f6",
   "metadata": {},
   "source": [
    "## time_list\n",
    "First, we should write a function that generates a lost of the times in the time intervals we need to make the importation of data easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcc6800e-d08d-41cc-9b4d-2cb8aff614ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_list(start_time, end_time, interval):\n",
    "    \"\"\"\n",
    "    Generate a list of datetime strings in the format 'YYYYMMDD_HH-MM' between start_time and end_time at intervals of 'interval' minutes.\n",
    "    \n",
    "    Parameters:\n",
    "    - start_time (datetime): The start time.\n",
    "    - end_time (datetime): The end time.\n",
    "    - interval (int): The interval in minutes between each time point.\n",
    "\n",
    "    Returns:\n",
    "    - times (list of str): List of formatted datetime strings.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate a list of times at the specified interval\n",
    "    times = []\n",
    "    current_time = start_time\n",
    "    while current_time <= end_time:\n",
    "        times.append(current_time.strftime('%Y%m%d_%H-%M'))\n",
    "        current_time += timedelta(minutes=interval)\n",
    "\n",
    "    return times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff017b-8464-434a-a61b-0b41f2eeacf6",
   "metadata": {},
   "source": [
    "## visualize_4\n",
    "Note: vmax doesn't set a threshold for the image, it's just that the colors are saturated at vmax (For example if vmax is 0.01, values greater than 0.01 will still be shown but will have the same saturated color).\n",
    "\n",
    "This function is taken from the now deleted notebook ii_Data_Manipulation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4ba0d3-73c9-48d9-a170-7b61c149e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_4(file_path, lat_range=None, lon_range=None, color=\"viridis\", vmax=0.1):\n",
    "    # Load the netCDF data\n",
    "    data = xr.open_dataset(file_path)\n",
    "    \n",
    "    # If ranges are specified, apply them to select the desired subset\n",
    "    if lat_range:\n",
    "        data = data.sel(latitude=slice(*lat_range))\n",
    "    if lon_range:\n",
    "        data = data.sel(longitude=slice(*lon_range))\n",
    "\n",
    "    # Determine the index data and labels based on instrument used\n",
    "    index_key = 'fai_anomaly' if \"abi\" in file_path else 'nfai_mean'\n",
    "    colorbar_label = 'Floating Algae Index Anomaly (FAI)' if \"abi\" in file_path else 'Normalized Floating Algae Index (NFAI)'\n",
    "    title = 'FAI anomaly across the selected region on ' if \"abi\" in file_path else 'NFAI across the selected region on '\n",
    "    \n",
    "    # Extract relevant data (NFAI or FAI anomaly)\n",
    "    index_data = data[index_key]\n",
    "\n",
    "    # Set non-positive values to a very small negative number, close to zero\n",
    "    index_data = xr.where(index_data > 0, index_data, -0.1)\n",
    "    \n",
    "    # Set up a plot with geographic projections\n",
    "    fig, ax = plt.subplots(figsize=(12, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    \n",
    "    # Customize the map with coastlines and features\n",
    "    ax.coastlines(resolution='10m', color='black')\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
    "\n",
    "    # Adding grid lines and disabling labels on the top and right\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "\n",
    "    # Plot the data with the modified contrast\n",
    "    im = index_data.plot(ax=ax, x='longitude', y='latitude', transform=ccrs.PlateCarree(),\n",
    "                         cmap=color, add_colorbar=True, extend='both',\n",
    "                         vmin=-0.01, vmax=vmax,  # Here we set the scale to max out at 0.5\n",
    "                         cbar_kwargs={'shrink': 0.35})\n",
    "\n",
    "    # Add color bar details\n",
    "    im.colorbar.set_label(colorbar_label)\n",
    "    \n",
    "    # Show the plot with title\n",
    "    plt.title(title + str(data.time.values[0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858c29fa-21c4-45e5-95d4-46511ac87d3a",
   "metadata": {},
   "source": [
    "## visualize_aggregate\n",
    "We should first write a function **(very similar to visualize_5, maybe we should make it use visualize_5)** to visualize the aggregate motion of the algae, this function would take the aggregate_data we're going to calculate as argument instead of the path to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab5271e3-427a-4ccb-88c8-bc575718a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_aggregate(aggregate_data, lat_range=None, lon_range=None, color=\"viridis\", vmax=0.001, threshold=0, output_filepath=None, filter_clouds=True):\n",
    "    # Select the desired subset\n",
    "    if lat_range:\n",
    "        aggregate_data = aggregate_data.sel(latitude=slice(*lat_range))\n",
    "    if lon_range:\n",
    "        aggregate_data = aggregate_data.sel(longitude=slice(*lon_range))\n",
    "    \n",
    "    # If filtering clouds, set NaN values to -0.1\n",
    "    if filter_clouds:\n",
    "        aggregate_data = xr.where(np.isnan(aggregate_data), -0.1, aggregate_data)\n",
    "    \n",
    "    # Set up a plot with geographic projections\n",
    "    fig, ax = plt.subplots(figsize=(12, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    \n",
    "    # Customize the map with coastlines and features\n",
    "    ax.coastlines(resolution='10m', color='black')\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
    "\n",
    "    # Adding grid lines and disabling labels on the top and right\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "\n",
    "    # Plot the aggregate data with the specified color, vmax, and threshold\n",
    "    im = aggregate_data.plot(ax=ax, x='longitude', y='latitude', transform=ccrs.PlateCarree(),\n",
    "                             cmap=color, add_colorbar=True, extend='both',\n",
    "                             vmin=threshold, vmax=vmax, cbar_kwargs={'shrink': 0.35})\n",
    "\n",
    "    # Add color bar details\n",
    "    colorbar_label = 'Aggregate Floating Algae Index (FAI)' \n",
    "    im.colorbar.set_label(colorbar_label)\n",
    "    \n",
    "    # Show the plot with title\n",
    "    plt.title(\"Aggregate Algae Distribution on 2022-07-24\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664153de-91de-4d41-a70d-7fc7d8fa6301",
   "metadata": {},
   "source": [
    "## save_as_netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c04d002a-5745-4c5d-8ba5-ff689554cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_netcdf(dataset, output_filepath):\n",
    "    \"\"\"\n",
    "    Save the given Dataset to a NetCDF file.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset (Dataset): The xarray Dataset to save.\n",
    "    - output_filepath (str): The path to the output NetCDF file.\n",
    "    \"\"\"\n",
    "    dataset.to_netcdf(output_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce78532-7272-4ce6-b417-a009e0adc24b",
   "metadata": {},
   "source": [
    "We obtain what appear to be the same results whether we calculate the median on the whole image, then zoom in, or zoom in then calculate it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e8844d-4431-45da-be14-02ccdf2b251e",
   "metadata": {},
   "source": [
    "## Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf265e5a-ac83-4d79-92d7-daf2b36514e8",
   "metadata": {},
   "source": [
    "### calculate_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27c0a36d-8a21-4a85-a801-38c0cb8e4eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_median(time_list, lat_range=None, lon_range=None, threshold=0):\n",
    "    \"\"\"\n",
    "    Calculate the median of algae presence over a given time range based on a list of times,\n",
    "    within specified latitude and longitude ranges.\n",
    "\n",
    "    Parameters:\n",
    "    - time_list (list of str): List of formatted datetime strings in the format 'YYYYMMDD_HH-MM'.\n",
    "    - lat_range (tuple): Tuple of (min_latitude, max_latitude).\n",
    "    - lon_range (tuple): Tuple of (min_longitude, max_longitude).\n",
    "    - threshold (float): The threshold above which data is considered.\n",
    "\n",
    "    Returns:\n",
    "    - median_algae_distribution (DataArray): The median algae distribution within the specified region.\n",
    "    \"\"\"\n",
    "    aggregate_data_list = []\n",
    "\n",
    "    # Loop over each time in the time list, loading the data and adding it to the list\n",
    "    for time_str in time_list:\n",
    "        file_path = f\"/media/yahia/ballena/CLS/abi-goes-global-hr/cls-abi-goes-global-hr_1d_{time_str}.nc\"\n",
    "        # Skip if the file does not exist\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Skipping: {file_path} does not exist.\")\n",
    "            continue\n",
    "        \n",
    "        data = xr.open_dataset(file_path)\n",
    "\n",
    "        # Apply latitude and longitude ranges if specified\n",
    "        if lat_range:\n",
    "            data = data.sel(latitude=slice(*lat_range))\n",
    "        if lon_range:\n",
    "            data = data.sel(longitude=slice(*lon_range))\n",
    "\n",
    "        # Extract the index of interest and drop the 'time' coordinate\n",
    "        algae_data = data['fai_anomaly'].squeeze(drop=True)\n",
    "\n",
    "        # Mask the data to include only algae (values greater than the threshold)\n",
    "        algae_masked = algae_data.where(algae_data > threshold)\n",
    "\n",
    "        # Add the masked data to our list (each element in this list is the data array, after processing, for the give time)\n",
    "        aggregate_data_list.append(algae_masked)\n",
    "\n",
    "    # Combine the data along a new dimension, then calculate the mean along that dimension\n",
    "    # Note: Xarray's mean function by default ignores nan values\n",
    "    aggregate_data = xr.concat(aggregate_data_list, dim='new_dim')\n",
    "    median_algae_distribution = aggregate_data.median(dim='new_dim')\n",
    "\n",
    "    # Extract the date from the first time string and set it as an attribute (Used for the figure title)\n",
    "    date_from_time = time_list[0].split('_')[0]  # Assuming time_list items are 'YYYYMMDD_HH-MM'\n",
    "    median_algae_distribution.attrs['date'] = date_from_time\n",
    "\n",
    "    return median_algae_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144d65fd-af0c-4380-ae2a-98a85aac3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Generating the time list\n",
    "    times = time_list(start_time=datetime(2022, 7, 24, 12, 0), end_time=datetime(2022, 7, 24, 18, 50), interval=10)\n",
    "    \n",
    "    # Calculating the median data for this time period\n",
    "    median_algae_distribution = calculate_median(times,lat_range=(14, 15), lon_range= (-66, -65))\n",
    "    \n",
    "    # Calculating the aggregate data for this time period\n",
    "    average_algae_distribution = calculate_mean(times,lat_range=(12, 17), lon_range=(-67, -60))\n",
    "    \n",
    "    #Visualizing the result and comparing it to the mean \n",
    "    visualize_aggregate(median_algae_distribution, (14, 15), (-66, -65), color=\"viridis\", vmax=0.001, threshold=0)\n",
    "    visualize_aggregate(average_algae_distribution, (12, 17), (-67, -60), color=\"viridis\", vmax=0.001, threshold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad301a10-e925-4281-b28c-fee475b85ec4",
   "metadata": {},
   "source": [
    "Although the difference is not very big, it is non negligible and we can see that median function produces rafts that are a bit thinner, which is preferable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4ff38c-e41f-4c79-87c2-2d01fd357eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':#\n",
    "    # Generating the time list\n",
    "    times = time_list(start_time=datetime(2022, 7, 24, 12, 0), end_time=datetime(2022, 7, 24, 18, 50), interval=10)\n",
    "    \n",
    "    # Calculating the min data for this time period\n",
    "    min_algae_distribution = calculate_min(times,lat_range=(12, 17), lon_range=(-67, -60))\n",
    "    \n",
    "    # Calculating the mean data for this time period\n",
    "    average_algae_distribution = calculate_mean(times,lat_range=(12, 17), lon_range=(-67, -60))\n",
    "    \n",
    "    #Visualizing the result and comparing it to the mean\n",
    "    visualize_aggregate(min_algae_distribution, (12, 17), (-67, -60), color=\"viridis\", vmax=0.001, threshold=0)\n",
    "    visualize_aggregate(average_algae_distribution, (12, 17), (-67, -60), color=\"viridis\", vmax=0.001, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2495f724-5c1e-4f4c-baeb-dad9b74e9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec4c2b32-6bbe-4370-9f3f-fec4f122fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_median_n(times, lat_range=None, lon_range=None, threshold=0):\n",
    "    \"\"\"\n",
    "    Calculate the median of algae presence over a given time range based on a list of times,\n",
    "    within specified latitude and longitude ranges.\n",
    "\n",
    "    Parameters:\n",
    "    - time_list (list of str): List of formatted datetime strings in the format 'YYYYMMDD_HH-MM'.\n",
    "    - lat_range (tuple): Tuple of (min_latitude, max_latitude).\n",
    "    - lon_range (tuple): Tuple of (min_longitude, max_longitude).\n",
    "    - threshold (float): The threshold above which data is considered.\n",
    "\n",
    "    Returns:\n",
    "    - median_dataset (Dataset): The median algae distribution within the specified region.\n",
    "    \"\"\"\n",
    "    aggregate_data_list = []\n",
    "\n",
    "    # Loop over each time in the time list, loading the data and adding it to the list\n",
    "    for time_str in times:\n",
    "        file_path = f\"/media/yahia/ballena/CLS/abi-goes-global-hr/cls-abi-goes-global-hr_1d_{time_str}.nc\"\n",
    "        # Skip if the file does not exist\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Skipping: {file_path} does not exist.\")\n",
    "            continue\n",
    "        \n",
    "        data = xr.open_dataset(file_path)\n",
    "\n",
    "        # Apply latitude and longitude ranges if specified\n",
    "        if lat_range:\n",
    "            data = data.sel(latitude=slice(*lat_range))\n",
    "        if lon_range:\n",
    "            data = data.sel(longitude=slice(*lon_range))\n",
    "\n",
    "        # Extract the index of interest and drop the 'time' coordinate\n",
    "        algae_data = data['fai_anomaly'].squeeze(drop=True)\n",
    "\n",
    "        # Mask the data to include only algae (values greater than the threshold)\n",
    "        algae_masked = algae_data.where(algae_data > threshold)\n",
    "\n",
    "        # Add the masked data to our list (each element in this list is the data array, after processing, for the give time)\n",
    "        aggregate_data_list.append(algae_masked)\n",
    "\n",
    "    # Combine the data along a new dimension, then calculate the median along that dimension\n",
    "    # Note: Xarray's median function by default ignores nan values\n",
    "    aggregate_data = xr.concat(aggregate_data_list, dim='new_dim')\n",
    "    median_algae_distribution = aggregate_data.median(dim='new_dim')\n",
    "\n",
    "    # Create a new Dataset to include latitude and longitude\n",
    "    median_dataset = xr.Dataset({\n",
    "        'median_fai_anomaly': median_algae_distribution\n",
    "    }, coords={\n",
    "        'latitude': median_algae_distribution.latitude,\n",
    "        'longitude': median_algae_distribution.longitude\n",
    "    })\n",
    "\n",
    "    # Extract the date from the first time string and set it as an attribute (Used for the figure title)\n",
    "    date_from_time = times[0].split('_')[0]  # Assuming time_list items are 'YYYYMMDD_HH-MM'\n",
    "    median_dataset.attrs['date'] = date_from_time\n",
    "\n",
    "    return median_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343f103-7efb-4e14-80b5-1bbe2c876c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    # Generating the time list\n",
    "    times = time_list(start_time=datetime(2022, 7, 24, 12, 0), end_time=datetime(2022, 7, 24, 18, 50), interval=10)\n",
    "    \n",
    "    # Calculate median\n",
    "    median_dataset = calculate_median(times, lat_range=(12, 17), lon_range=(-67, -60), threshold=0)\n",
    "    \n",
    "    # Save to NetCDF\n",
    "    output_filepath = '/home/yahia/Documents/Jupyter/Sargassum/median_algae_distribution.nc'\n",
    "    save_as_netcdf(median_dataset, output_filepath)\n",
    "    \n",
    "    print(f\"Median algae distribution saved to {output_filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
