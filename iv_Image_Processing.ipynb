{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9503bf90-be3f-4e58-a5c0-64a4530c7ee6",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "Using the results of the previous notebook, we're going to try to use the OpenCV library to process the images and save them so we can then apply our motion estimation algorithms to ABI-GOES aggregate images over a certain period of time (10 days perhaps)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486cb3ae-e170-477a-a648-dd35b80b2096",
   "metadata": {},
   "source": [
    "## Importing necessary libraries and notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d65db229-94b9-4d4a-9d13-0ae51953bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b30506ff-412b-4471-a57c-269137d2e2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import ticker\n",
    "from IPython.display import Image, display, HTML\n",
    "from multiprocessing import Pool\n",
    "from scipy.ndimage import label\n",
    "import mplcursors\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Import the other notebooks without running their cells\n",
    "from ii_Data_Manipulation import visualize_4\n",
    "from iii_GOES_average import time_list, visualize_aggregate, calculate_median, split_and_aggregate_median, save_as_netcdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e2465b-a0ec-4c11-9d50-da51ec7fe9ed",
   "metadata": {},
   "source": [
    "## Preparing the Images\n",
    "We're going to work on 10 images obtained from averaging all ABI-GOES images for a given day. First, we need to average the images for each day and then save them to our hard drive.\n",
    "\n",
    "One challenge is that acquisitions don't start and end at the same time for each day (acquisitions start at 12:00 for 2022/07/24 for example), so we need to be able to collect a list of the times at which we have data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fafb31-72eb-4468-b4dd-cdd8e811a044",
   "metadata": {},
   "source": [
    "### *collect_times*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc2aef99-4bfc-493e-b59b-6e9f2d473a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_times(date, directory):\n",
    "    \"\"\" Collect the earliest and latest acquisition times for a given date from file names. \"\"\"\n",
    "    prefix = f\"cls-abi-goes-global-hr_1d_{date}\"\n",
    "    files = [f for f in os.listdir(directory) if f.startswith(prefix)]\n",
    "    times = [f.split('_')[-1].split('.')[0] for f in files]  # Assumes files are named '..._HH-MM.nc'\n",
    "    if times:\n",
    "        return min(times), max(times)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9548f1-9c30-4226-b59b-6c4b9d50b818",
   "metadata": {},
   "source": [
    "### *save_aggregate*\n",
    "Because we've encountered bugs and stack overflow when we tried to modify the function of notebook 3 by adding an optional parameter (**output_filepath**=None), which if specified saves the figure instead of showing it (and removes the legend), we've decided instead to write a new function here **save_aggregate** that can also display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1dc050-f434-415e-8a9c-0daec7b77bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_aggregate(aggregate_data, lat_range=None, lon_range=None, color=\"viridis\", vmax=0.001, threshold=0.0001, output_filepath=None, netcdf_filepath=None, filter_clouds=True, display=False):\n",
    "    # Select the desired subset\n",
    "    if lat_range:\n",
    "        aggregate_data = aggregate_data.sel(latitude=slice(*lat_range))\n",
    "    if lon_range:\n",
    "        aggregate_data = aggregate_data.sel(longitude=slice(*lon_range))\n",
    "\n",
    "    # If filtering clouds, set NaN values to zero\n",
    "    if filter_clouds:\n",
    "        aggregate_data = xr.where(np.isnan(aggregate_data), 0, aggregate_data)\n",
    "\n",
    "    # Set up a plot with geographic projections\n",
    "    fig, ax = plt.subplots(figsize=(12, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    \n",
    "    # Customize the map with coastlines and features\n",
    "    ax.coastlines(resolution='10m', color='black', visible=True)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':', visible=True)\n",
    "    ax.add_feature(cfeature.LAND, facecolor='lightgray', visible=True)\n",
    "\n",
    "    # Show gridlines only when visualizing interactively\n",
    "    if display:\n",
    "        gl = ax.gridlines(draw_labels=True, linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        cbar_kwargs = {'shrink': 0.35}\n",
    "    else:\n",
    "        cbar_kwargs = None\n",
    "\n",
    "    # Plot the aggregate data with the specified color, vmax, and threshold\n",
    "    im = aggregate_data.plot(ax=ax, x='longitude', y='latitude', transform=ccrs.PlateCarree(),\n",
    "                             cmap=color, add_colorbar=display,\n",
    "                             vmin=threshold, vmax=vmax, cbar_kwargs=cbar_kwargs)\n",
    "\n",
    "    # Set title and colorbar only when visualizing interactively\n",
    "    if display:\n",
    "        im.colorbar.set_label('Aggregate Floating Algae Index (FAI)')\n",
    "        plot_date = aggregate_data.attrs.get('date', 'Unknown Date')\n",
    "        plt.title(f\"Aggregate Algae Distribution on {plot_date}\")\n",
    "        plt.show()\n",
    "\n",
    "    if output_filepath:\n",
    "        plt.savefig(output_filepath)  \n",
    "        plt.close(fig)\n",
    "\n",
    "    # Save the data as a NetCDF file if a filepath is provided\n",
    "    if netcdf_filepath:\n",
    "        # Create a new Dataset to include latitude and longitude\n",
    "        dataset = xr.Dataset({\n",
    "            'fai_anomaly': aggregate_data\n",
    "        }, coords={\n",
    "            'latitude': aggregate_data.latitude,\n",
    "            'longitude': aggregate_data.longitude\n",
    "        })\n",
    "        dataset.to_netcdf(netcdf_filepath)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae94ba0-04c6-4e86-a620-19761912b5f8",
   "metadata": {},
   "source": [
    "We have the option to get the raw average (without the mask for the land) or to mask the land and we should test both images to see which is best for the OF algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dc6aa7-20e7-4102-b29b-1691cb4e5ebc",
   "metadata": {},
   "source": [
    "### *process_dates*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a52bd4d-b580-4d2b-b950-3075f3cf992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dates(start_date, end_date, directory, output_dir, lat_range=None, lon_range=None, color=\"viridis\", save_image=True, save_netcdf=False):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Convert the start and end dates from strings to datetime objects\n",
    "    current_date = datetime.strptime(start_date, '%Y%m%d')\n",
    "    end_date = datetime.strptime(end_date, '%Y%m%d')\n",
    "    \n",
    "    while current_date <= end_date:\n",
    "        # Format the current date as a string in 'YYYYMMDD' format\n",
    "        date_str = current_date.strftime('%Y%m%d')\n",
    "        \n",
    "        # Discover the start and end times of image acquisition on the current day by scanning the directory\n",
    "        times = collect_times(date_str, directory)\n",
    "        \n",
    "        if times:\n",
    "            # Create a list of timestamps for the day using the discovered start and end times\n",
    "            times_for_day = time_list(\n",
    "                datetime.strptime(date_str + '_' + times[0], '%Y%m%d_%H-%M'),\n",
    "                datetime.strptime(date_str + '_' + times[1], '%Y%m%d_%H-%M'), \n",
    "                10  # Interval between images in minutes\n",
    "            )\n",
    "            \n",
    "            # Calculate the median distribution of algae based on the list of timestamps\n",
    "            median_distribution = calculate_median(times_for_day, lat_range, lon_range)\n",
    "            \n",
    "            # Prepare the output file paths for the current day's visualization and NetCDF file\n",
    "            output_image_path = os.path.join(output_dir, f'algae_distribution_{date_str}.png') if save_image else None\n",
    "            output_netcdf_path = os.path.join(output_dir, f'algae_distribution_{date_str}.nc') if save_netcdf else None\n",
    "            \n",
    "            # Visualize the median algae distribution and save it as both an image and NetCDF file (if the optional parameters are provided)\n",
    "            save_aggregate(median_distribution, lat_range, lon_range, color=color, output_filepath=output_image_path, netcdf_filepath=output_netcdf_path, display=False)\n",
    "        \n",
    "        # Increment the current date by one day\n",
    "        current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fc9de9-92dc-4fe8-b29f-300562d18583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = '20220723'\n",
    "# end_date = '20220724'\n",
    "# directory = '/media/yahia/ballena/CLS/abi-goes-global-hr' \n",
    "# output_directory = '/home/yahia/Documents/Jupyter/Sargassum/Images/Test/ABI_Averages' \n",
    "# lat_range = (12, 17)  \n",
    "# lon_range = (-67, -60) \n",
    "\n",
    "# # Call the function\n",
    "# process_dates(start_date, end_date, directory, output_directory, lat_range, lon_range, save_image=True, save_netcdf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf28ce06-2c61-4899-ac41-d214287435ce",
   "metadata": {},
   "source": [
    "If we look at the images, we can see that some of them are covered by clouds which makes detecting the algae impossible. A solution we could implement is to use the OLCI images (if they're more clear) and add them to the ABI aggregates (using OpenCV's **OR** operator for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0862b-029e-4353-be42-89588ea1a313",
   "metadata": {},
   "source": [
    "### *plot_xarray*\n",
    "Takes as input an xarray and outputs an interactive graph where you can hover over the pixels to get the corresponding value. Useful for debugging and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8518a56b-d175-4b82-8023-33018abe55d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_xarray(xarray_dataset, variable_name=\"fai_anomaly\", title='Interactive Plot', xlabel='Longitude Index', ylabel='Latitude Index', cmap='viridis'):\n",
    "    \"\"\"\n",
    "    Plot the specified variable from the given xarray dataset interactively.\n",
    "    \n",
    "    Parameters:\n",
    "    xarray_dataset (xr.Dataset): The xarray dataset containing the data to plot.\n",
    "    variable_name (str): The name of the variable to plot.\n",
    "    title (str): The title of the plot.\n",
    "    xlabel (str): The label for the x-axis.\n",
    "    ylabel (str): The label for the y-axis.\n",
    "    cmap (str): The colormap to use for the plot.\n",
    "    \"\"\"\n",
    "    %matplotlib widget\n",
    "    \n",
    "    xarray_data = xarray_dataset[variable_name]\n",
    "    \n",
    "    def plot_data(x=0, y=0):\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        im = ax.imshow(xarray_data, origin='lower', cmap=cmap)\n",
    "        \n",
    "        # Title and labels\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        \n",
    "        # Text annotation for displaying value under cursor\n",
    "        text = ax.text(0, 0, '', va='bottom', ha='left')\n",
    "        \n",
    "        def onclick(event):\n",
    "            # Get the x and y pixel coords\n",
    "            ix, iy = int(event.xdata + 0.5), int(event.ydata + 0.5)\n",
    "            value = xarray_data.isel(longitude=ix, latitude=iy).values\n",
    "            text.set_text(f'Value: {value}')\n",
    "            text.set_position((ix, iy))\n",
    "        \n",
    "        fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "    \n",
    "    interact(plot_data, x=(0, xarray_data.shape[1] - 1), y=(0, xarray_data.shape[0] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a463b6b-aeb8-403f-b1a9-cc7116100797",
   "metadata": {},
   "source": [
    "### Image Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028e348-364f-42cd-a46b-fcecdbc139be",
   "metadata": {},
   "source": [
    "#### *plot_interactive_image*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9542e36b-479d-4b8d-b282-cdad7df7bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interactive_image(image):\n",
    "    height, width = image.shape\n",
    "\n",
    "    # Create x and y coordinates for each pixel\n",
    "    x = np.arange(width)\n",
    "    y = np.arange(height)\n",
    "\n",
    "    # Create a meshgrid for pixel coordinates\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "    # Flatten the arrays for use in scatter plot\n",
    "    x_flat = xx.flatten()\n",
    "    y_flat = yy.flatten()\n",
    "    img_flat = image.flatten()\n",
    "\n",
    "    # Create a Plotly figure\n",
    "    fig = go.Figure(data=go.Scatter(\n",
    "        x=x_flat,\n",
    "        y=y_flat,\n",
    "        mode='markers',\n",
    "        marker=dict(size=1, opacity=0),  # Invisible markers but with hover info\n",
    "        text=[f\"Pixel value: {v}\" for v in img_flat],\n",
    "        hoverinfo=\"text\"\n",
    "    ))\n",
    "\n",
    "    # Add image trace\n",
    "    fig.add_trace(go.Image(z=image))\n",
    "\n",
    "    # Update layout to remove axes and provide a title\n",
    "    fig.update_layout(\n",
    "        title=\"Interactive Image Plot\",\n",
    "        xaxis_showgrid=False,\n",
    "        yaxis_showgrid=False,\n",
    "        xaxis_zeroline=False,\n",
    "        yaxis_zeroline=False,\n",
    "        xaxis_visible=False,\n",
    "        yaxis_visible=False,\n",
    "        width=800,\n",
    "        height=800,\n",
    "        hovermode='closest'\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c32604-fd5a-4637-9b88-65d10683649f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from plotly.offline import init_notebook_mode\n",
    "# init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34a3ae10-e922-4440-a2d3-5502a22d26f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     source_path = '/home/yahia/Documents/Jupyter/Sargassum/Images/Sub-Daily/median_20220724_12-14.nc'\n",
    "#     lat_range = (12, 17)  \n",
    "#     lon_range = (-67, -60)\n",
    "    \n",
    "#     # Read the NetCDF file\n",
    "#     dataset = xr.open_dataset(source_path)\n",
    "    \n",
    "#     # Apply geographic slicing \n",
    "#     if lat_range and 'latitude' in dataset.coords:\n",
    "#         dataset = dataset.sel(latitude=slice(*lat_range))\n",
    "#     if lon_range and 'longitude' in dataset.coords:\n",
    "#         dataset = dataset.sel(longitude=slice(*lon_range))\n",
    "        \n",
    "#     # Extract the only variable in the dataset\n",
    "#     variable_name = list(dataset.data_vars)[0]\n",
    "#     data = dataset[variable_name].values\n",
    "\n",
    "#     # Ensure the data is 2D (grayscale image)\n",
    "#     if len(data.shape) == 3:\n",
    "#         data = data[0]  # Assuming the data is 3D and taking the first slice\n",
    "\n",
    "#     # Convert the data to an 8-bit image\n",
    "#     image = cv2.normalize(data, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "#     image = binarize_image(image, threshold = 5)\n",
    "    \n",
    "#     # Flip the image vertically\n",
    "#     image = cv2.flip(image, 0)\n",
    "\n",
    "#     # Save the image to a PNG file\n",
    "#     output_path = '/home/yahia/Documents/Jupyter/Sargassum/Images/Sub-Daily/median_20220724_12-14.png'  # Update the path as needed\n",
    "#     cv2.imwrite(output_path, image)\n",
    "\n",
    "#     print(f\"Image saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181597c0-7f45-4f96-ad24-f32ba259eb20",
   "metadata": {},
   "source": [
    "#### *display_image_mpl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84b8fcf-9a2c-43db-98f7-0cf62ff4a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_mpl(image_array, scale=1):\n",
    "    \"\"\"\n",
    "    Displays an image using matplotlib. Converts from BGR to RGB if needed and handles both grayscale and color images.\n",
    "    Allows specification of the display size.\n",
    "\n",
    "    Parameters:\n",
    "    - image_array (numpy array): The image data array. It can be in grayscale or BGR color format.\n",
    "    - width (float): Width of the figure in inches.\n",
    "    - height (float): Height of the figure in inches.\n",
    "    \"\"\"\n",
    "    # Check if image is in color (BGR format), and convert to RGB for display\n",
    "    if len(image_array.shape) == 3 and image_array.shape[2] == 3:\n",
    "        image_array = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Create a figure with specified size\n",
    "    plt.figure(figsize=(8*scale, 6*scale))\n",
    "    \n",
    "    # Determine if the image is grayscale and display it\n",
    "    if len(image_array.shape) == 2 or image_array.shape[2] == 1:\n",
    "        plt.imshow(image_array, cmap='gray')  # Display grayscale image\n",
    "    else:\n",
    "        plt.imshow(image_array)  # Display color image\n",
    "    \n",
    "    # Hide axes and show the figure\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a490461e-4683-43bb-9a09-a55dacef9ec7",
   "metadata": {},
   "source": [
    "#### *crop_image*\n",
    "Let's write a function to crop images so as to remove the white space from the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8778671-cb6d-4fd0-b808-c855793e2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image):\n",
    "    # Convert to grayscale if it is a color image\n",
    "    if len(image.shape) == 3:\n",
    "        gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_img = image\n",
    "\n",
    "    # Threshold the image to isolate the content\n",
    "    _, thresh = cv2.threshold(gray_img, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find contours from the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the largest contour which will encompass the area of interest\n",
    "        c = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Get the bounding rectangle of the largest contour\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        \n",
    "        # Crop the original image using the dimensions of the bounding rectangle\n",
    "        cropped_img = image[y:y+h, x:x+w]\n",
    "        return cropped_img\n",
    "    else:\n",
    "        print(\"No significant contours found.\")\n",
    "        return image  # Return original image if no contours were found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c1bf9-5f8d-4c07-b546-6fdde84c5ede",
   "metadata": {},
   "source": [
    "#### *binarize_image*\n",
    "Binarizing the images (indicating the presence of algae by absolute black and the rest by white) might be beneficial for our Optical Flow algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97fc3a38-712e-46dc-b2af-1b1b927c223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_image(image, threshold):\n",
    "    # Ensure the image is grayscale\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply binary thresholding\n",
    "    _, binary_image = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY)\n",
    "    return binary_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1cb3a0-e107-412e-95ce-cfd9b6984fea",
   "metadata": {},
   "source": [
    "#### *bilateral_image*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8277a28-8157-489d-a898-d0be83efe6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilateral_image(image, diameter=9, sigmaColor=75, sigmaSpace=75):\n",
    "    \"\"\"\n",
    "    Apply a bilateral filter to an image to reduce noise while keeping edges sharp.\n",
    "    \n",
    "    Parameters:\n",
    "    - diameter (int): Diameter of each pixel neighborhood that is used during filtering.\n",
    "                      If it is non-positive, it is computed from sigmaSpace.\n",
    "    - sigmaColor (float): Filter sigma in the color space. A larger value of the parameter\n",
    "                          means that farther colors within the pixel neighborhood (see sigmaSpace)\n",
    "                          will be mixed together, resulting in larger areas of semi-equal color.\n",
    "    - sigmaSpace (float): Filter sigma in the coordinate space. A larger value of the parameter\n",
    "                          means that farther pixels will influence each other as long as their\n",
    "                          colors are close enough (see sigmaColor). When d>0, it specifies the\n",
    "                          neighborhood size regardless of sigmaSpace. Otherwise, d is proportional\n",
    "                          to sigmaSpace.\n",
    "\n",
    "    Returns:\n",
    "    - filtered_image (ndarray): The image after applying the bilateral filter.\n",
    "    \"\"\"\n",
    "    bilateral = cv2.bilateralFilter(image, diameter, sigmaColor, sigmaSpace)\n",
    "    return bilateral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7677def9-8695-4a79-b5b7-20104acd5439",
   "metadata": {},
   "source": [
    "#### *filter_by_size*\n",
    "This function filters out the small sargassum aggregates which might be noise.\n",
    "\n",
    "**The smaller the threshold is, the slower it is. No longer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d4b7cf6-ce63-4ac3-bf68-42bbd850e37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_size(image, size_threshold):\n",
    "    if len(image.shape) != 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=8)\n",
    "    valid_labels = [i for i in range(1, num_labels) if stats[i, cv2.CC_STAT_AREA] >= size_threshold]\n",
    "    \n",
    "    filtered_image = np.isin(labels, valid_labels).astype(np.uint8) * 255\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c239ed-e143-40e6-bb26-ba9944e4af93",
   "metadata": {},
   "source": [
    "#### *adaptive_filter_by_size*\n",
    "Applies a different size threshold above a certain latitude (usually 30° N). This is done to filter more detections which are probably noise (in the north) and not filter out too much the the areas where there are genuine detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8883e83-c0e4-49d4-be8f-ff39d48d3e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_filter_by_size(dataset, base_threshold, higher_threshold, latitude_limit=30):\n",
    "    \"\"\"\n",
    "    Filters image components by size using xarray, applying a higher threshold for regions with latitude > 30.\n",
    "\n",
    "    Args:\n",
    "    dataset (xarray.Dataset): The input dataset containing the image data and latitude coordinate.\n",
    "    base_threshold (int): The base threshold for the area of connected components.\n",
    "    higher_threshold (int): The threshold for areas with latitude > latitude_limit.\n",
    "    latitude_limit (float): The latitude above which the higher threshold is applied.\n",
    "\n",
    "    Returns:\n",
    "    xarray.Dataset: The dataset with the image data filtered by size.\n",
    "    \"\"\"\n",
    "    # Ensure dataset has 'latitude' coordinate\n",
    "    if 'latitude' not in dataset.coords:\n",
    "        raise ValueError(\"Dataset must have 'latitude' as a coordinate\")\n",
    "\n",
    "    # Convert the data array to a numpy array\n",
    "    image = dataset.to_array().values.squeeze()\n",
    "\n",
    "    # Convert image to grayscale if it is not already\n",
    "    if len(image.shape) != 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Label the connected components\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(image.astype(np.uint8), connectivity=8)\n",
    "\n",
    "    # Create an empty array to store the filtered image\n",
    "    filtered_image = np.zeros_like(image, dtype=np.uint8)\n",
    "\n",
    "    # Iterate over each component\n",
    "    for i in range(1, num_labels):\n",
    "        # Component stats\n",
    "        _, y, _, h, area = stats[i]\n",
    "        # Determine the latitude at the component's centroid\n",
    "        centroid_latitude = dataset.latitude[y + h // 2].values\n",
    "\n",
    "        # Apply thresholds based on latitude\n",
    "        effective_threshold = higher_threshold if centroid_latitude > latitude_limit else base_threshold\n",
    "        if area >= effective_threshold:\n",
    "            filtered_image[labels == i] = 255\n",
    "\n",
    "    # Convert the numpy array back to an xarray DataArray\n",
    "    filtered_da = xr.DataArray(filtered_image, dims=dataset.dims, coords=dataset.coords)\n",
    "\n",
    "    return filtered_da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43de773-ecce-44b1-9335-8f5b9eb11cad",
   "metadata": {},
   "source": [
    "#### *adaptive_filter*\n",
    "Applies a filter based on local densities (the areas with more detections will be filtered less)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496daadf-b1c4-4501-a1ba-21fe4aa2532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_filter(image, adaptive_base_threshold, window_size=10, density_scale_factor=1.5):\n",
    "    \"\"\"\n",
    "    Adaptive filtering based on local densities.\n",
    "\n",
    "    Args:\n",
    "    image (numpy.ndarray): The input binary image.\n",
    "    adaptive_base_threshold (int): The base threshold for the area of connected components.\n",
    "    window_size (int): The size of the window to calculate local densities.\n",
    "    density_scale_factor (float): Factor to scale the base threshold based on local density.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The filtered image.\n",
    "    \"\"\"\n",
    "    if len(image.shape) != 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate local density of detections\n",
    "    kernel = np.ones((window_size, window_size), np.uint8)\n",
    "    local_density = cv2.filter2D((image > 0).astype(np.uint8), -1, kernel) / (window_size**2)\n",
    "\n",
    "    # Prepare output image\n",
    "    output_image = np.zeros_like(image)\n",
    "\n",
    "    # Label connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=8)\n",
    "\n",
    "    # Process each component\n",
    "    for i in range(1, num_labels):\n",
    "        # Get the component's stats\n",
    "        x, y, w, h, area = stats[i]\n",
    "\n",
    "        # Calculate adaptive threshold for the component\n",
    "        local_density_mean = np.mean(local_density[y:y+h, x:x+w])\n",
    "        adaptive_threshold = adaptive_base_threshold * (1 + local_density_mean * density_scale_factor)\n",
    "\n",
    "        # Filter based on adaptive threshold\n",
    "        if area >= adaptive_threshold:\n",
    "            component_mask = (labels == i)\n",
    "            output_image[component_mask] = 255\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2db0731-9507-4362-9ba4-d1272e39250a",
   "metadata": {},
   "source": [
    "#### *opening*\n",
    "An *erosion* followed by a *dilation*: first an erosion is applied to remove the small blobs, then a dilation is applied to regrow the size of the original object.\n",
    "\n",
    "We can change the kernel_size as well as the kernel_shape. Increasing the kernel_size, increase the \"aggression\" of the filter while changing the kernel_shape didn't make much of a visible difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ad7b5-e37b-402e-af16-09dc7587de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opening(image, kernel_size=3, kernel_shape=cv2.MORPH_RECT):\n",
    "    # Convert to grayscale if the image is in color\n",
    "    if len(image.shape) != 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Create the structuring element (kernel)\n",
    "    if kernel_shape == 'ellipse':\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    elif kernel_shape == 'cross':\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (kernel_size, kernel_size))\n",
    "    else:\n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "\n",
    "    # Apply the morphological opening\n",
    "    opened_image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    return opened_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c7de52-139f-45a4-8b13-9cd7f6a7d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Opening Test\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Paths\n",
    "#     source_path = \"/media/yahia/ballena/ABI/NetCDF/Atlantic/Averages/algae_distribution_20220723.nc\"\n",
    "#     dest_path = '/home/yahia/Documents/Jupyter/Sargassum/Images/Test/Opening_20220723.nc'\n",
    "    \n",
    "#     # Process the directory\n",
    "#     process_netCDF(source_path, dest_path, threshold=1, bilateral=False, binarize=True, negative=False, median=False,\n",
    "#                    filter_small=True, size_threshold=10, opened=True, kernel_size=2, land_mask=False, coast_mask=False, coast_threshold=50000)\n",
    "#     # NOTE: if you get permission denied, don't forget to close ncviewer first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cd0323-537f-4eda-807f-d45db610fbd3",
   "metadata": {},
   "source": [
    "The following function is used to create a NetCDF that will be used for mask_coast. (One-time use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d153e77-1087-488d-89d3-021529a461d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_reduced_netcdf(input_file, output_file):\n",
    "#     # Load the original dataset\n",
    "#     ds = xr.open_dataset(input_file)\n",
    "    \n",
    "#     # Extract the latitude and longitude values from gphit and glamt\n",
    "#     latitude = ds['gphit'].values[:, 0]  # Assuming latitude varies along the first dimension\n",
    "#     longitude = ds['glamt'].values[0, :]  # Assuming longitude varies along the second dimension\n",
    "    \n",
    "#     # Ensure unique and sorted values for coordinates\n",
    "#     latitude = np.unique(latitude)\n",
    "#     longitude = np.unique(longitude)\n",
    "    \n",
    "#     # Create a new DataArray for Distcoast with the new coordinates\n",
    "#     distcoast = xr.DataArray(ds['Distcoast'].values, dims=('latitude', 'longitude'), coords={'latitude': latitude, 'longitude': longitude})\n",
    "    \n",
    "#     # Create a new dataset\n",
    "#     new_ds = xr.Dataset({'Distcoast': distcoast})\n",
    "    \n",
    "#     # Save the new dataset to a NetCDF file\n",
    "#     new_ds.to_netcdf(output_file)\n",
    "    \n",
    "#     return new_ds\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "#     input_file = \"/home/yahia/Documents/Jupyter/Sargassum/SARG12_distcoast.nc\"\n",
    "#     output_file = '/home/yahia/Documents/Jupyter/Sargassum/distcoast.nc'\n",
    "#     new_dataset = create_reduced_netcdf(input_file, output_file)\n",
    "#     print(new_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de316d-ca68-45a2-8707-bab6848602ef",
   "metadata": {},
   "source": [
    "#### *mask_coast*\n",
    "Function to filter detections that are close to the coast. Unlike the other functions, this one takes in a dataset as input not an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "359f187b-53e2-485b-a42d-d838b4c98e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_coast(fai_dataset, distcoast_dataset_path='/home/yahia/Documents/Jupyter/Sargassum/Utilities/distcoast.nc', \n",
    "               threshold=5000, land_mask=True):\n",
    "    # Load the distance from coast dataset\n",
    "    distcoast_dataset = xr.open_dataset(distcoast_dataset_path)\n",
    "    dist_from_coast = distcoast_dataset['Distcoast']\n",
    "    \n",
    "    # Ensure fai_dataset has 'latitude' and 'longitude' coordinates\n",
    "    if 'latitude' not in fai_dataset.coords or 'longitude' not in fai_dataset.coords:\n",
    "        fai_dataset = fai_dataset.rename({'y': 'latitude', 'x': 'longitude'})\n",
    "    \n",
    "    # Interpolate the distance from coast data to match fai_dataset's coordinate grid\n",
    "    interpolated_dist_from_coast = dist_from_coast.interp(\n",
    "        latitude=fai_dataset.latitude, \n",
    "        longitude=fai_dataset.longitude, \n",
    "        method='nearest'\n",
    "    )\n",
    "    \n",
    "    # Define the boxes representing parts of North America\n",
    "    box1 = (fai_dataset.longitude >= -100) & (fai_dataset.longitude <= -72) & (fai_dataset.latitude >= 28) & (fai_dataset.latitude <= 40)\n",
    "    box2 = (fai_dataset.longitude >= -100) & (fai_dataset.longitude <= -79.68) & (fai_dataset.latitude >= 24) & (fai_dataset.latitude <= 28)\n",
    "    box3 = (fai_dataset.longitude >= -100) & (fai_dataset.longitude <= -86) & (fai_dataset.latitude >= 17) & (fai_dataset.latitude <= 24)\n",
    "    box4 = (fai_dataset.longitude >= -100) & (fai_dataset.longitude <= -79) & (fai_dataset.latitude >= 12) & (fai_dataset.latitude <= 17)\n",
    "    \n",
    "    # Combine the boxes into a single mask where True means it's within the NA boxes\n",
    "    na_mask = box1 | box2 | box3 | box4\n",
    "    \n",
    "    # Mask where the distance is greater than or equal to the threshold OR outside NA boxes\n",
    "    mask = (interpolated_dist_from_coast >= threshold) | ~na_mask\n",
    "    \n",
    "    # Optionally set land (distcoast == 0) to NaN\n",
    "    if land_mask:\n",
    "        land_mask = interpolated_dist_from_coast == 0\n",
    "        interpolated_dist_from_coast = interpolated_dist_from_coast.where(~land_mask, other=np.nan)\n",
    "        # Apply the mask to keep original values where the mask is True or set to 0 where False, and NaN for land\n",
    "        masked_fai_dataset = fai_dataset.where(mask, other=0)\n",
    "        masked_fai_dataset = masked_fai_dataset.where(~land_mask, other=np.nan)\n",
    "    else:\n",
    "        # Apply the mask without considering the land explicitly\n",
    "        masked_fai_dataset = fai_dataset.where(mask, other=0)\n",
    "    \n",
    "    return masked_fai_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6897fa-8c39-429c-82a5-c04fab28b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    fai_dataset = xr.open_dataset('/media/yahia/ballena/ABI/NetCDF/Atlantic/Averages/algae_distribution_20220723.nc')\n",
    "    threshold = 50000\n",
    "    masked_fai_dataset = mask_coast(fai_dataset, threshold=threshold, land_mask=False)\n",
    "    print(masked_fai_dataset)\n",
    "    masked_fai_dataset.to_netcdf(\"/home/yahia/Documents/Jupyter/Sargassum/Images/Test/zboub.nc\")\n",
    "    # plot_xarray(masked_fai_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcef2af-1095-4b1b-a094-4f6073dfa1f4",
   "metadata": {},
   "source": [
    "### *process_netCDF*\n",
    "Takes as input a netCDF file and applies the wanted filters to it and outputs another netCDF file.\n",
    "**Optimize the mask_coast part** (when both land_mask and coast_mask are false the function mask_coast will still be called but do nothing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bffb316-6eb1-4347-b038-28e71b1be36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_netCDF(\n",
    "    source_path, dest_path=None, threshold=1, bilateral=False, binarize=False, \n",
    "    negative=False, filter_small=False, opened=False, kernel_size=3, size_threshold=50, \n",
    "    median=False, coast_mask=False, coast_threshold=5000, land_mask=False,\n",
    "    adaptive=False, adaptive_base_threshold=20, window_size=10, density_scale_factor=1.5,\n",
    "    adaptive_small=False, base_threshold=15, higher_threshold=50, latitude_limit=30):\n",
    "    \n",
    "    # Read the NetCDF file\n",
    "    dataset = xr.open_dataset(source_path)\n",
    "    \n",
    "    # Extract the only variable in the dataset\n",
    "    variable_name = list(dataset.data_vars)[0]\n",
    "    data = dataset[variable_name].values\n",
    "\n",
    "    # Ensure the data is 2D (grayscale image)\n",
    "    if len(data.shape) == 3:\n",
    "        data = data[0]  # Assuming the data is 3D and taking the first slice\n",
    "    \n",
    "    # Convert the data to an 8-bit image\n",
    "    image = cv2.normalize(data, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    \n",
    "    # Apply binary thresholding if required\n",
    "    if binarize:\n",
    "        image = binarize_image(image, threshold)\n",
    "\n",
    "    # Make the image negative if required\n",
    "    if negative:\n",
    "        image = cv2.bitwise_not(image)\n",
    "\n",
    "    # Filter small components if required\n",
    "    if filter_small:\n",
    "        image = filter_by_size(image, size_threshold)\n",
    "\n",
    "    # Apply adaptive filter if required\n",
    "    if adaptive:\n",
    "        image = adaptive_filter(image, adaptive_base_threshold=adaptive_threshold, window_size=window_size, density_scale_factor=density_scale_factor)\n",
    "    \n",
    "    # Apply opening filter if required\n",
    "    if opened:\n",
    "        image = opening(image, kernel_size=kernel_size)\n",
    "\n",
    "    # Apply bilateral filter if required\n",
    "    if bilateral:\n",
    "        image = bilateral_image(image)\n",
    "\n",
    "    # Apply median filter if required\n",
    "    if median:\n",
    "        image = median_filter(image, kernel_size=3)\n",
    "\n",
    "    # Convert image back to data array for further processing\n",
    "    processed_data = xr.DataArray(image, dims=dataset[variable_name].dims, coords=dataset[variable_name].coords)\n",
    "\n",
    "    # Reconstruct dataset with processed data for applying coastal mask\n",
    "    processed_dataset = xr.Dataset({variable_name: processed_data})\n",
    "\n",
    "    if adaptive_small:\n",
    "        processed_dataset = adaptive_filter_by_size(processed_dataset, base_threshold=base_threshold, higher_threshold=higher_threshold, latitude_limit=latitude_limit)\n",
    "    \n",
    "    # Apply coastal mask if required (the else clause is to allow application of land_mask without coast_mask)\n",
    "    if coast_mask:\n",
    "        processed_dataset = mask_coast(processed_dataset, threshold=coast_threshold, land_mask=land_mask)\n",
    "\n",
    "    else:\n",
    "        processed_dataset = mask_coast(processed_dataset, threshold=0, land_mask=land_mask)\n",
    "\n",
    "    # Save the processed data back to a new NetCDF file only if dest_path is specified\n",
    "    if dest_path:\n",
    "        processed_dataset.to_netcdf(dest_path)\n",
    "\n",
    "    return processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e39aaf-7480-4bab-bb89-1e91a9af0c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atlantic Average\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths\n",
    "    source_path = \"/media/yahia/ballena/ABI/NetCDF/Atlantic/Averages/algae_distribution_20220723.nc\"\n",
    "    dest_path = '/home/yahia/Documents/Jupyter/Sargassum/Images/Test/Filtered_20220723.nc'\n",
    "    \n",
    "    # Process the directory\n",
    "    process_netCDF(source_path, dest_path, threshold=1, bilateral=False, binarize=True, negative=False, \n",
    "                   filter_small=False, size_threshold=10, land_mask=False, coast_mask=False, coast_threshold=50000,\n",
    "                   adaptive=False, adaptive_base_threshold=25, window_size=30, density_scale_factor=1.5,\n",
    "                   adaptive_small=True, base_threshold=15, higher_threshold=10000, latitude_limit=30)\n",
    "    # NOTE: if you get permission denied, don't forget to close ncviewer first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b4c36b-c8ad-4d56-9dd2-d114a297d47c",
   "metadata": {},
   "source": [
    "Saving the result as a NetCDF with two variables (fai_anomaly and filtered)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9305d7-7e20-4bf5-8f87-513435270172",
   "metadata": {},
   "source": [
    "### *process_directory_netCDF*\n",
    "Processes all the netCDF file in a given directory by calling the process_netCDF function on each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1eb0e1db-f3a1-46fb-bff9-0ee952382d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory_netCDF(\n",
    "    source_dir, dest_dir, threshold=9, bilateral=False, binarize=True, negative=False, \n",
    "    filter_small=False, opened=False, kernel_size=3, size_threshold=50, median=False, \n",
    "    coast_mask=False, coast_threshold=5000, land_mask=False, adaptive=False, \n",
    "    adaptive_base_threshold=20, window_size=10, density_scale_factor=1.5, adaptive_small=False, \n",
    "    base_threshold=15, higher_threshold=50, latitude_limit=30):\n",
    "    \n",
    "    # Ensure the destination directory exists\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)\n",
    "\n",
    "    # Iterate over all files in the source directory\n",
    "    for filename in os.listdir(source_dir):\n",
    "        if filename.endswith('.nc'):\n",
    "            # Original NetCDF file path\n",
    "            source_path = os.path.join(source_dir, filename)\n",
    "            \n",
    "            # New filename with 'Processed' prefix\n",
    "            new_filename = 'Processed_' + filename\n",
    "            \n",
    "            # Define the output path for the processed NetCDF file\n",
    "            dest_path = os.path.join(dest_dir, new_filename)\n",
    "            \n",
    "            # Process the NetCDF file\n",
    "            process_netCDF(\n",
    "                source_path, dest_path, threshold, bilateral, binarize, \n",
    "                negative, filter_small, opened, kernel_size, size_threshold, median, \n",
    "                coast_mask, coast_threshold, land_mask, adaptive, adaptive_base_threshold, \n",
    "                window_size, density_scale_factor, adaptive_small, base_threshold, \n",
    "                higher_threshold, latitude_limit\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "688ee7f1-07e3-439a-bbfb-6e22ea3d8fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    source_dir = '/home/yahia/Documents/Jupyter/Sargassum/Images/Sub-Daily'\n",
    "    dest_dir = '/home/yahia/Documents/Jupyter/Sargassum/Images/Sub-Daily/Binarized'\n",
    "    process_directory_netCDF(source_dir, dest_dir, threshold=1, bilateral=False, binarize=True, negative=False, filter_small=True, size_threshold=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223d1826-a9a6-4da7-83ae-a0bb34427dd8",
   "metadata": {},
   "source": [
    "### *process_directory*\n",
    "This function takes as input images and applies the wanted functions to them and then saves them in the provided directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "098b1383-3b6e-4809-af31-2a159d9d4592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(source_dir, dest_dir, threshold=180, bilateral=False, binarize=False, crop=True, negative=False):\n",
    "    # Ensure the destination directory exists\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)\n",
    "\n",
    "    # Iterate over all files in the source directory\n",
    "    for filename in os.listdir(source_dir):\n",
    "        if filename.endswith('.png'):\n",
    "            # Original image path\n",
    "            image_path = os.path.join(source_dir, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            # Filter the image\n",
    "            if bilateral:\n",
    "                image = bilateral_image(image)\n",
    "            \n",
    "            # Binarize the image\n",
    "            if binarize:\n",
    "                image = binarize_image(image, threshold)\n",
    "\n",
    "            # Crop the image\n",
    "            if crop:\n",
    "                image = crop_image(image)\n",
    "\n",
    "            # Make the image negative\n",
    "            if negative:\n",
    "                image = cv2.bitwise_not(image)\n",
    "            \n",
    "            # New filename with 'Processed' prefix\n",
    "            new_filename = 'Processed_' + filename\n",
    "            \n",
    "            # Define the output path for the processed image\n",
    "            output_path = os.path.join(dest_dir, new_filename)\n",
    "            \n",
    "            # Save the processed image\n",
    "            cv2.imwrite(output_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb3acf2d-18b7-40b7-9edc-3275647f488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     # Paths\n",
    "#     source_directory = '/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages'\n",
    "#     destination_directory = '/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral'\n",
    "    \n",
    "#     # Process the directory\n",
    "#     process_directory(source_directory, destination_directory, threshold=100, bilateral=True, binarize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39b66db-5eba-403d-b7bf-609c3c2a4d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     # Display the processed image\n",
    "#     image_path = '/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Binarized_Bilateral/Binarized_Bilateral_algae_distribution_20220724.png'\n",
    "#     display(Image(filename=image_path, width=700))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe3d0ce-bb13-4242-b3f3-0bb06b64871f",
   "metadata": {},
   "source": [
    "The **threshold** value must be chosen carefully so as to leave all the algae, but not leave the clouds, land or other undesirable features. \n",
    "\n",
    "This is what the Binarized version looks like (for **cmap=\"binary\"** and **threshold=180**), this should make it easier for the OF algorithms to track the algae. If we increase the threshold (which leaves in more algae), we get a lot of discrete algae spots, which is probably not going to be good for our algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba034e9-2fff-4603-bd9e-ce7f46e56039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     image_path = '/home/yahia/Documents/Jupyter/Sargassum/Images/Binarized_algae_distribution_20220724_thresh_200.png'\n",
    "#     display(Image(filename=image_path, width=700))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fe4e1f-7501-4e1a-ada3-2e101df6c6aa",
   "metadata": {},
   "source": [
    "This is what the binarized version looks like for **threshold=200**.\n",
    "Maybe we could still use this, if we apply a filter to it (median filter for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d14e6-4014-4941-a190-ca4c1e9b205f",
   "metadata": {},
   "source": [
    "## Finding a Good Example\n",
    "The 10-day period we have chosen (starting on 2022/07/24 and ending on 2022/08/02) may not be enough on its own to visualize motion vectors because a lot of the acquisitions are masked by clouds, so we're going to try to find 2 consecutive days in which the detections are clear after averaging the ABI-GOES images.\n",
    "\n",
    "After a few tries, we've found the week of 2022/07/18 - 2022/07/24 to be good, with 22, 23 and 24 having particularly clear images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef566cc-9604-4252-b8fb-1005495109ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    start_date = '20220718'\n",
    "    end_date = '20220724'\n",
    "    directory = '/media/yahia/ballena/CLS/abi-goes-global-hr' \n",
    "    output_directory = '/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages' \n",
    "    latitude_range = (12, 17)  \n",
    "    longitude_range = (-67, -60) \n",
    "    \n",
    "    # Calculate the 1-day averages and save them\n",
    "    process_dates(start_date, end_date, directory, output_directory, latitude_range, longitude_range, color=\"binary\")\n",
    "    \n",
    "    # Paths\n",
    "    source_directory = '/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages'\n",
    "    destination_directory = '/home/yahia/Documents/Jupyter/Images/Sargassum/ABI_Averages_Binarized_Bilateral'\n",
    "    \n",
    "    # Process the directory (filter, binarize and crop the images)\n",
    "    process_directory(source_directory, destination_directory, threshold=180, bilateral=True, binarize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d80cfa-17d8-464a-a01a-bc2effb15f2e",
   "metadata": {},
   "source": [
    "## Producing Viridis Images\n",
    "After all the image processing we did, the algorithm may not be able to track individual pixels any more, so raw viridis images may actually be better than the images we processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6d6bdc-77c9-4d1c-b4b6-6817e87a5604",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    start_date = '20220718'\n",
    "    end_date = '20220724'\n",
    "    directory = '/media/yahia/ballena/CLS/abi-goes-global-hr' \n",
    "    output_directory = '/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Viridis' \n",
    "    latitude_range = (12, 17)  \n",
    "    longitude_range = (-67, -60) \n",
    "    \n",
    "    # Calculate the 1-day averages and save them\n",
    "    process_dates(start_date, end_date, directory, output_directory, latitude_range, longitude_range, color=\"viridis\")\n",
    "    \n",
    "    # Paths\n",
    "    source_directory = '/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Viridis'\n",
    "    destination_directory = '/home/yahia/Documents/Jupyter/Sargassum/Images/ABI_Averages_Processed_Viridis'\n",
    "    \n",
    "    # Process the directory (filter, binarize and crop the images)\n",
    "    process_directory(source_directory, destination_directory, threshold=180, bilateral=False, binarize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71bdf97-1a49-40e8-86cd-be9c955095ab",
   "metadata": {},
   "source": [
    "# Producing the Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148f76c5-9320-4528-9ce1-a5b8e90e31b4",
   "metadata": {},
   "source": [
    "## ABI_Averages_Antilles\n",
    "We're going to average and process all the ABI-GOES images and save them to the directory ABI_Averages on the hard drive \"ballena\". Running this block might take a while. To optimize we could try and parallelize this process using the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4fd4a7-5cbe-4091-b4c8-f82d7195cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    start_date = '20221121'\n",
    "    end_date = '20221231'\n",
    "    directory = '/media/yahia/ballena/CLS/abi-goes-global-hr' \n",
    "    output_directory = '/media/yahia/ballena/ABI_Averages_Antilles' \n",
    "    latitude_range = (12, 17)  \n",
    "    longitude_range = (-67, -60) \n",
    "    \n",
    "    # Calculate the 1-day averages and save them\n",
    "    process_dates(start_date, end_date, directory, output_directory, latitude_range, longitude_range, color=\"viridis\")\n",
    "    \n",
    "    # Paths\n",
    "    source_directory = '/media/yahia/ballena/ABI_Averages_Antilles' \n",
    "    destination_directory = '/media/yahia/ballena/ABI_Averages_Antilles_Processed' \n",
    "    \n",
    "    # Process the directory (filter, binarize and crop the images)\n",
    "    process_directory(source_directory, destination_directory, threshold=180, bilateral=False, binarize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5617c345-1cba-40ed-9d61-7d940ec3a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarized and bilateral images\n",
    "if __name__ == '__main__':\n",
    "    # Paths\n",
    "    source_directory = '/media/yahia/ballena/ABI/ABI_Averages_Antilles' \n",
    "    destination_directory = '/media/yahia/ballena/ABI/ABI_Averages_Antilles_Binarized_Bilateral' \n",
    "    \n",
    "    # Process the directory (filter, binarize and crop the images)\n",
    "    process_directory(source_directory, destination_directory, threshold=100, bilateral=True, binarize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1db967-3257-4af5-8e45-cba974a4613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarized and bilateral images (negative)\n",
    "if __name__ == '__main__':\n",
    "    # Paths\n",
    "    source_directory = '/media/yahia/ballena/ABI/ABI_Averages_Antilles' \n",
    "    destination_directory = '/media/yahia/ballena/ABI/ABI_Averages_Antilles_Binarized_Bilateral_Negative' \n",
    "    \n",
    "    # Process the directory (filter, binarize and crop the images)\n",
    "    process_directory(source_directory, destination_directory, threshold=100, bilateral=True, binarize=True, negative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bcfff9-16d3-42c1-93f5-30d2902a6610",
   "metadata": {},
   "source": [
    "## MODIS_Images\n",
    "The function **process_dates** we previously defined is only adapted to ABI-GOES images, we will need to write a function that does the same for MODIS and OLCI images. We will also need to do the same for **save_aggregate**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277a3c6-290d-4965-b335-4185762009e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(file_path, lat_range=None, lon_range=None, color=\"viridis\", vmax=0.1, output_filepath=None):\n",
    "    # Load the netCDF data\n",
    "    data = xr.open_dataset(file_path)\n",
    "    \n",
    "    # If ranges are specified, apply them to select the desired subset\n",
    "    if lat_range:\n",
    "        data = data.sel(latitude=slice(*lat_range))\n",
    "    if lon_range:\n",
    "        data = data.sel(longitude=slice(*lon_range))\n",
    "\n",
    "    # Determine the index data and labels based on instrument used\n",
    "    index_key = 'fai_anomaly' if \"abi\" in file_path else 'nfai_mean'\n",
    "    colorbar_label = 'Floating Algae Index Anomaly (FAI)' if \"abi\" in file_path else 'Normalized Floating Algae Index (NFAI)'\n",
    "    title = 'FAI anomaly across the selected region on ' if \"abi\" in file_path else 'NFAI across the selected region on '\n",
    "    \n",
    "    # Extract relevant data (NFAI or FAI anomaly)\n",
    "    index_data = data[index_key]\n",
    "\n",
    "    # Set non-positive values to a very small negative number, close to zero\n",
    "    index_data = xr.where(index_data > 0, index_data, -0.1)\n",
    "    \n",
    "    # Set up a plot with geographic projections\n",
    "    fig, ax = plt.subplots(figsize=(12, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    \n",
    "    # Customize the map with coastlines and features\n",
    "    ax.coastlines(resolution='10m', color='black')\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
    "\n",
    "    # Show gridlines only when visualizing interactively, not when saving the output\n",
    "    if output_filepath is None:\n",
    "        gl = ax.gridlines(draw_labels=True, linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        cbar_kwargs = {'shrink': 0.35}\n",
    "    else:\n",
    "        cbar_kwargs = None\n",
    "\n",
    "    # Plot the data with the modified contrast\n",
    "    im = index_data.plot(ax=ax, x='longitude', y='latitude', transform=ccrs.PlateCarree(),\n",
    "                         cmap=color, add_colorbar=True, extend='both',\n",
    "                         vmin=-0.01, vmax=vmax,  # Here we set the scale to max out at 0.5\n",
    "                         cbar_kwargs={'shrink': 0.35})\n",
    "\n",
    "    # Set title and colorbar only when visualizing interactively\n",
    "    if output_filepath is None:\n",
    "        im.colorbar.set_label('Normalized Floating Algae Index (NFAI)')\n",
    "        plot_date = data.attrs.get('date', 'Unknown Date')\n",
    "        plt.title(f\"Algae Distribution on {plot_date}\")\n",
    "\n",
    "    if output_filepath:\n",
    "        plt.savefig(output_filepath)  \n",
    "        plt.close(fig)  \n",
    "    else:\n",
    "        plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23844ac3-4b2f-4d23-b28e-1f480660f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dates_2(start_date, end_date, directory, output_dir, lat_range=None, lon_range=None, color=\"viridis\"):\n",
    "    # Convert the start and end dates from strings to datetime objects\n",
    "    current_date = datetime.strptime(start_date, '%Y%m%d')\n",
    "    end_date = datetime.strptime(end_date, '%Y%m%d')\n",
    "    \n",
    "    while current_date <= end_date:\n",
    "        # Format the current date as a string in 'YYYYMMDD' format\n",
    "        date_str = current_date.strftime('%Y%m%d')\n",
    "        \n",
    "        # Prepare the output file path for the current day's visualization\n",
    "        # Visualize the median algae distribution and save it using the provided visualization function\n",
    "        if \"modis\" in directory:\n",
    "            output_file_path = os.path.join(output_dir, f'MODIS_{date_str}.png')\n",
    "            file_path = directory + f\"/cls-modis-aqua-global-lr_1d_{date_str}.nc\"\n",
    "        elif \"olci\" in directory:\n",
    "            output_file_path = os.path.join(output_dir, f'OLCI_{date_str}.png')\n",
    "            file_path = directory + f\"/cls-olci-s3-global-lr_1d_{date_str}.nc\"\n",
    "\n",
    "        # Check if the file exists before proceeding\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found for date: {date_str}, skipping...\")\n",
    "        else:\n",
    "            try:\n",
    "                save_image(file_path, lat_range, lon_range, color=color, output_filepath=output_file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {file_path}: {e}\")\n",
    "    \n",
    "        # Increment the current date by one day\n",
    "        current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ed8a19-da1b-4ec5-bb57-7c51a67e76c9",
   "metadata": {},
   "source": [
    "Generating the MODIS images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af9a3f7-db27-4c3d-85ad-135070a01f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    start_date = '20201207'\n",
    "    end_date = '20221231'\n",
    "    directory = '/media/yahia/ballena/CLS/modis-aqua-global-lr' \n",
    "    output_directory = '/media/yahia/ballena/MODIS_Antilles' \n",
    "    latitude_range = (12, 17)  \n",
    "    longitude_range = (-67, -60) \n",
    "    \n",
    "    # Calculate the 1-day averages and save them\n",
    "    process_dates_2(start_date, end_date, directory, output_directory, latitude_range, longitude_range, color=\"viridis\")\n",
    "    \n",
    "    # Paths\n",
    "    source_directory = '/media/yahia/ballena/MODIS_Antilles' \n",
    "    destination_directory = '/media/yahia/ballena/MODIS_Antilles_Processed' \n",
    "    \n",
    "    # Process the directory (filter, binarize and crop the images)\n",
    "    process_directory(source_directory, destination_directory, threshold=180, bilateral=False, binarize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f0dda-86c6-470c-a078-0dabc6ca162f",
   "metadata": {},
   "source": [
    "## OLCI_Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f3e06c-c8a6-425f-b6f9-80e1b914d43f",
   "metadata": {},
   "source": [
    "Generating the OLCI images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93740a50-d18b-41c6-b59e-6dbf51f69b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    start_date = '20201207'\n",
    "    end_date = '20240122'\n",
    "    directory = '/media/yahia/ballena/CLS/olci-s3-global-lr' \n",
    "    output_directory = '/media/yahia/ballena/OLCI_Antilles' \n",
    "    latitude_range = (12, 17)  \n",
    "    longitude_range = (-67, -60) \n",
    "    \n",
    "    # Calculate the 1-day averages and save them\n",
    "    process_dates_2(start_date, end_date, directory, output_directory, latitude_range, longitude_range, color=\"viridis\")\n",
    "    \n",
    "    # Paths\n",
    "    source_directory = '/media/yahia/ballena/OLCI_Antilles' \n",
    "    destination_directory = '/media/yahia/ballena/OLCI_Antilles_Processed' \n",
    "    \n",
    "    # Process the directory (filter, binarize and crop the images)\n",
    "    process_directory(source_directory, destination_directory, threshold=180, bilateral=False, binarize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92054f3c-d2b3-4f73-9816-0c2e15bd2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ATLANTIC TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dee196-cc57-4400-a4b9-fc8419ea9901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     start_date = '20220723'\n",
    "#     end_date = '20220724'\n",
    "#     directory = '/media/yahia/ballena/CLS/abi-goes-global-hr' \n",
    "#     output_directory = '/media/yahia/ballena/TEST/Atlantic' \n",
    "#     lat_splits = [12, 16, 20, 24, 28, 32, 36, 40]  # Define latitude splits\n",
    "#     lon_splits = [-100, -90, -80, -70, -60, -50, -40, -30, -20, -12]  # Define longitude splits\n",
    "\n",
    "#     def process_dates_3(start_date, end_date, directory, output_dir, lat_splits, lon_splits, color=\"viridis\"):\n",
    "#         current_date = datetime.strptime(start_date, '%Y%m%d')\n",
    "#         end_date = datetime.strptime(end_date, '%Y%m%d')\n",
    "        \n",
    "#         while current_date <= end_date:\n",
    "#             date_str = current_date.strftime('%Y%m%d')\n",
    "#             times = collect_times(date_str, directory)\n",
    "            \n",
    "#             if times:\n",
    "#                 times_for_day = time_list(\n",
    "#                     datetime.strptime(f'{date_str}_{times[0]}', '%Y%m%d_%H-%M'),\n",
    "#                     datetime.strptime(f'{date_str}_{times[1]}', '%Y%m%d_%H-%M'),\n",
    "#                     interval=10\n",
    "#                 )\n",
    "#                 median_distribution = split_and_aggregate_median(lat_splits, lon_splits, times_for_day)\n",
    "#                 output_file_path = os.path.join(output_dir, f'algae_distribution_{date_str}.png')\n",
    "#                 save_aggregate(median_distribution, color=color, output_filepath=output_file_path)\n",
    "            \n",
    "#             current_date += timedelta(days=1)\n",
    "\n",
    "#     # Calculate the 1-day averages and save them\n",
    "#     process_dates_3(start_date, end_date, directory, output_directory, lat_splits, lon_splits, color=\"viridis\")\n",
    "    \n",
    "#     # Paths\n",
    "#     source_directory = '/media/yahia/ballena/TEST/Atlantic' \n",
    "#     destination_directory = '/media/yahia/ballena/Test/Atlantic_Cropped' \n",
    "    \n",
    "#     # Process the directory (filter, binarize and crop the images)\n",
    "#     process_directory(source_directory, destination_directory, threshold=180, bilateral=False, binarize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe368ea-26b4-4d82-b6fa-809a7b680d0d",
   "metadata": {},
   "source": [
    "Saving the image after calculating the median on each region then combining gives the same exact result as calculating the median over the whole region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6826f0-2a83-4dd7-8fcd-0ec0dc8485ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
