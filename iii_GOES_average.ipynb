{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f3c209-055e-48f3-802c-8ba78b7c6964",
   "metadata": {},
   "source": [
    "# Averaging ABI-GOES images for a given day:\n",
    "We could try to average the images for a given day to try and reproduce the images we see on the CLS datastore.\n",
    "GOES doesn't cover the same region from image to image, so we can't directly calculate the average, we'll have to calculate an average only when there is data (non-nan values). We're going to work on the same day of 24/07/2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf370928-7e70-4791-9ae7-318d43960628",
   "metadata": {},
   "source": [
    "## Importing necessary libraries and notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6bbac2-4bd8-4be9-9dd0-8479aa69806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "import os\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import ticker\n",
    "from IPython.display import Image\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Import the other notebooks without running their cells\n",
    "from ii_Data_Manipulation import visualize_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01eab59-c963-47dc-8349-275ea27b52f6",
   "metadata": {},
   "source": [
    "## time_list\n",
    "First, we should write a function that generates a lost of the times in the time intervals we need to make the importation of data easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc6800e-d08d-41cc-9b4d-2cb8aff614ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_list(start_time, end_time, interval):\n",
    "    \"\"\"\n",
    "    Generate a list of datetime strings in the format 'YYYYMMDD_HH-MM' between start_time and end_time at intervals of 'interval' minutes.\n",
    "    \n",
    "    Parameters:\n",
    "    - start_time (datetime): The start time.\n",
    "    - end_time (datetime): The end time.\n",
    "    - interval (int): The interval in minutes between each time point.\n",
    "\n",
    "    Returns:\n",
    "    - times (list of str): List of formatted datetime strings.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate a list of times at the specified interval\n",
    "    times = []\n",
    "    current_time = start_time\n",
    "    while current_time <= end_time:\n",
    "        times.append(current_time.strftime('%Y%m%d_%H-%M'))\n",
    "        current_time += timedelta(minutes=interval)\n",
    "\n",
    "    return times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858c29fa-21c4-45e5-95d4-46511ac87d3a",
   "metadata": {},
   "source": [
    "## visualize_aggregate\n",
    "We should first write a function **(very similar to visualize_5, maybe we should make it use visualize_5)** to visualize the aggregate motion of the algae, this function would take the aggregate_data we're going to calculate as argument instead of the path to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5271e3-427a-4ccb-88c8-bc575718a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_aggregate(aggregate_data, lat_range=None, lon_range=None, color=\"viridis\", vmax=0.001, threshold=0, output_filepath=None, filter_clouds=True):\n",
    "    # Select the desired subset\n",
    "    if lat_range:\n",
    "        aggregate_data = aggregate_data.sel(latitude=slice(*lat_range))\n",
    "    if lon_range:\n",
    "        aggregate_data = aggregate_data.sel(longitude=slice(*lon_range))\n",
    "    \n",
    "    # If filtering clouds, set NaN values to -0.1\n",
    "    if filter_clouds:\n",
    "        aggregate_data = xr.where(np.isnan(aggregate_data), -0.1, aggregate_data)\n",
    "    \n",
    "    # Set up a plot with geographic projections\n",
    "    fig, ax = plt.subplots(figsize=(12, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    \n",
    "    # Customize the map with coastlines and features\n",
    "    ax.coastlines(resolution='10m', color='black')\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
    "\n",
    "    # Adding grid lines and disabling labels on the top and right\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "\n",
    "    # Plot the aggregate data with the specified color, vmax, and threshold\n",
    "    im = aggregate_data.plot(ax=ax, x='longitude', y='latitude', transform=ccrs.PlateCarree(),\n",
    "                             cmap=color, add_colorbar=True, extend='both',\n",
    "                             vmin=threshold, vmax=vmax, cbar_kwargs={'shrink': 0.35})\n",
    "\n",
    "    # Add color bar details\n",
    "    colorbar_label = 'Aggregate Floating Algae Index (FAI)' \n",
    "    im.colorbar.set_label(colorbar_label)\n",
    "    \n",
    "    # Show the plot with title\n",
    "    plt.title(\"Aggregate Algae Distribution on 2022-07-24\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5232c574-bb09-4c4b-886c-6b68b1c5315e",
   "metadata": {},
   "source": [
    "## visualize_aggregate_plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b2bd60-fd43-48fc-8640-71f0f4d3baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_aggregate_plotly(aggregate_data, lat_range=None, lon_range=None, color=\"Viridis\", vmax=0.001, threshold=0, output_filepath=None, filter_clouds=True):\n",
    "    # Select the desired subset\n",
    "    if lat_range:\n",
    "        aggregate_data = aggregate_data.sel(latitude=slice(*lat_range))\n",
    "    if lon_range:\n",
    "        aggregate_data = aggregate_data.sel(longitude=slice(*lon_range))\n",
    "    \n",
    "    # If filtering clouds, set NaN values to -0.1\n",
    "    if filter_clouds:\n",
    "        aggregate_data = xr.where(np.isnan(aggregate_data), -0.1, aggregate_data)\n",
    "    \n",
    "    # Convert the data to a DataFrame for Plotly\n",
    "    df = aggregate_data.to_dataframe().reset_index()\n",
    "    \n",
    "    # Filter data based on threshold\n",
    "    df = df[df[aggregate_data.name] > threshold]\n",
    "\n",
    "    # Create a 2D heatmap\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add the heatmap trace\n",
    "    fig.add_trace(go.Heatmap(\n",
    "        z=df[aggregate_data.name],\n",
    "        x=df['longitude'],\n",
    "        y=df['latitude'],\n",
    "        colorscale=color,\n",
    "        zmin=threshold,\n",
    "        zmax=vmax,\n",
    "        colorbar=dict(title='Aggregate Floating Algae Index (FAI)')\n",
    "    ))\n",
    "\n",
    "    # Customize the layout to ensure no grey areas appear around the plot\n",
    "    fig.update_layout(\n",
    "        title=\"Aggregate Algae Distribution on 2022-07-24\",\n",
    "        xaxis=dict(showgrid=False, zeroline=False, range=[df['longitude'].min(), df['longitude'].max()]),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, range=[df['latitude'].min(), df['latitude'].max()]),\n",
    "        autosize=True,\n",
    "        margin=dict(l=0, r=0, t=40, b=0),  # adjust margins to ensure no empty space\n",
    "        paper_bgcolor='rgba(0,0,0,0)',  # make background transparent\n",
    "        plot_bgcolor='rgba(0,0,0,0)'  # ensure plot background is also transparent\n",
    "    )\n",
    "\n",
    "    # Ensure the plot stretches to fit the data precisely\n",
    "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "\n",
    "    # Save the plot if output_filepath is provided\n",
    "    if output_filepath:\n",
    "        fig.write_html(output_filepath, auto_open=True)\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e890f4-ba7d-4ac7-bd56-10b35587fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     # Generating the time list\n",
    "#     times = time_list(start_time=datetime(2022, 7, 24, 12, 0), end_time=datetime(2022, 7, 24, 18, 50), interval=10)\n",
    "    \n",
    "#     # Calculating the median data for this time period\n",
    "#     median_algae_distribution = calculate_median(times,lat_range=(12, 17), lon_range= (-67, -60))\n",
    "    \n",
    "#     #Visualizing the result and comparing it to the mean \n",
    "#     visualize_aggregate_interactive(median_algae_distribution, (12, 17), (-67, -60), color=\"viridis\", vmax=0.001, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee5375-8bc5-43ad-9f10-47a06e9d79e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     # Generating the time list\n",
    "#     times = time_list(start_time=datetime(2022, 7, 24, 12, 0), end_time=datetime(2022, 7, 24, 18, 50), interval=10)\n",
    "    \n",
    "#     # Calculating the median data for this time period\n",
    "#     median_algae_distribution = calculate_median(times,lat_range=(14, 15), lon_range= (-67, -65))\n",
    "    \n",
    "#     #Visualizing the result and comparing it to the mean \n",
    "#     visualize_aggregate_interactive(median_algae_distribution, (14, 15), (-67, -65), color=\"viridis\", vmax=0.001, threshold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad2ac16-d1ff-48c3-9d78-88ff7ffb4af8",
   "metadata": {},
   "source": [
    "This function allows us to zoom and it also shows the latitude, longitude and FAI of the pixel we're hovering over, although the zoom functionality is a bit finnicky. If we want just the zoom we can use **%matplotlib widget** at the beginning of our execution block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e26726-71a8-4bf4-bf7d-0881c3bb7119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "# if __name__ == '__main__':\n",
    "#     # Generating the time list\n",
    "#     times = time_list(start_time=datetime(2022, 7, 24, 12, 0), end_time=datetime(2022, 7, 24, 18, 50), interval=10)\n",
    "    \n",
    "#     # Calculating the median data for this time period\n",
    "#     median_algae_distribution = calculate_median(times,lat_range=(12, 17), lon_range= (-67, -60))\n",
    "    \n",
    "#     #Visualizing the result and comparing it to the mean \n",
    "#     visualize_aggregate(median_algae_distribution, (12, 17), (-67, -60), color=\"viridis\", vmax=0.001, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dcc9b3-156d-4274-817e-8123d3186a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "# if __name__ == '__main__':\n",
    "#     # Generating the time list\n",
    "#     times = time_list(start_time=datetime(2022, 7, 24, 12, 0), end_time=datetime(2022, 7, 24, 18, 50), interval=10)\n",
    "    \n",
    "#     # Calculating the median data for this time period\n",
    "#     median_algae_distribution = calculate_median(times)\n",
    "    \n",
    "#     #Visualizing the result and comparing it to the mean \n",
    "#     visualize_aggregate(median_algae_distribution, color=\"viridis\", vmax=0.001, threshold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c2aa7-d0c5-462b-a126-637bcbc68849",
   "metadata": {},
   "source": [
    "## split_and_aggregate_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a081b19b-55a8-4732-9edc-23361f2517d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_aggregate_median(lat_splits, lon_splits, time_list, threshold=0):\n",
    "    \"\"\"\n",
    "    Splits the data into regions, calculates median for each region across given times, and aggregates back.\n",
    "\n",
    "    Parameters:\n",
    "    - data (xarray Dataset): The dataset containing the ABI data.\n",
    "    - lat_splits (list of float): Latitude boundaries for splitting the dataset.\n",
    "    - lon_splits (list of float): Longitude boundaries for splitting the dataset.\n",
    "    - time_list (list of str): List of formatted datetime strings in the format 'YYYYMMDD_HH-MM'.\n",
    "    - threshold (float): The threshold above which data is considered.\n",
    "\n",
    "    Returns:\n",
    "    - aggregated_median (xarray DataArray): The aggregated median distribution.\n",
    "    \"\"\"\n",
    "    regional_medians = []\n",
    "\n",
    "    # Iterate over each region defined by lat and lon splits\n",
    "    for i in range(len(lat_splits) - 1):\n",
    "        for j in range(len(lon_splits) - 1):\n",
    "            lat_range = (lat_splits[i], lat_splits[i + 1])\n",
    "            lon_range = (lon_splits[j], lon_splits[j + 1])\n",
    "\n",
    "            # Fetch and process the median for this region\n",
    "            median = calculate_median(time_list, lat_range, lon_range, threshold)\n",
    "            regional_medians.append(median)\n",
    "    \n",
    "    # Combine using `concat` along a new dimension and then take the median of that dimension\n",
    "    if regional_medians:\n",
    "        combined = xr.concat(regional_medians, dim='new_dim')\n",
    "        aggregated_median = combined.median(dim='new_dim')\n",
    "        return aggregated_median\n",
    "    else:\n",
    "        return None  # or handle empty list case appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f3949-447d-4b04-b0fd-f5a504c34f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "if __name__ == '__main__':\n",
    "    lat_splits = [12, 15.5, 19, 22.5, 26, 29.5, 33, 36.5, 40]  # Define latitude splits\n",
    "    lon_splits = [-100, -89, -78, -67, -56, -45, -34, -23, -12]  # Define longitude splits\n",
    "    # Generating the time list\n",
    "    times = time_list(start_time=datetime(2022, 7, 24, 12, 0), end_time=datetime(2022, 7, 24, 18, 50), interval=10)\n",
    "    \n",
    "    # Calculating the median data for this time period\n",
    "    aggregated_median = split_and_aggregate_median(lat_splits, lon_splits, times)\n",
    "    \n",
    "    #Visualizing the result and comparing it to the mean \n",
    "    visualize_aggregate(aggregated_median, (14, 15), (-66, -65), color=\"viridis\", vmax=0.001, threshold=0)\n",
    "\n",
    "    # Comparing to averaging on just the region\n",
    "    # Calculating the median data for this time period\n",
    "    median_algae_distribution = calculate_median(times,lat_range=(14, 15), lon_range= (-66, -65))\n",
    "    \n",
    "    #Visualizing the result and comparing it to the mean \n",
    "    visualize_aggregate(median_algae_distribution, (14, 15), (-66, -65), color=\"viridis\", vmax=0.001, threshold=0)\n",
    "\n",
    "    # Comparing to whole atlatnic then zooming\n",
    "    # Calculating the median data for this time period\n",
    "    median_algae_distribution = calculate_median(times)\n",
    "    \n",
    "    #Visualizing the result and comparing it to the mean \n",
    "    visualize_aggregate(median_algae_distribution, color=\"viridis\", vmax=0.001, threshold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664153de-91de-4d41-a70d-7fc7d8fa6301",
   "metadata": {},
   "source": [
    "## save_as_netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d002a-5745-4c5d-8ba5-ff689554cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_netcdf(dataset, output_filepath):\n",
    "    \"\"\"\n",
    "    Save the given Dataset to a NetCDF file.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset (Dataset): The xarray Dataset to save.\n",
    "    - output_filepath (str): The path to the output NetCDF file.\n",
    "    \"\"\"\n",
    "    dataset.to_netcdf(output_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce78532-7272-4ce6-b417-a009e0adc24b",
   "metadata": {},
   "source": [
    "We obtain what appear to be the same results whether we calculate the median on the whole image, then zoom in, or zoom in then calculate it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e8844d-4431-45da-be14-02ccdf2b251e",
   "metadata": {},
   "source": [
    "## Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baacffce-e91e-4869-8b16-83ee02783d5f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### calculate_mean\n",
    "- We should also write a function to calculate the aggregate (mean) data on the time frame we want using the previous function time_list. \n",
    "- Note: **This is only adapted to ABI-GOES for the moment.**\n",
    "- **We can and should optimize this by making it calculate the aggregate on a selected region instead of the whole image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbfc6a6-5f98-4c73-a41a-56caada73b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(time_list, lat_range=None, lon_range=None, threshold=0):\n",
    "    \"\"\"\n",
    "    Calculate the aggregate data of algae presence over a given time range based on a list of times,\n",
    "    within specified latitude and longitude ranges.\n",
    "\n",
    "    Parameters:\n",
    "    - time_list (list of str): List of formatted datetime strings in the format 'YYYYMMDD_HH-MM'.\n",
    "    - lat_range (tuple): Tuple of (min_latitude, max_latitude).\n",
    "    - lon_range (tuple): Tuple of (min_longitude, max_longitude).\n",
    "    - threshold (float): The threshold above which data is considered.\n",
    "\n",
    "    Returns:\n",
    "    - average_algae_distribution (DataArray): The mean algae distribution within the specified region.\n",
    "    \"\"\"\n",
    "    aggregate_data_list = []\n",
    "\n",
    "    # Loop over each time in the time list, loading the data and adding it to the list\n",
    "    for time_str in time_list:\n",
    "        file_path = f\"/media/yahia/ballena/CLS/abi-goes-global-hr/cls-abi-goes-global-hr_1d_{time_str}.nc\"\n",
    "        data = xr.open_dataset(file_path)\n",
    "\n",
    "        # Apply latitude and longitude ranges if specified\n",
    "        if lat_range:\n",
    "            data = data.sel(latitude=slice(*lat_range))\n",
    "        if lon_range:\n",
    "            data = data.sel(longitude=slice(*lon_range))\n",
    "\n",
    "        # Extract the index of interest and drop the 'time' coordinate\n",
    "        algae_data = data['fai_anomaly'].squeeze(drop=True)\n",
    "\n",
    "        # Mask the data to include only algae (values greater than the threshold)\n",
    "        algae_masked = algae_data.where(algae_data > threshold)\n",
    "\n",
    "        # Add the masked data to our list (each element in this list is the data array, after processing, for the give time)\n",
    "        aggregate_data_list.append(algae_masked)\n",
    "\n",
    "    # Combine the data along a new dimension, then calculate the mean along that dimension\n",
    "    # Note: Xarray's mean function by default ignores nan values\n",
    "    aggregate_data = xr.concat(aggregate_data_list, dim='new_dim')\n",
    "    average_algae_distribution = aggregate_data.mean(dim='new_dim')\n",
    "\n",
    "    return average_algae_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d4e764-6da3-4511-a53c-b37acfc1657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Generating the time list\n",
    "    times = time_list(start_time=datetime(2022, 7, 24, 12, 0), end_time=datetime(2022, 7, 24, 18, 50), interval=10)\n",
    "    \n",
    "    # Calculating the aggregate data for this time period\n",
    "    average_algae_distribution = calculate_mean(times,lat_range=(12, 17), lon_range=(-67, -60))\n",
    "    \n",
    "    #Visualizing the result and comparing it to the OLCI and CLS datastore images\n",
    "    visualize_aggregate(average_algae_distribution, (12, 17), (-67, -60), color=\"viridis\", vmax=0.001, threshold=0.0001)\n",
    "    path = \"/media/yahia/ballena/CLS/olci-s3-global-lr/cls-olci-s3-global-lr_1d_20220724.nc\" \n",
    "    visualize_4(path,(12,17),(-67,-60),color=\"viridis\")\n",
    "    Image(filename='/home/yahia/Documents/Jupyter/Sargassum/Images/CLS_ABI_20220724.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c883a3b7-cadd-4575-a45c-99966101ec5c",
   "metadata": {},
   "source": [
    "- This result is pretty good, it shows pretty clearly the algae (without much interference from the clouds).\n",
    "- The comparison with the image from the CLS datastore shows us that our result is identical with theirs.\n",
    "- The comparison with the OLCI image, shows us the strength and weaknesses of both images (aside from the temporal resolution where ABI-GOES is much better):\n",
    "\n",
    "  \n",
    "  The OLCI image is less impacted by clouds, so a single OLCI image is always better than an ABI-GOES image. It is also more precise than the ABI-GOES images, as it has a higher resolution and it's not averaged, so the sargassum rafts are more fine and therefore accurate in the OLCI image. However, in the example we have, the sargassum raft that is in the center is obscured by clouds so we don't see all of it. This is not a problem for the ABI-GOES image where we can see the locations the whole raft occupied throughout the day.\n",
    "\n",
    "**Ideas for improvement:**\n",
    "- ~Optimize the calculate_aggregate_data function (do the zoom before you calculate). We should however lose accuracy at the borders with this method.~ **DONE**\n",
    "- Denoise the image and remove the small spots to clean it out (are they sargassum or not?).\n",
    "- Use the OLCI image to improve the accuracy of the ABI-GOES image (but how?).\n",
    "- Conversely, we can use the ABI-GOES aggregate image which has overall less cloud interference to interpolate the missing data points (like in the center raft for example) in the OLCI image.\n",
    "- Use the ABI-GOES images differently (instead of calculating aggregate) and produce an image that has color for each hour to visualize the dynamics of the algae."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf265e5a-ac83-4d79-92d7-daf2b36514e8",
   "metadata": {},
   "source": [
    "### calculate_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0a36d-8a21-4a85-a801-38c0cb8e4eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_median(time_list, lat_range=None, lon_range=None, threshold=0):\n",
    "    \"\"\"\n",
    "    Calculate the median of algae presence over a given time range based on a list of times,\n",
    "    within specified latitude and longitude ranges.\n",
    "\n",
    "    Parameters:\n",
    "    - time_list (list of str): List of formatted datetime strings in the format 'YYYYMMDD_HH-MM'.\n",
    "    - lat_range (tuple): Tuple of (min_latitude, max_latitude).\n",
    "    - lon_range (tuple): Tuple of (min_longitude, max_longitude).\n",
    "    - threshold (float): The threshold above which data is considered.\n",
    "\n",
    "    Returns:\n",
    "    - median_algae_distribution (DataArray): The median algae distribution within the specified region.\n",
    "    \"\"\"\n",
    "    aggregate_data_list = []\n",
    "\n",
    "    # Loop over each time in the time list, loading the data and adding it to the list\n",
    "    for time_str in time_list:\n",
    "        file_path = f\"/media/yahia/ballena/CLS/abi-goes-global-hr/cls-abi-goes-global-hr_1d_{time_str}.nc\"\n",
    "        # Skip if the file does not exist\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Skipping: {file_path} does not exist.\")\n",
    "            continue\n",
    "        \n",
    "        data = xr.open_dataset(file_path)\n",
    "\n",
    "        # Apply latitude and longitude ranges if specified\n",
    "        if lat_range:\n",
    "            data = data.sel(latitude=slice(*lat_range))\n",
    "        if lon_range:\n",
    "            data = data.sel(longitude=slice(*lon_range))\n",
    "\n",
    "        # Extract the index of interest and drop the 'time' coordinate\n",
    "        algae_data = data['fai_anomaly'].squeeze(drop=True)\n",
    "\n",
    "        # Mask the data to include only algae (values greater than the threshold)\n",
    "        algae_masked = algae_data.where(algae_data > threshold)\n",
    "\n",
    "        # Add the masked data to our list (each element in this list is the data array, after processing, for the give time)\n",
    "        aggregate_data_list.append(algae_masked)\n",
    "\n",
    "    # Combine the data along a new dimension, then calculate the mean along that dimension\n",
    "    # Note: Xarray's mean function by default ignores nan values\n",
    "    aggregate_data = xr.concat(aggregate_data_list, dim='new_dim')\n",
    "    median_algae_distribution = aggregate_data.median(dim='new_dim')\n",
    "\n",
    "    # Extract the date from the first time string and set it as an attribute (Used for the figure title)\n",
    "    date_from_time = time_list[0].split('_')[0]  # Assuming time_list items are 'YYYYMMDD_HH-MM'\n",
    "    median_algae_distribution.attrs['date'] = date_from_time\n",
    "\n",
    "    return median_algae_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144d65fd-af0c-4380-ae2a-98a85aac3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Generating the time list\n",
    "    times = time_list(start_time=datetime(2022, 7, 24, 12, 0), end_time=datetime(2022, 7, 24, 18, 50), interval=10)\n",
    "    \n",
    "    # Calculating the median data for this time period\n",
    "    median_algae_distribution = calculate_median(times,lat_range=(14, 15), lon_range= (-66, -65))\n",
    "    \n",
    "    # Calculating the aggregate data for this time period\n",
    "    average_algae_distribution = calculate_mean(times,lat_range=(12, 17), lon_range=(-67, -60))\n",
    "    \n",
    "    #Visualizing the result and comparing it to the mean \n",
    "    visualize_aggregate(median_algae_distribution, (14, 15), (-66, -65), color=\"viridis\", vmax=0.001, threshold=0)\n",
    "    visualize_aggregate(average_algae_distribution, (12, 17), (-67, -60), color=\"viridis\", vmax=0.001, threshold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad301a10-e925-4281-b28c-fee475b85ec4",
   "metadata": {},
   "source": [
    "Although the difference is not very big, it is non negligible and we can see that median function produces rafts that are a bit thinner, which is preferable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4ff38c-e41f-4c79-87c2-2d01fd357eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':#\n",
    "    # Generating the time list\n",
    "    times = time_list(start_time=datetime(2022, 7, 24, 12, 0), end_time=datetime(2022, 7, 24, 18, 50), interval=10)\n",
    "    \n",
    "    # Calculating the min data for this time period\n",
    "    min_algae_distribution = calculate_min(times,lat_range=(12, 17), lon_range=(-67, -60))\n",
    "    \n",
    "    # Calculating the mean data for this time period\n",
    "    average_algae_distribution = calculate_mean(times,lat_range=(12, 17), lon_range=(-67, -60))\n",
    "    \n",
    "    #Visualizing the result and comparing it to the mean\n",
    "    visualize_aggregate(min_algae_distribution, (12, 17), (-67, -60), color=\"viridis\", vmax=0.001, threshold=0)\n",
    "    visualize_aggregate(average_algae_distribution, (12, 17), (-67, -60), color=\"viridis\", vmax=0.001, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2495f724-5c1e-4f4c-baeb-dad9b74e9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c2b32-6bbe-4370-9f3f-fec4f122fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_median_n(times, lat_range=None, lon_range=None, threshold=0):\n",
    "    \"\"\"\n",
    "    Calculate the median of algae presence over a given time range based on a list of times,\n",
    "    within specified latitude and longitude ranges.\n",
    "\n",
    "    Parameters:\n",
    "    - time_list (list of str): List of formatted datetime strings in the format 'YYYYMMDD_HH-MM'.\n",
    "    - lat_range (tuple): Tuple of (min_latitude, max_latitude).\n",
    "    - lon_range (tuple): Tuple of (min_longitude, max_longitude).\n",
    "    - threshold (float): The threshold above which data is considered.\n",
    "\n",
    "    Returns:\n",
    "    - median_dataset (Dataset): The median algae distribution within the specified region.\n",
    "    \"\"\"\n",
    "    aggregate_data_list = []\n",
    "\n",
    "    # Loop over each time in the time list, loading the data and adding it to the list\n",
    "    for time_str in times:\n",
    "        file_path = f\"/media/yahia/ballena/CLS/abi-goes-global-hr/cls-abi-goes-global-hr_1d_{time_str}.nc\"\n",
    "        # Skip if the file does not exist\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Skipping: {file_path} does not exist.\")\n",
    "            continue\n",
    "        \n",
    "        data = xr.open_dataset(file_path)\n",
    "\n",
    "        # Apply latitude and longitude ranges if specified\n",
    "        if lat_range:\n",
    "            data = data.sel(latitude=slice(*lat_range))\n",
    "        if lon_range:\n",
    "            data = data.sel(longitude=slice(*lon_range))\n",
    "\n",
    "        # Extract the index of interest and drop the 'time' coordinate\n",
    "        algae_data = data['fai_anomaly'].squeeze(drop=True)\n",
    "\n",
    "        # Mask the data to include only algae (values greater than the threshold)\n",
    "        algae_masked = algae_data.where(algae_data > threshold)\n",
    "\n",
    "        # Add the masked data to our list (each element in this list is the data array, after processing, for the give time)\n",
    "        aggregate_data_list.append(algae_masked)\n",
    "\n",
    "    # Combine the data along a new dimension, then calculate the median along that dimension\n",
    "    # Note: Xarray's median function by default ignores nan values\n",
    "    aggregate_data = xr.concat(aggregate_data_list, dim='new_dim')\n",
    "    median_algae_distribution = aggregate_data.median(dim='new_dim')\n",
    "\n",
    "    # Create a new Dataset to include latitude and longitude\n",
    "    median_dataset = xr.Dataset({\n",
    "        'median_fai_anomaly': median_algae_distribution\n",
    "    }, coords={\n",
    "        'latitude': median_algae_distribution.latitude,\n",
    "        'longitude': median_algae_distribution.longitude\n",
    "    })\n",
    "\n",
    "    # Extract the date from the first time string and set it as an attribute (Used for the figure title)\n",
    "    date_from_time = times[0].split('_')[0]  # Assuming time_list items are 'YYYYMMDD_HH-MM'\n",
    "    median_dataset.attrs['date'] = date_from_time\n",
    "\n",
    "    return median_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343f103-7efb-4e14-80b5-1bbe2c876c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    # Generating the time list\n",
    "    times = time_list(start_time=datetime(2022, 7, 24, 12, 0), end_time=datetime(2022, 7, 24, 18, 50), interval=10)\n",
    "    \n",
    "    # Calculate median\n",
    "    median_dataset = calculate_median(times, lat_range=(12, 17), lon_range=(-67, -60), threshold=0)\n",
    "    \n",
    "    # Save to NetCDF\n",
    "    output_filepath = '/home/yahia/Documents/Jupyter/Sargassum/median_algae_distribution.nc'\n",
    "    save_as_netcdf(median_dataset, output_filepath)\n",
    "    \n",
    "    print(f\"Median algae distribution saved to {output_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb08dbf-3861-4ca2-b5d0-b4941f1cb6f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### calculate_percentile\n",
    "This is a sort of generalization of the last 3 functions, (setting the percentile to 50 will return the median, setting it to 100 the max, and to 0 the min)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8f6087-c901-4fcf-a4af-c7da47e353e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentile(time_list, lat_range=None, lon_range=None, threshold=0, percentile=50):\n",
    "    \"\"\"\n",
    "    Calculate a specified percentile of algae presence over a given time range based on a list of times,\n",
    "    within specified latitude and longitude ranges.\n",
    "\n",
    "    Parameters:\n",
    "    - time_list (list of str): List of formatted datetime strings in the format 'YYYYMMDD_HH-MM'.\n",
    "    - lat_range (tuple): Tuple of (min_latitude, max_latitude), specifying the latitude range to analyze.\n",
    "    - lon_range (tuple): Tuple of (min_longitude, max_longitude), specifying the longitude range to analyze.\n",
    "    - threshold (float): The threshold above which data is considered, to focus on significant algae presence.\n",
    "    - percentile (float): The percentile to calculate (0-100).\n",
    "\n",
    "    Returns:\n",
    "    - percentile_algae_distribution (DataArray): The specified percentile of algae distribution within the specified region.\n",
    "    \"\"\"\n",
    "    aggregate_data_list = []\n",
    "\n",
    "    # Loop over each time in the time list, loading the data and adding it to the list\n",
    "    for time_str in time_list:\n",
    "        file_path = f\"/media/yahia/ballena/CLS/abi-goes-global-hr/cls-abi-goes-global-hr_1d_{time_str}.nc\"\n",
    "        data = xr.open_dataset(file_path)\n",
    "\n",
    "        # Apply latitude and longitude ranges if specified\n",
    "        if lat_range:\n",
    "            data = data.sel(latitude=slice(*lat_range))\n",
    "        if lon_range:\n",
    "            data = data.sel(longitude=slice(*lon_range))\n",
    "\n",
    "        # Extract the index of interest and drop the 'time' coordinate\n",
    "        algae_data = data['fai_anomaly'].squeeze(drop=True)\n",
    "\n",
    "        # Mask the data to include only algae (values greater than the threshold)\n",
    "        algae_masked = algae_data.where(algae_data > threshold)\n",
    "\n",
    "        # Add the masked data to our list\n",
    "        aggregate_data_list.append(algae_masked)\n",
    "\n",
    "    # Combine the data along a new dimension\n",
    "    aggregate_data = xr.concat(aggregate_data_list, dim='new_dim')\n",
    "\n",
    "    # Calculate the specified percentile along that dimension\n",
    "    percentile_algae_distribution = aggregate_data.quantile(percentile / 100.0, dim='new_dim', skipna=True)\n",
    "\n",
    "    return percentile_algae_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4cc002-f9b9-4fbe-810d-716527a95a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Generating the time list\n",
    "    times = time_list(start_time=datetime(2022, 7, 24, 12, 0), end_time=datetime(2022, 7, 24, 18, 50), interval=10)\n",
    "    \n",
    "    # Calculating the percentile data for this time period\n",
    "    percentile_algae_distribution = calculate_percentile(times,lat_range=(12, 17), lon_range=(-67, -60), percentile=100)\n",
    "    \n",
    "    # Calculating the median data for this time period\n",
    "    median_algae_distribution = calculate_median(times,lat_range=(12, 17), lon_range=(-67, -60))\n",
    "    \n",
    "    #Visualizing the result and comparing it to the mean\n",
    "    visualize_aggregate(percentile_algae_distribution, (12, 17), (-67, -60), color=\"viridis\", vmax=0.001, threshold=0)\n",
    "    visualize_aggregate(median_algae_distribution, (12, 17), (-67, -60), color=\"viridis\", vmax=0.001, threshold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b5ef16-eac6-44e2-a6dc-30f0dfad8a4e",
   "metadata": {},
   "source": [
    "For the moment, I see no reason we'd need to need any percentiles other than the median (percentile=50), but this is a generalization, which could be useful to factor code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16786c18-1037-4ba7-be5b-b24aadff81b7",
   "metadata": {},
   "source": [
    "# Averaging ABI-GOES images for an hour\n",
    "An average over a day for ABI-GOES images isn't really the point of our project. We want to track the movement of sargassum over 1-hour periods (even less ideally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbcc68e-7c7b-4f6a-924e-b9ccea638790",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Generating the time list\n",
    "    times = time_list(start_time=datetime(2022, 7, 24, 12, 0), end_time=datetime(2022, 7, 24, 13, 00), interval=10)\n",
    "    \n",
    "    # Calculating the median data for this time period\n",
    "    median_algae_distribution = calculate_median(times,lat_range=(12, 17), lon_range=(-67, -60))\n",
    "    \n",
    "    #Visualizing the result\n",
    "    visualize_aggregate(median_algae_distribution, (12, 17), (-67, -60), color=\"viridis\", vmax=0.001, threshold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e9adc5-00a5-41ed-a4ee-57e8d9dad79b",
   "metadata": {},
   "source": [
    "In the span of an hour, the clouds have not moved enough for us to get a clear image, so on its own and with the functions we have so far, an hour doesn't provide enough data to be able to detect the algae. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a7d6a-2115-4c64-bb9c-e024b7ef59b3",
   "metadata": {},
   "source": [
    "# Search for a good temporal resolution\n",
    "A day of averaging is too much and would defeat the purpose of our work. An hour is too little and the result has too much clouds. That's why we should try and find a compromise between temporal resolution and clarity.\n",
    "\n",
    "But how could we quantify whether the solution we settle on is good enough or not? Maybe we could compare the Algae Ratio **$Ar= \\frac{\\text{number of pixels with algae}}{\\text{number of pixels with algae in mean image}} $** to an Aglae Ratio Threshold **Art** where we'd consider an image to be satisfactory if **$Ar > Art$**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0009c37c-0ba0-4b47-a0fc-9e1f6b086a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Generating the time list\n",
    "    times = time_list(start_time=datetime(2022, 7, 24, 12, 0), end_time=datetime(2022, 7, 24, 16, 00), interval=10)\n",
    "    times2 = time_list(start_time=datetime(2022, 7, 24, 14, 0), end_time=datetime(2022, 7, 24, 16, 00), interval=10)\n",
    "    \n",
    "    # Calculating the median data for this time period\n",
    "    median_algae_distribution = calculate_median(times,lat_range=(12, 17), lon_range=(-67, -60))\n",
    "    median_algae_distribution_2 = calculate_median(times2,lat_range=(12, 17), lon_range=(-67, -60))\n",
    "    \n",
    "    #Visualizing the result\n",
    "    visualize_aggregate(median_algae_distribution, (12, 17), (-67, -60), color=\"viridis\", vmax=0.001, threshold=0)\n",
    "    visualize_aggregate(median_algae_distribution_2, (12, 17), (-67, -60), color=\"viridis\", vmax=0.001, threshold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74945e9-5d35-4507-b50a-5a7759741494",
   "metadata": {},
   "source": [
    "We should come back to this, but for now we're going to work on 1-day ABI-GOES averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fac7e2-be6a-4b9d-a9c5-4802e5610359",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Generating the time list\n",
    "    times = time_list(start_time=datetime(2022, 9, 28, 10, 0), end_time=datetime(2022, 9, 28, 18, 50), interval=10)\n",
    "    \n",
    "    # Calculating the median data for this time period\n",
    "    median_algae_distribution = calculate_median(times,lat_range=(12, 17), lon_range=(-67, -60))\n",
    "    \n",
    "    #Visualizing the result\n",
    "    visualize_aggregate(median_algae_distribution, (12, 17), (-67, -60), color=\"viridis\", vmax=0.001, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc013c-1052-4714-b1ea-1dee92311f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
