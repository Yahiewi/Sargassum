{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a25767a6-28d6-4abe-b472-068794b09fbf",
   "metadata": {},
   "source": [
    "# PWC-Net\n",
    "Utilizes a pyramid processing framework, warping, and cost volume techniques. It is designed for both accuracy and efficiency, making it suitable for real-time applications that require high-quality flow estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5a09d6-8f4e-4d00-87d3-7653da0fa3af",
   "metadata": {},
   "source": [
    "## Importing necessary libraries and notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dce049-613e-4f04-b50a-d4d880b7a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "import io\n",
    "import os\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import ticker\n",
    "from IPython.display import Image, display\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "# Append the cloned repository to the system path\n",
    "sys.path.append(os.path.abspath('/home/yahia/Documents/GitProjects/pytorch-pwc'))\n",
    "# Import the necessary functions from pwc_net\n",
    "# from pwc_net import estimate\n",
    "\n",
    "# Append the parent directory (Sargassum) to the system path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "# Import the other notebooks without running their cells\n",
    "from ii_Data_Manipulation import visualize_4\n",
    "from iii_GOES_average import time_list, visualize_aggregate, calculate_median\n",
    "from iv_Image_Processing import collect_times, crop_image, save_aggregate, binarize_image, bilateral_image, process_dates, process_directory\n",
    "from v_i_OF_Functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f72ce35-53f6-4369-91d5-9abaa4b069a6",
   "metadata": {},
   "source": [
    "## PWC-Net Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910230ac-7759-457a-847d-25417cfdacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = torch.from_numpy(img).permute(2, 0, 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8e6c2-ea0b-48ee-a427-7f073a1a88bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the modified run.py\n",
    "run_py_path = '/home/yahia/Documents/GitProjects/pytorch-pwc/run.py'\n",
    "\n",
    "# Sample image paths\n",
    "image_one_path = '/home/yahia/Documents/GitProjects/pytorch-pwc/images/one.png'\n",
    "image_two_path = '/home/yahia/Documents/GitProjects/pytorch-pwc/images/two.png'\n",
    "\n",
    "# Ensure paths are absolute if needed\n",
    "run_py_path = os.path.abspath(run_py_path)\n",
    "image_one_path = os.path.abspath(image_one_path)\n",
    "image_two_path = os.path.abspath(image_two_path)\n",
    "\n",
    "# Output file path\n",
    "output_path = os.path.abspath('/home/yahia/Documents/GitProjects/pytorch-pwc/images/out.flo')\n",
    "\n",
    "# Run the modified script\n",
    "subprocess.run(['python', run_py_path, '--model', 'default', '--one', image_one_path, '--two', image_two_path, '--out', output_path])\n",
    "\n",
    "# Function to read .flo files\n",
    "def read_flo_file(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        magic = np.fromfile(f, np.float32, count=1)\n",
    "        assert magic == 202021.25, \"Magic number incorrect. Invalid .flo file\"\n",
    "        w = np.fromfile(f, np.int32, count=1)[0]\n",
    "        h = np.fromfile(f, np.int32, count=1)[0]\n",
    "        data = np.fromfile(f, np.float32, count=2*w*h)\n",
    "        data2D = np.resize(data, (h, w, 2))\n",
    "        return data2D\n",
    "\n",
    "# Read and visualize the output\n",
    "flow = read_flo_file(output_path)\n",
    "plt.imshow(flow[:, :, 0], cmap='gray')\n",
    "plt.title('Optical Flow (x component)')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(flow[:, :, 1], cmap='gray')\n",
    "plt.title('Optical Flow (y component)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87860e04-d140-4956-b037-62ea24250bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "prev_img_path = \"/media/yahia/ballena/ABI/ABI_Averages_Antilles_Binarized_Bilateral_Negative/Processed_algae_distribution_20220723.png\"\n",
    "next_img_path = \"/media/yahia/ballena/ABI/ABI_Averages_Antilles_Binarized_Bilateral_Negative/Processed_algae_distribution_20220724.png\"\n",
    "prev_img = preprocess_image(prev_img_path)\n",
    "next_img = preprocess_image(next_img_path)\n",
    "\n",
    "# Compute optical flow\n",
    "device = 'cpu'  # or 'cuda' if you have a GPU\n",
    "flow = estimate(prev_img, next_img, model_type='default', device=device)\n",
    "\n",
    "# Convert the flow to a numpy array\n",
    "flow = flow.numpy().transpose(1, 2, 0)\n",
    "\n",
    "# Plot flow vectors on the base image\n",
    "flow_plot = plot_flow_vectors(flow, prev_img_path, step=16, scale=1, display=True, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c8f3d-05f1-403c-bc1d-634139cfeb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
