{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1f18c3-8fa2-4a29-ae48-5ce04c80ceac",
   "metadata": {},
   "source": [
    "# DeepFlow NetCDF\n",
    "Since we're now using NetCDF files instead of png, we will need to modify a lot of the functions we used to visualize our result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e488cd2-646e-4533-bfdc-206cf1c4345b",
   "metadata": {},
   "source": [
    "## Importing necessary libraries and notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa7fa1-0e84-490b-97fd-75ca1c792c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import io\n",
    "import os\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import ticker\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from matplotlib.collections import LineCollection\n",
    "from IPython.display import Image, display, clear_output\n",
    "from PIL import Image as PILImage\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Import the other notebooks without running their cells\n",
    "from ii_Data_Manipulation import visualize_4\n",
    "from iii_GOES_average import time_list, visualize_aggregate, calculate_median\n",
    "from iv_Image_Processing import collect_times, crop_image, save_aggregate, binarize_image, bilateral_image, process_dates, process_directory\n",
    "from vii_Flow_Analysis import haversine\n",
    "from v_i_OF_Functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d498027-901f-4cbe-8f6d-c9877e6daf99",
   "metadata": {},
   "source": [
    "## DeepFlow on NetCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121dcc72-5070-43e0-b076-fb489bf877b5",
   "metadata": {},
   "source": [
    "### *visualize*\n",
    "A generalization of the visualize function in the very first notebook with the added option of plotting flow vectors and choosing the step (density) and scale of the flow vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82008ea3-7c07-4d0c-bbc4-41ad9078ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(file_path, variable_key=\"fai_anomaly\", lat_range=None, lon_range=None, color=\"viridis\", colorbar_label=\"\", title=\"\", flow_vectors=None, quiver_step=None, quiver_scale=None):\n",
    "    \"\"\"\n",
    "    Visualizes the NetCDF data and optionally overlays flow vectors.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: Path to the NetCDF file.\n",
    "    - variable_key: Key for the variable of interest in the NetCDF dataset.\n",
    "    - lat_range: Tuple of (min, max) latitude to subset the data.\n",
    "    - lon_range: Tuple of (min, max) longitude to subset the data.\n",
    "    - color: Color map for the plot.\n",
    "    - colorbar_label: Label for the color bar.\n",
    "    - title: Title of the plot.\n",
    "    - flow_vectors: Optional tuple of flow vector components (flow_u, flow_v).\n",
    "    - quiver_step: Sampling step for displaying quiver arrows, controls density.\n",
    "    - quiver_scale: Scaling factor for quiver arrows, controls size.\n",
    "    \"\"\"\n",
    "    # Load the netCDF data\n",
    "    data = xr.open_dataset(file_path)\n",
    "    \n",
    "    # If ranges are specified, apply them to select the desired subset\n",
    "    if lat_range and 'latitude' in data.coords:\n",
    "        data = data.sel(latitude=slice(*lat_range))\n",
    "    if lon_range and 'longitude' in data.coords:\n",
    "        data = data.sel(longitude=slice(*lon_range))\n",
    "\n",
    "    # Set up a plot with geographic projections\n",
    "    fig, ax = plt.subplots(figsize=(12, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    \n",
    "    # Extract relevant data \n",
    "    index_data = data[variable_key]\n",
    "\n",
    "    # Plot the data\n",
    "    im = index_data.plot(ax=ax, x='longitude', y='latitude', transform=ccrs.PlateCarree(),\n",
    "                         cmap=color, add_colorbar=True, extend='both', cbar_kwargs={'shrink': 0.35})\n",
    "\n",
    "    # Add color bar details\n",
    "    im.colorbar.set_label(colorbar_label)\n",
    "\n",
    "    # Customize the map with coastlines and features\n",
    "    ax.coastlines(resolution='10m', color='black')\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "\n",
    "    # Plot flow vectors if provided\n",
    "    if flow_vectors:\n",
    "        # Automatically determine quiver_step and quiver_scale if not provided\n",
    "        if quiver_step is None:\n",
    "            quiver_step = max(1, int(len(data.latitude) / 20))  # Sample about 20 arrows along the latitude\n",
    "        if quiver_scale is None:\n",
    "            quiver_scale = max(1, int(len(data.latitude) / 2))  # Scale according to number of latitude points\n",
    "\n",
    "        # Create a meshgrid for the flow vectors that matches the data subset\n",
    "        Y, X = np.meshgrid(data.latitude, data.longitude, indexing='ij')\n",
    "        # Apply the step for vector density and scale for vector size\n",
    "        ax.quiver(X[::quiver_step, ::quiver_step], Y[::quiver_step, ::quiver_step], flow_vectors[0][::quiver_step, ::quiver_step], flow_vectors[1][::quiver_step, ::quiver_step], color='red', scale=quiver_scale)\n",
    "\n",
    "    # Show the plot with title\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de105aa-7561-4818-9024-6e72f225d23c",
   "metadata": {},
   "source": [
    "### *calculate_deepflow*\n",
    "A function to calculate and return deepflow using as input two NetCDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d782fed-1dc1-4a94-8fbd-18ac03e6d7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_deepflow(nc_file1, nc_file2, variable_key=\"fai_anomaly\"):\n",
    "    # Load data\n",
    "    data1 = xr.open_dataset(nc_file1)\n",
    "    data2 = xr.open_dataset(nc_file2)\n",
    "    img1 = data1[variable_key].values\n",
    "    img2 = data2[variable_key].values\n",
    "\n",
    "    # Get the latitude and longitude values from the dataset\n",
    "    latitudes = data1.latitude.values\n",
    "    longitudes = data1.longitude.values\n",
    "\n",
    "    # Compute distances in meters between consecutive latitude and longitude points\n",
    "    d_lat_km = haversine(longitudes[0], latitudes[0], longitudes[0], latitudes[1]) * 1000\n",
    "    d_lon_km = haversine(longitudes[0], latitudes[0], longitudes[1], latitudes[0]) * 1000\n",
    "\n",
    "    # Ensure data is 2D\n",
    "    if img1.ndim == 3:\n",
    "        img1 = img1[0]\n",
    "    if img2.ndim == 3:\n",
    "        img2 = img2[0]\n",
    "\n",
    "    # Normalize and convert to 8-bit grayscale\n",
    "    img1 = cv2.normalize(img1, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    img2 = cv2.normalize(img2, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "    # Compute DeepFlow\n",
    "    deep_flow = cv2.optflow.createOptFlow_DeepFlow()\n",
    "    flow = deep_flow.calc(img1, img2, None)\n",
    "\n",
    "    # Convert pixel flow to real world distance flow\n",
    "    flow_u_km = flow[..., 0] * (d_lon_km / data1.dims['longitude'])\n",
    "    flow_v_km = flow[..., 1] * (d_lat_km / data1.dims['latitude'])\n",
    "\n",
    "    return flow_u_km, flow_v_km  # Return flow in kilometers per pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfefb79-45b1-435b-86dc-882656bad7ec",
   "metadata": {},
   "source": [
    "### Default Color (Viridis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b2ca8-f525-4714-b5bf-190b96803116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without Flow\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '/media/yahia/ballena/ABI/NetCDF/Partition/n = 24/Averages/[14.333333333333334,15.5],[-63.33333333333333,-67.0]/algae_distribution_20220723.nc'\n",
    "    visualize(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad629a-af17-483e-becf-a62e96c7af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow on Antilles\n",
    "if __name__ == \"__main__\":\n",
    "    prev_nc = '/home/yahia/Documents/Jupyter/Sargassum/Images/Test/ABI_Averages/algae_distribution_20220723.nc'\n",
    "    next_nc = '/home/yahia/Documents/Jupyter/Sargassum/Images/Test/ABI_Averages/algae_distribution_20220724.nc'\n",
    "    \n",
    "    flow_vectors = calculate_deepflow(prev_nc, next_nc)\n",
    "    visualize(prev_nc, variable_key=\"fai_anomaly\", colorbar_label=\"FAI\", title=\"Optical Flow\", flow_vectors=flow_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e517ac-b188-4c23-8fe5-d3bf9b4be7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow on Atlantic\n",
    "if __name__ == \"__main__\":\n",
    "    prev_nc = \"/media/yahia/ballena/ABI/NetCDF/Atlantic/Averages/algae_distribution_20220723.nc\"\n",
    "    next_nc = \"/media/yahia/ballena/ABI/NetCDF/Atlantic/Averages/algae_distribution_20220724.nc\"\n",
    "    \n",
    "    flow_vectors = calculate_deepflow(prev_nc, next_nc)\n",
    "    visualize(prev_nc, variable_key=\"fai_anomaly\", colorbar_label=\"FAI\", title=\"Optical Flow\", flow_vectors=flow_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9578d138-7d61-40ea-b905-7ec5e62b91e4",
   "metadata": {},
   "source": [
    "### Binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d3c257-d355-4c18-a78f-3c92b444a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without Flow\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '/media/yahia/ballena/ABI/NetCDF/Partition/n = 24/Averages_Binarized/[14.333333333333334,15.5],[-63.33333333333333,-67.0]/Processed_algae_distribution_20220723.nc'\n",
    "    visualize(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5464c757-a7c0-456e-adc6-4dc345f8792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow on Antilles\n",
    "if __name__ == \"__main__\":\n",
    "    prev_nc = '/home/yahia/Documents/Jupyter/Sargassum/Images/Test/Processed_ABI_Averages/Processed_algae_distribution_20220723.nc'\n",
    "    next_nc = '/home/yahia/Documents/Jupyter/Sargassum/Images/Test/Processed_ABI_Averages/Processed_algae_distribution_20220724.nc'\n",
    "    \n",
    "    flow_vectors = calculate_deepflow(prev_nc, next_nc)\n",
    "    visualize(prev_nc, variable_key=\"fai_anomaly\", colorbar_label=\"FAI\", title=\"Optical Flow\", flow_vectors=flow_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9599885-a310-40e1-8843-d0af60e536fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow on Atlantic\n",
    "if __name__ == \"__main__\":\n",
    "    prev_nc = \"/media/yahia/ballena/ABI/NetCDF/Atlantic/Averages_Binarized/Processed_algae_distribution_20220723.nc\"\n",
    "    next_nc = \"/media/yahia/ballena/ABI/NetCDF/Atlantic/Averages_Binarized/Processed_algae_distribution_20220724.nc\"\n",
    "    \n",
    "    flow_vectors = calculate_deepflow(prev_nc, next_nc)\n",
    "    visualize(prev_nc, variable_key=\"fai_anomaly\", colorbar_label=\"FAI\", title=\"Optical Flow\", flow_vectors=flow_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67857bdc-f7f7-447b-9e76-a615c5f7e981",
   "metadata": {},
   "source": [
    "### *save_flow*\n",
    "This function takes as input the path for the NetCDF image and the (already calculated) flow and creates a new NetCDF file with two new variables containing the flow vector components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461e375-5c6f-418e-80b4-ffd8927c1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_flow(file_path, variable_key=\"fai_anomaly\", lat_range=None, lon_range=None, flow_vectors=None, output_path=\"output.nc\"):\n",
    "    \"\"\"\n",
    "    Saves the original NetCDF data and optionally overlays flow vectors as new data variables into another NetCDF file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the NetCDF file.\n",
    "    - variable_key (str): Key for the variable of interest in the NetCDF dataset.\n",
    "    - lat_range (tuple): Tuple of (min, max) latitude to subset the data.\n",
    "    - lon_range (tuple): Tuple of (min, max) longitude to subset the data.\n",
    "    - flow_vectors (tuple): Optional tuple of flow vector components (flow_u, flow_v).\n",
    "    - output_path (str): Path to save the results as a NetCDF file.\n",
    "    \"\"\"\n",
    "    # Load the NetCDF data\n",
    "    data = xr.open_dataset(file_path)\n",
    "    \n",
    "    # Subset the data based on provided latitude and longitude ranges\n",
    "    if lat_range and 'latitude' in data.coords:\n",
    "        data = data.sel(latitude=slice(*lat_range))\n",
    "    if lon_range and 'longitude' in data.coords:\n",
    "        data = data.sel(longitude=slice(*lon_range))\n",
    "\n",
    "    # Include flow vectors as new data variables if provided\n",
    "    if flow_vectors:\n",
    "        data['flow_u'] = (('latitude', 'longitude'), flow_vectors[0])\n",
    "        data['flow_v'] = (('latitude', 'longitude'), flow_vectors[1])\n",
    "\n",
    "    # Save the modified dataset to a new NetCDF file\n",
    "    data.to_netcdf(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d36a7ba-7467-4371-b36b-87d8834f4e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on Antilles\n",
    "if __name__ == \"__main__\":\n",
    "    prev_nc = '/home/yahia/Documents/Jupyter/Sargassum/Images/Test/Processed_ABI_Averages/Processed_algae_distribution_20220723.nc'\n",
    "    next_nc = '/home/yahia/Documents/Jupyter/Sargassum/Images/Test/Processed_ABI_Averages/Processed_algae_distribution_20220724.nc'\n",
    "    \n",
    "    flow_vectors = calculate_deepflow(prev_nc, next_nc)\n",
    "    # Example usage\n",
    "    save_flow(prev_nc, 'fai_anomaly', output_path=\"/home/yahia/Documents/Jupyter/Sargassum/Images/Test/Antilles_with_flow.nc\", flow_vectors=flow_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d95f8ea-6063-46fb-9d1a-145564f32469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on Atlantic\n",
    "if __name__ == \"__main__\":\n",
    "    prev_nc = \"/media/yahia/ballena/ABI/NetCDF/Atlantic/Averages_Binarized/Processed_algae_distribution_20220723.nc\"\n",
    "    next_nc = \"/media/yahia/ballena/ABI/NetCDF/Atlantic/Averages_Binarized/Processed_algae_distribution_20220724.nc\"\n",
    "    \n",
    "    flow_vectors = calculate_deepflow(prev_nc, next_nc)\n",
    "    # Example usage\n",
    "    save_flow(prev_nc, 'fai_anomaly', output_path=\"/home/yahia/Documents/Jupyter/Sargassum/Images/Test/Atlantic_with_flow.nc\", flow_vectors=flow_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3429b0e8-fdfd-4cf7-a757-e7937cbcfbef",
   "metadata": {},
   "source": [
    "### *visualize_quiver* \n",
    "Takes as input a NetCDF file with the added variables **flow_u** and **flow_v** and uses them to overlay the vectors on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d291ca6-c52d-4f9d-a7dc-49cb1adaa6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_quiver(file_path, variable_key=\"fai_anomaly\", quiver_step=10, quiver_scale=100, save_path=None, mask_data=True):\n",
    "    \"\"\"\n",
    "    Visualizes the optical flow vectors on top of the variable image from a NetCDF file.\n",
    "    Only shows vectors where the data is non-zero if masking is enabled.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the NetCDF file.\n",
    "    - variable_key (str): Key for the variable of interest (typically the image data).\n",
    "    - quiver_step (int): Step size for downsampling the quiver plot to reduce vector density.\n",
    "    - quiver_scale (int): Scaling factor for the vectors to control their size.\n",
    "    - save_path (str, optional): Path to save the figure as a high-resolution PNG image. If None, the image is not saved.\n",
    "    - mask_data (bool, optional): If True, vectors are only displayed where the data is non-zero.\n",
    "    \"\"\"\n",
    "    data = xr.open_dataset(file_path)\n",
    "\n",
    "    # Increase figure size for better resolution in the saved image\n",
    "    fig, ax = plt.subplots(figsize=(25, 20), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    data[variable_key].plot(ax=ax, x='longitude', y='latitude', transform=ccrs.PlateCarree(), cmap='gray', add_colorbar=False)\n",
    "\n",
    "    # Calculate the step size for displaying vectors\n",
    "    skip = (slice(None, None, quiver_step), slice(None, None, quiver_step))\n",
    "    X, Y = np.meshgrid(data.longitude, data.latitude)\n",
    "    U = data['flow_u'].values\n",
    "    V = data['flow_v'].values\n",
    "\n",
    "    if mask_data:\n",
    "        # Mask where the data is zero\n",
    "        mask = data[variable_key].values != 0\n",
    "        masked_X = X[skip][mask[skip]]\n",
    "        masked_Y = Y[skip][mask[skip]]\n",
    "        masked_U = U[skip][mask[skip]]\n",
    "        masked_V = V[skip][mask[skip]]\n",
    "    else:\n",
    "        masked_X = X[skip]\n",
    "        masked_Y = Y[skip]\n",
    "        masked_U = U[skip]\n",
    "        masked_V = V[skip]\n",
    "\n",
    "    # Overlay the flow vectors\n",
    "    ax.quiver(masked_X, masked_Y, masked_U, masked_V, color='red', scale=quiver_scale)\n",
    "\n",
    "    plt.title('Optical Flow on Image')\n",
    "\n",
    "    # Save the figure if a save_path is provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)  # Close the figure to free up memory\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829aebea-ce3c-4e7f-bf78-d7b0b0c79eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antilles\n",
    "if __name__ == \"__main__\":\n",
    "    visualize_quiver(\"/home/yahia/Documents/Jupyter/Sargassum/Images/Test/Antilles_with_flow.nc\", 'fai_anomaly', quiver_step=12, quiver_scale=500, mask_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be51c5-14e9-421b-9115-b6472e8e0355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antilles (masked)\n",
    "if __name__ == \"__main__\":\n",
    "    visualize_quiver(\"/home/yahia/Documents/Jupyter/Sargassum/Images/Test/Antilles_with_flow.nc\", 'fai_anomaly', quiver_step=5, quiver_scale=1000, mask_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f82731-1178-43d0-9226-f68aec4baefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atlantic\n",
    "if __name__ == \"__main__\":\n",
    "    visualize_quiver(\"/home/yahia/Documents/Jupyter/Sargassum/Images/Test/Atlantic_with_flow.nc\", 'fai_anomaly', quiver_step=45, quiver_scale=3000, save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc0b64-5658-4392-81fa-34102985be80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atlantic\n",
    "if __name__ == \"__main__\":\n",
    "    visualize_quiver(\"/home/yahia/Documents/Jupyter/Sargassum/Images/Test/Atlantic_with_flow.nc\", 'fai_anomaly', quiver_step=15, quiver_scale=5000, save_path='/home/yahia/Bureau/atlantic_flow_masked', mask_data=True)\n",
    "    # visualize_quiver(\"/home/yahia/Documents/Jupyter/Sargassum/Images/Test/Atlantic_with_flow.nc\", 'fai_anomaly', quiver_step=10, quiver_scale=5000, save_path=None, mask_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76df50c7-8317-47d8-8467-f17c68b50356",
   "metadata": {},
   "source": [
    "### *visualize_flow*\n",
    "Similar to *visualize_quiver*, but uses custom vectors instead of quiver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e9da5e-6733-43c3-b969-0f19832b3eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_flow(file_path, variable_key=\"fai_anomaly\", quiver_step=10, line_width=0.5, quiver_scale=1.0, save_path=None, mask_data=True):\n",
    "    data = xr.open_dataset(file_path)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 16), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    data[variable_key].plot(ax=ax, x='longitude', y='latitude', transform=ccrs.PlateCarree(), cmap='gray', add_colorbar=False)\n",
    "\n",
    "    # Generate meshgrid for coordinates and vector components, applying downsampling by quiver_step\n",
    "    X, Y = np.meshgrid(data.longitude[::quiver_step], data.latitude[::quiver_step])\n",
    "    U = data['flow_u'].values[::quiver_step, ::quiver_step]\n",
    "    V = data['flow_v'].values[::quiver_step, ::quiver_step]\n",
    "\n",
    "    if mask_data:\n",
    "        mask = data[variable_key].values[::quiver_step, ::quiver_step] != 0\n",
    "        X, Y, U, V = X[mask], Y[mask], U[mask], V[mask]\n",
    "\n",
    "    # Scale the vectors using quiver_scale\n",
    "    U, V = U * quiver_scale, V * quiver_scale\n",
    "\n",
    "    # Calculate end points of vectors\n",
    "    end_X, end_Y = X + U, Y + V\n",
    "    lines = np.array([[[x, y], [ex, ey]] for x, y, ex, ey in zip(X.flatten(), Y.flatten(), end_X.flatten(), end_Y.flatten())])\n",
    "\n",
    "    # Create a LineCollection from the arrays of line segments\n",
    "    lc = LineCollection(lines, colors='red', linewidths=line_width, transform=ccrs.PlateCarree())\n",
    "    ax.add_collection(lc)\n",
    "\n",
    "    plt.title('Optical Flow on Image')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)  # Close the figure to free up memory\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12be288-0568-4bf9-b2d3-111202b4530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antilles\n",
    "if __name__ == \"__main__\":\n",
    "    visualize_flow(\"/home/yahia/Documents/Jupyter/Sargassum/Images/Test/Antilles_with_flow.nc\", 'fai_anomaly', quiver_step=12, quiver_scale=0.005, mask_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1806601a-6f93-444f-8bc6-ff9ee5b5a886",
   "metadata": {},
   "source": [
    "## Comparison with Glorys12 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec5e49f-e196-462a-b1e8-768612b9a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #Calculate flow\n",
    "    prev_nc = \"/media/yahia/ballena/ABI/NetCDF/Atlantic/Averages_Binarized/Processed_algae_distribution_20220723.nc\"\n",
    "    next_nc = \"/media/yahia/ballena/ABI/NetCDF/Atlantic/Averages_Binarized/Processed_algae_distribution_20220724.nc\"\n",
    "    \n",
    "    flow_u, flow_v = calculate_deepflow(prev_nc, next_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff797fe-e762-4914-a474-00400d509688",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Loading Glorys12\n",
    "    ds = xr.open_dataset('/media/yahia/ballena/GLORYS12_SARG/glorys12_1d_2022.nc')\n",
    "    \n",
    "    # Extract data for '2022-07-23' and remove any singleton time dimensions\n",
    "    current_u = ds['uo'].sel(time='2022-07-23').squeeze()\n",
    "    current_v = ds['vo'].sel(time='2022-07-23').squeeze()\n",
    "\n",
    "    # Check and match dimensions\n",
    "    if 'latitude' in current_u.dims and 'longitude' in current_u.dims:\n",
    "        lon, lat = np.meshgrid(current_u.longitude, current_u.latitude)\n",
    "    else:\n",
    "        lon = current_u.longitude\n",
    "        lat = current_u.latitude\n",
    "\n",
    "    # Assume flow_u and flow_v are numpy arrays extracted from your analysis with matching dimensions\n",
    "    difference_u = flow_u - current_u.values\n",
    "    difference_v = flow_v - current_v.values\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Plot for horizontal difference (u-component)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    lon, lat = np.meshgrid(current_u.longitude, current_u.latitude)\n",
    "    u_plot = plt.pcolormesh(lon, lat, difference_u, shading='auto', cmap='coolwarm')\n",
    "    plt.colorbar(u_plot, label='Difference in u-component (m/s)')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.title('Horizontal Difference (u-component)')\n",
    "\n",
    "    # Plot for vertical difference (v-component)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    v_plot = plt.pcolormesh(lon, lat, difference_v, shading='auto', cmap='coolwarm')\n",
    "    plt.colorbar(v_plot, label='Difference in v-component (m/s)')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.title('Vertical Difference (v-component)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e40e0a-ac49-4e30-a66b-e0bf87526ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
